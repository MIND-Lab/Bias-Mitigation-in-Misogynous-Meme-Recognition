{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal BMA (TAGS TEXT CAPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import json\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from Utils import load_data, project_paths, evaluation_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_tags_train = pd.read_csv(project_paths.csv_uni_tags_train_probs, sep=\"\\t\")\n",
    "probs_text_train = pd.read_csv(project_paths.csv_uni_text_train_probs, sep=\"\\t\")\n",
    "probs_caps_train = pd.read_csv(project_paths.csv_uni_caps_train_probs, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>SVM PROB 0</th>\n",
       "      <th>SVM PROB 1</th>\n",
       "      <th>KNN PROB 0</th>\n",
       "      <th>KNN PROB 1</th>\n",
       "      <th>NB PROB 0</th>\n",
       "      <th>NB PROB 1</th>\n",
       "      <th>DT PROB 0</th>\n",
       "      <th>DT PROB 1</th>\n",
       "      <th>MLP PROB 0</th>\n",
       "      <th>MLP PROB 1</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>BMA PROB 0</th>\n",
       "      <th>BMA PROB 1</th>\n",
       "      <th>BMA LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0.633238</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.309880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>0.713027</td>\n",
       "      <td>0.286973</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.828080</td>\n",
       "      <td>0.171920</td>\n",
       "      <td>0.629571</td>\n",
       "      <td>0.370429</td>\n",
       "      <td>0.655799</td>\n",
       "      <td>0.344201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682752</td>\n",
       "      <td>0.317248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>0.633238</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.309880</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>0.633238</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.309880</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10028.jpg</td>\n",
       "      <td>0.715659</td>\n",
       "      <td>0.284341</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.832299</td>\n",
       "      <td>0.167701</td>\n",
       "      <td>0.629571</td>\n",
       "      <td>0.370429</td>\n",
       "      <td>0.653258</td>\n",
       "      <td>0.346742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644988</td>\n",
       "      <td>0.355012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9958.jpg</td>\n",
       "      <td>0.743568</td>\n",
       "      <td>0.256432</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.626108</td>\n",
       "      <td>0.373892</td>\n",
       "      <td>0.615198</td>\n",
       "      <td>0.384802</td>\n",
       "      <td>1</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9984.jpg</td>\n",
       "      <td>0.626514</td>\n",
       "      <td>0.373486</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.709288</td>\n",
       "      <td>0.290712</td>\n",
       "      <td>0.686821</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.677944</td>\n",
       "      <td>0.322056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648380</td>\n",
       "      <td>0.351620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9988.jpg</td>\n",
       "      <td>0.713976</td>\n",
       "      <td>0.286024</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.830421</td>\n",
       "      <td>0.169579</td>\n",
       "      <td>0.626108</td>\n",
       "      <td>0.373892</td>\n",
       "      <td>0.649404</td>\n",
       "      <td>0.350596</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644020</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9989.jpg</td>\n",
       "      <td>0.695625</td>\n",
       "      <td>0.304375</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.197230</td>\n",
       "      <td>0.686821</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.662517</td>\n",
       "      <td>0.337483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688271</td>\n",
       "      <td>0.311729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9993.jpg</td>\n",
       "      <td>0.594650</td>\n",
       "      <td>0.405350</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.739494</td>\n",
       "      <td>0.260506</td>\n",
       "      <td>0.686821</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.590239</td>\n",
       "      <td>0.409761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639531</td>\n",
       "      <td>0.360469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  SVM PROB 0  SVM PROB 1  KNN PROB 0  KNN PROB 1  NB PROB 0  \\\n",
       "0         1.jpg    0.633238    0.366762    0.714286    0.285714   0.710887   \n",
       "1     10000.jpg    0.713027    0.286973    0.666667    0.333333   0.828080   \n",
       "2      1001.jpg    0.633238    0.366762    0.714286    0.285714   0.710887   \n",
       "3     10016.jpg    0.633238    0.366762    0.714286    0.285714   0.710887   \n",
       "4     10028.jpg    0.715659    0.284341    0.476190    0.523810   0.832299   \n",
       "...         ...         ...         ...         ...         ...        ...   \n",
       "9995   9958.jpg    0.743568    0.256432    0.476190    0.523810   0.999757   \n",
       "9996   9984.jpg    0.626514    0.373486    0.619048    0.380952   0.709288   \n",
       "9997   9988.jpg    0.713976    0.286024    0.476190    0.523810   0.830421   \n",
       "9998   9989.jpg    0.695625    0.304375    0.666667    0.333333   0.802770   \n",
       "9999   9993.jpg    0.594650    0.405350    0.666667    0.333333   0.739494   \n",
       "\n",
       "      NB PROB 1  DT PROB 0  DT PROB 1  MLP PROB 0  MLP PROB 1  ground_truth  \\\n",
       "0      0.289113   0.691209   0.308791    0.690120    0.309880             0   \n",
       "1      0.171920   0.629571   0.370429    0.655799    0.344201             0   \n",
       "2      0.289113   0.691209   0.308791    0.690120    0.309880             1   \n",
       "3      0.289113   0.691209   0.308791    0.690120    0.309880             1   \n",
       "4      0.167701   0.629571   0.370429    0.653258    0.346742             0   \n",
       "...         ...        ...        ...         ...         ...           ...   \n",
       "9995   0.000243   0.626108   0.373892    0.615198    0.384802             1   \n",
       "9996   0.290712   0.686821   0.313179    0.677944    0.322056             1   \n",
       "9997   0.169579   0.626108   0.373892    0.649404    0.350596             0   \n",
       "9998   0.197230   0.686821   0.313179    0.662517    0.337483             0   \n",
       "9999   0.260506   0.686821   0.313179    0.590239    0.409761             0   \n",
       "\n",
       "      BMA PROB 0  BMA PROB 1  BMA LABELS  \n",
       "0       0.671682    0.328318           0  \n",
       "1       0.682752    0.317248           0  \n",
       "2       0.671682    0.328318           0  \n",
       "3       0.671682    0.328318           0  \n",
       "4       0.644988    0.355012           0  \n",
       "...          ...         ...         ...  \n",
       "9995    0.677800    0.322200           0  \n",
       "9996    0.648380    0.351620           0  \n",
       "9997    0.644020    0.355980           0  \n",
       "9998    0.688271    0.311729           0  \n",
       "9999    0.639531    0.360469           0  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_tags_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text_train = pd.read_csv(project_paths.csv_uni_tags_test_scores, sep=\"\\t\")\n",
    "score_caps_train = pd.read_csv(project_paths.csv_uni_text_test_scores, sep=\"\\t\")\n",
    "score_tags_train = pd.read_csv(project_paths.csv_uni_caps_test_scores, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE 0 SVM</th>\n",
       "      <th>SCORE 1 SVM</th>\n",
       "      <th>SCORE 0 KNN</th>\n",
       "      <th>SCORE 1 KNN</th>\n",
       "      <th>SCORE 0 NB</th>\n",
       "      <th>SCORE 1 NB</th>\n",
       "      <th>SCORE 0 DT</th>\n",
       "      <th>SCORE 1 DT</th>\n",
       "      <th>SCORE 0 MLP</th>\n",
       "      <th>SCORE 1 MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656017</td>\n",
       "      <td>0.695570</td>\n",
       "      <td>0.651709</td>\n",
       "      <td>0.693609</td>\n",
       "      <td>0.631696</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.650628</td>\n",
       "      <td>0.680077</td>\n",
       "      <td>0.637778</td>\n",
       "      <td>0.703636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.651820</td>\n",
       "      <td>0.703103</td>\n",
       "      <td>0.646355</td>\n",
       "      <td>0.699352</td>\n",
       "      <td>0.630743</td>\n",
       "      <td>0.708985</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.693533</td>\n",
       "      <td>0.642616</td>\n",
       "      <td>0.715184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.658018</td>\n",
       "      <td>0.705736</td>\n",
       "      <td>0.653135</td>\n",
       "      <td>0.704721</td>\n",
       "      <td>0.638941</td>\n",
       "      <td>0.715350</td>\n",
       "      <td>0.659816</td>\n",
       "      <td>0.697923</td>\n",
       "      <td>0.653488</td>\n",
       "      <td>0.720096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.657787</td>\n",
       "      <td>0.708632</td>\n",
       "      <td>0.652115</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.641121</td>\n",
       "      <td>0.721297</td>\n",
       "      <td>0.660614</td>\n",
       "      <td>0.701293</td>\n",
       "      <td>0.653348</td>\n",
       "      <td>0.722897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.657285</td>\n",
       "      <td>0.705817</td>\n",
       "      <td>0.649520</td>\n",
       "      <td>0.702882</td>\n",
       "      <td>0.638395</td>\n",
       "      <td>0.717492</td>\n",
       "      <td>0.661273</td>\n",
       "      <td>0.699981</td>\n",
       "      <td>0.650158</td>\n",
       "      <td>0.720403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.659827</td>\n",
       "      <td>0.706704</td>\n",
       "      <td>0.654083</td>\n",
       "      <td>0.706317</td>\n",
       "      <td>0.638694</td>\n",
       "      <td>0.717362</td>\n",
       "      <td>0.663005</td>\n",
       "      <td>0.700755</td>\n",
       "      <td>0.653839</td>\n",
       "      <td>0.721228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.663290</td>\n",
       "      <td>0.706841</td>\n",
       "      <td>0.655108</td>\n",
       "      <td>0.704509</td>\n",
       "      <td>0.639663</td>\n",
       "      <td>0.715892</td>\n",
       "      <td>0.665558</td>\n",
       "      <td>0.700514</td>\n",
       "      <td>0.653126</td>\n",
       "      <td>0.720021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.665149</td>\n",
       "      <td>0.707054</td>\n",
       "      <td>0.656583</td>\n",
       "      <td>0.704130</td>\n",
       "      <td>0.642160</td>\n",
       "      <td>0.716478</td>\n",
       "      <td>0.667371</td>\n",
       "      <td>0.700855</td>\n",
       "      <td>0.654464</td>\n",
       "      <td>0.720344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.667850</td>\n",
       "      <td>0.705845</td>\n",
       "      <td>0.659691</td>\n",
       "      <td>0.701564</td>\n",
       "      <td>0.645113</td>\n",
       "      <td>0.715387</td>\n",
       "      <td>0.671008</td>\n",
       "      <td>0.699075</td>\n",
       "      <td>0.657820</td>\n",
       "      <td>0.717574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.665526</td>\n",
       "      <td>0.706059</td>\n",
       "      <td>0.657146</td>\n",
       "      <td>0.701226</td>\n",
       "      <td>0.641794</td>\n",
       "      <td>0.714414</td>\n",
       "      <td>0.668696</td>\n",
       "      <td>0.698682</td>\n",
       "      <td>0.655356</td>\n",
       "      <td>0.716991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCORE 0 SVM  SCORE 1 SVM  SCORE 0 KNN  SCORE 1 KNN  SCORE 0 NB  SCORE 1 NB  \\\n",
       "0     0.656017     0.695570     0.651709     0.693609    0.631696    0.701087   \n",
       "1     0.651820     0.703103     0.646355     0.699352    0.630743    0.708985   \n",
       "2     0.658018     0.705736     0.653135     0.704721    0.638941    0.715350   \n",
       "3     0.657787     0.708632     0.652115     0.705882    0.641121    0.721297   \n",
       "4     0.657285     0.705817     0.649520     0.702882    0.638395    0.717492   \n",
       "5     0.659827     0.706704     0.654083     0.706317    0.638694    0.717362   \n",
       "6     0.663290     0.706841     0.655108     0.704509    0.639663    0.715892   \n",
       "7     0.665149     0.707054     0.656583     0.704130    0.642160    0.716478   \n",
       "8     0.667850     0.705845     0.659691     0.701564    0.645113    0.715387   \n",
       "9     0.665526     0.706059     0.657146     0.701226    0.641794    0.714414   \n",
       "\n",
       "   SCORE 0 DT  SCORE 1 DT  SCORE 0 MLP  SCORE 1 MLP  \n",
       "0    0.650628    0.680077     0.637778     0.703636  \n",
       "1    0.649518    0.693533     0.642616     0.715184  \n",
       "2    0.659816    0.697923     0.653488     0.720096  \n",
       "3    0.660614    0.701293     0.653348     0.722897  \n",
       "4    0.661273    0.699981     0.650158     0.720403  \n",
       "5    0.663005    0.700755     0.653839     0.721228  \n",
       "6    0.665558    0.700514     0.653126     0.720021  \n",
       "7    0.667371    0.700855     0.654464     0.720344  \n",
       "8    0.671008    0.699075     0.657820     0.717574  \n",
       "9    0.668696    0.698682     0.655356     0.716991  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_text_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results BMA single modality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris_tags_train = pd.read_csv(project_paths.csv_uni_tags_test_res, sep=\"\\t\")\n",
    "ris_caps_train = pd.read_csv(project_paths.csv_uni_text_test_res, sep=\"\\t\")\n",
    "ris_text_train = pd.read_csv(project_paths.csv_uni_caps_test_res, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measures</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>NB</th>\n",
       "      <th>DT</th>\n",
       "      <th>MLP</th>\n",
       "      <th>BMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prec pos</td>\n",
       "      <td>0.604436</td>\n",
       "      <td>0.597496</td>\n",
       "      <td>0.604436</td>\n",
       "      <td>0.592150</td>\n",
       "      <td>0.601521</td>\n",
       "      <td>0.599009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prec neg</td>\n",
       "      <td>0.623094</td>\n",
       "      <td>0.623583</td>\n",
       "      <td>0.623094</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.625140</td>\n",
       "      <td>0.628651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rec pos</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.664200</td>\n",
       "      <td>0.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rec neg</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1 pos</td>\n",
       "      <td>0.628242</td>\n",
       "      <td>0.630784</td>\n",
       "      <td>0.628242</td>\n",
       "      <td>0.639042</td>\n",
       "      <td>0.631309</td>\n",
       "      <td>0.635621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1 neg</td>\n",
       "      <td>0.596455</td>\n",
       "      <td>0.584485</td>\n",
       "      <td>0.596455</td>\n",
       "      <td>0.571116</td>\n",
       "      <td>0.590780</td>\n",
       "      <td>0.584875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACC</td>\n",
       "      <td>0.628877</td>\n",
       "      <td>0.642589</td>\n",
       "      <td>0.609668</td>\n",
       "      <td>0.641744</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.612100</td>\n",
       "      <td>0.639748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measures       SVM       KNN        NB        DT       MLP       BMA\n",
       "0  Prec pos  0.604436  0.597496  0.604436  0.592150  0.601521  0.599009\n",
       "1  Prec neg  0.623094  0.623583  0.623094  0.630435  0.625140  0.628651\n",
       "2   Rec pos  0.654000  0.668000  0.654000  0.694000  0.664200  0.677000\n",
       "3   Rec neg  0.572000  0.550000  0.572000  0.522000  0.560000  0.546800\n",
       "4    F1 pos  0.628242  0.630784  0.628242  0.639042  0.631309  0.635621\n",
       "5    F1 neg  0.596455  0.584485  0.596455  0.571116  0.590780  0.584875\n",
       "6       ACC  0.628877  0.642589  0.609668  0.641744  0.659600  0.611900\n",
       "7       AUC  0.607500  0.609000  0.613000  0.608000  0.612100  0.639748"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ris_tags_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_caps0_train = ris_caps_train.loc[ris_caps_train[\"measures\"]==\"F1 pos\", \"BMA\"].values[0]\n",
    "f1_text0_train = ris_text_train.loc[ris_text_train[\"measures\"]==\"F1 pos\", \"BMA\"].values[0]\n",
    "f1_tags0_train = ris_tags_train.loc[ris_tags_train[\"measures\"]==\"F1 pos\", \"BMA\"].values[0]\n",
    "f1_caps1_train = ris_caps_train.loc[ris_caps_train[\"measures\"]==\"F1 neg\", \"BMA\"].values[0]\n",
    "f1_text1_train = ris_text_train.loc[ris_text_train[\"measures\"]==\"F1 neg\", \"BMA\"].values[0]\n",
    "f1_tags1_train = ris_tags_train.loc[ris_tags_train[\"measures\"]==\"F1 neg\", \"BMA\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6928342665591812"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_caps0_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>SVM PROB 0</th>\n",
       "      <th>SVM PROB 1</th>\n",
       "      <th>KNN PROB 0</th>\n",
       "      <th>KNN PROB 1</th>\n",
       "      <th>NB PROB 0</th>\n",
       "      <th>NB PROB 1</th>\n",
       "      <th>DT PROB 0</th>\n",
       "      <th>DT PROB 1</th>\n",
       "      <th>MLP PROB 0</th>\n",
       "      <th>MLP PROB 1</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>BMA PROB 0</th>\n",
       "      <th>BMA PROB 1</th>\n",
       "      <th>BMA LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0.633238</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.309880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>0.713027</td>\n",
       "      <td>0.286973</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.828080</td>\n",
       "      <td>0.171920</td>\n",
       "      <td>0.629571</td>\n",
       "      <td>0.370429</td>\n",
       "      <td>0.655799</td>\n",
       "      <td>0.344201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682752</td>\n",
       "      <td>0.317248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001.jpg</td>\n",
       "      <td>0.633238</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.309880</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10016.jpg</td>\n",
       "      <td>0.633238</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.710887</td>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.691209</td>\n",
       "      <td>0.308791</td>\n",
       "      <td>0.690120</td>\n",
       "      <td>0.309880</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10028.jpg</td>\n",
       "      <td>0.715659</td>\n",
       "      <td>0.284341</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.832299</td>\n",
       "      <td>0.167701</td>\n",
       "      <td>0.629571</td>\n",
       "      <td>0.370429</td>\n",
       "      <td>0.653258</td>\n",
       "      <td>0.346742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644988</td>\n",
       "      <td>0.355012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9958.jpg</td>\n",
       "      <td>0.743568</td>\n",
       "      <td>0.256432</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.626108</td>\n",
       "      <td>0.373892</td>\n",
       "      <td>0.615198</td>\n",
       "      <td>0.384802</td>\n",
       "      <td>1</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9984.jpg</td>\n",
       "      <td>0.626514</td>\n",
       "      <td>0.373486</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.709288</td>\n",
       "      <td>0.290712</td>\n",
       "      <td>0.686821</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.677944</td>\n",
       "      <td>0.322056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648380</td>\n",
       "      <td>0.351620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9988.jpg</td>\n",
       "      <td>0.713976</td>\n",
       "      <td>0.286024</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.830421</td>\n",
       "      <td>0.169579</td>\n",
       "      <td>0.626108</td>\n",
       "      <td>0.373892</td>\n",
       "      <td>0.649404</td>\n",
       "      <td>0.350596</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644020</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9989.jpg</td>\n",
       "      <td>0.695625</td>\n",
       "      <td>0.304375</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.802770</td>\n",
       "      <td>0.197230</td>\n",
       "      <td>0.686821</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.662517</td>\n",
       "      <td>0.337483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688271</td>\n",
       "      <td>0.311729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9993.jpg</td>\n",
       "      <td>0.594650</td>\n",
       "      <td>0.405350</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.739494</td>\n",
       "      <td>0.260506</td>\n",
       "      <td>0.686821</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.590239</td>\n",
       "      <td>0.409761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639531</td>\n",
       "      <td>0.360469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  SVM PROB 0  SVM PROB 1  KNN PROB 0  KNN PROB 1  NB PROB 0  \\\n",
       "0         1.jpg    0.633238    0.366762    0.714286    0.285714   0.710887   \n",
       "1     10000.jpg    0.713027    0.286973    0.666667    0.333333   0.828080   \n",
       "2      1001.jpg    0.633238    0.366762    0.714286    0.285714   0.710887   \n",
       "3     10016.jpg    0.633238    0.366762    0.714286    0.285714   0.710887   \n",
       "4     10028.jpg    0.715659    0.284341    0.476190    0.523810   0.832299   \n",
       "...         ...         ...         ...         ...         ...        ...   \n",
       "9995   9958.jpg    0.743568    0.256432    0.476190    0.523810   0.999757   \n",
       "9996   9984.jpg    0.626514    0.373486    0.619048    0.380952   0.709288   \n",
       "9997   9988.jpg    0.713976    0.286024    0.476190    0.523810   0.830421   \n",
       "9998   9989.jpg    0.695625    0.304375    0.666667    0.333333   0.802770   \n",
       "9999   9993.jpg    0.594650    0.405350    0.666667    0.333333   0.739494   \n",
       "\n",
       "      NB PROB 1  DT PROB 0  DT PROB 1  MLP PROB 0  MLP PROB 1  ground_truth  \\\n",
       "0      0.289113   0.691209   0.308791    0.690120    0.309880             0   \n",
       "1      0.171920   0.629571   0.370429    0.655799    0.344201             0   \n",
       "2      0.289113   0.691209   0.308791    0.690120    0.309880             1   \n",
       "3      0.289113   0.691209   0.308791    0.690120    0.309880             1   \n",
       "4      0.167701   0.629571   0.370429    0.653258    0.346742             0   \n",
       "...         ...        ...        ...         ...         ...           ...   \n",
       "9995   0.000243   0.626108   0.373892    0.615198    0.384802             1   \n",
       "9996   0.290712   0.686821   0.313179    0.677944    0.322056             1   \n",
       "9997   0.169579   0.626108   0.373892    0.649404    0.350596             0   \n",
       "9998   0.197230   0.686821   0.313179    0.662517    0.337483             0   \n",
       "9999   0.260506   0.686821   0.313179    0.590239    0.409761             0   \n",
       "\n",
       "      BMA PROB 0  BMA PROB 1  BMA LABELS  \n",
       "0       0.671682    0.328318           0  \n",
       "1       0.682752    0.317248           0  \n",
       "2       0.671682    0.328318           0  \n",
       "3       0.671682    0.328318           0  \n",
       "4       0.644988    0.355012           0  \n",
       "...          ...         ...         ...  \n",
       "9995    0.677800    0.322200           0  \n",
       "9996    0.648380    0.351620           0  \n",
       "9997    0.644020    0.355980           0  \n",
       "9998    0.688271    0.311729           0  \n",
       "9999    0.639531    0.360469           0  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_tags_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################  BMA #############################\n",
      "ACC BMA  [0.773, 0.775, 0.782, 0.789, 0.783, 0.799, 0.796, 0.8, 0.785, 0.792]\n",
      "ACC BMA  0.7874000000000001\n",
      "AUC BMA  [0.8813344865141904, 0.8739714075307375, 0.8804380870093921, 0.8840915374721008, 0.8749639976958525, 0.8883928571428571, 0.8908551739041696, 0.8972635890543562, 0.8848428672316385, 0.8945901462090177]\n",
      "AUC BMA  0.8850744149764311\n",
      "precision class 1 of k fold BMA  0.8080861990887079\n",
      "precision class 0 of kfold BMA  0.7697252896680618\n",
      "prec  0.7889057443783849\n",
      "recall class 1 k fold BMA 0.7543516584288692\n",
      "recall class 0 k fold BMA  0.8207297072476964\n",
      "rec  0.7875406828382828\n",
      "f1 pos BMA  0.7799568084346458\n",
      "f1 neg BMA  0.7941178980455632\n",
      "f1  0.7870373532401045\n"
     ]
    }
   ],
   "source": [
    "predictions_bma = []\n",
    "auc_bma_list = []\n",
    "acc_bma_list = []\n",
    "rec_pos = []\n",
    "rec_neg = []\n",
    "prec_pos = []\n",
    "prec_neg = []\n",
    "f1_pos = []\n",
    "f1_neg = []\n",
    "verit_assoluta = []\n",
    "\n",
    "y_test_complete = []\n",
    "labels_bma_complete=[]\n",
    "\n",
    "labels_bma = []\n",
    "sum_prob0_bma =[]\n",
    "sum_prob1_bma =[]\n",
    "y_prob_auc = []\n",
    "predictions_bma = []\n",
    "tp_bma = []\n",
    "tn_bma = []\n",
    "fn_bma = []\n",
    "fp_bma = []\n",
    "auc_bma_list = []\n",
    "acc_bma_list = []\n",
    "y_test = probs_tags_train[\"ground_truth\"]\n",
    "for j in range(0, 10):\n",
    "    y_test = probs_tags_train.loc[j*1000:((j*1000) + 1000)-1,\"ground_truth\"]\n",
    "    labels_bma = []\n",
    "    y_prob_auc = []\n",
    "    for i in range(j*1000, ((j*1000) + 1000)):\n",
    "        tags_prob0 = (probs_tags_train[\"SVM PROB 0\"][i]* score_tags_train[\"SCORE 0 SVM\"][j]) + (probs_tags_train[\"KNN PROB 0\"][i]* score_tags_train[\"SCORE 0 KNN\"][j])+ (probs_tags_train[\"NB PROB 0\"][i]* score_tags_train[\"SCORE 0 NB\"][j]) +  (probs_tags_train[\"DT PROB 0\"][i]* score_tags_train[\"SCORE 0 DT\"][j]) +  (probs_tags_train[\"MLP PROB 0\"][i]* score_tags_train[\"SCORE 0 MLP\"][j])\n",
    "        text_prob0 = (probs_text_train[\"SVM PROB 0\"][i]* score_text_train[\"SCORE 0 SVM\"][j]) + (probs_text_train[\"KNN PROB 0\"][i]* score_text_train[\"SCORE 0 KNN\"][j])+ (probs_text_train[\"NB PROB 0\"][i]* score_text_train[\"SCORE 0 NB\"][j]) +  (probs_text_train[\"DT PROB 0\"][i]* score_text_train[\"SCORE 0 DT\"][j]) +  (probs_text_train[\"MLP PROB 0\"][i]* score_text_train[\"SCORE 0 MLP\"][j]) \n",
    "        caps_prob0 = (probs_caps_train[\"SVM PROB 0\"][i]* score_caps_train[\"SCORE 0 SVM\"][j]) + (probs_caps_train[\"KNN PROB 0\"][i]* score_caps_train[\"SCORE 0 KNN\"][j])+ (probs_caps_train[\"NB PROB 0\"][i]* score_caps_train[\"SCORE 0 NB\"][j]) +  (probs_caps_train[\"DT PROB 0\"][i]* score_caps_train[\"SCORE 0 DT\"][j]) +  (probs_caps_train[\"MLP PROB 0\"][i]* score_caps_train[\"SCORE 0 MLP\"][j]) \n",
    "        tags_prob1 = (probs_tags_train[\"SVM PROB 1\"][i]* score_tags_train[\"SCORE 1 SVM\"][j]) + (probs_tags_train[\"KNN PROB 1\"][i]* score_tags_train[\"SCORE 1 KNN\"][j])+ (probs_tags_train[\"NB PROB 1\"][i]* score_tags_train[\"SCORE 1 NB\"][j]) +  (probs_tags_train[\"DT PROB 1\"][i]* score_tags_train[\"SCORE 1 DT\"][j]) +  (probs_tags_train[\"MLP PROB 1\"][i]* score_tags_train[\"SCORE 1 MLP\"][j])\n",
    "        text_prob1 = (probs_text_train[\"SVM PROB 1\"][i]* score_text_train[\"SCORE 1 SVM\"][j]) + (probs_text_train[\"KNN PROB 1\"][i]* score_text_train[\"SCORE 1 KNN\"][j])+ (probs_text_train[\"NB PROB 1\"][i]* score_text_train[\"SCORE 1 NB\"][j]) +  (probs_text_train[\"DT PROB 1\"][i]* score_text_train[\"SCORE 1 DT\"][j]) +  (probs_text_train[\"MLP PROB 1\"][i]* score_text_train[\"SCORE 1 MLP\"][j]) \n",
    "        caps_prob1 = (probs_caps_train[\"SVM PROB 1\"][i]* score_caps_train[\"SCORE 1 SVM\"][j]) + (probs_caps_train[\"KNN PROB 1\"][i]* score_caps_train[\"SCORE 1 KNN\"][j])+ (probs_caps_train[\"NB PROB 1\"][i]* score_caps_train[\"SCORE 1 NB\"][j]) +  (probs_caps_train[\"DT PROB 1\"][i]* score_caps_train[\"SCORE 1 DT\"][j]) +  (probs_caps_train[\"MLP PROB 1\"][i]* score_caps_train[\"SCORE 1 MLP\"][j]) \n",
    "        \n",
    "        marginale_1_ = tags_prob1 + text_prob1 + caps_prob1\n",
    "        marginale_0_ = tags_prob0 + text_prob0 + caps_prob0\n",
    "        \n",
    "        label_norm_0, label_norm_1 = evaluation_metrics.normalize(marginale_0_,marginale_1_)\n",
    "        sum_prob0_bma.append(label_norm_0)\n",
    "        sum_prob1_bma.append(label_norm_1)\n",
    "\n",
    "        y_prob_auc.append(marginale_1_)\n",
    "        if label_norm_0 > label_norm_1:\n",
    "          labels_bma.append(0)\n",
    "        else:\n",
    "          labels_bma.append(1)\n",
    "\n",
    "    results = evaluation_metrics.compute_evaluation_metrics(y_test, labels_bma)\n",
    "\n",
    "    rec_pos.append(results['recall'][0]) \n",
    "    rec_neg.append(results['recall'][1]) \n",
    "    f1_pos.append(results['f1'][0])   \n",
    "    f1_neg.append(results['f1'][1])\n",
    "    prec_pos.append( results['precision'][0])\n",
    "    prec_neg.append(results['precision'][1])\n",
    "    \n",
    "    fpr_bma, tpr_bma, thresholds_bma = roc_curve(y_test, y_prob_auc)\n",
    "    roc_auc_bma = auc(fpr_bma, tpr_bma)\n",
    "\n",
    "    auc_bma_list.append(roc_auc_bma)\n",
    "    acc_bma = accuracy_score(y_test,labels_bma)\n",
    "    acc_bma_list.append(acc_bma)\n",
    "    predictions_bma.append(labels_bma)\n",
    "    verit_assoluta.append(y_test)\n",
    "\n",
    "verit_assoluta = [item for sublist in verit_assoluta for item in sublist]\n",
    "predictions_bma = [item for sublist in predictions_bma for item in sublist]\n",
    "\n",
    "\n",
    "print(\"################  BMA #############################\")\n",
    "print(\"ACC BMA \", acc_bma_list)\n",
    "print(\"ACC BMA \", sum(acc_bma_list)/10)\n",
    "print(\"AUC BMA \", auc_bma_list)\n",
    "print(\"AUC BMA \", sum(auc_bma_list)/10)\n",
    "\n",
    "print(\"precision class 1 of k fold BMA \", mean(prec_pos))\n",
    "print(\"precision class 0 of kfold BMA \", mean(prec_neg))\n",
    "print(\"prec \", mean([mean(prec_pos), mean(prec_neg)]))\n",
    "\n",
    "print(\"recall class 1 k fold BMA\", mean(rec_pos))\n",
    "print(\"recall class 0 k fold BMA \", mean(rec_neg))\n",
    "print(\"rec \", mean([mean(rec_pos),mean(rec_neg)]))\n",
    "\n",
    "print(\"f1 pos BMA \", mean(f1_pos))\n",
    "print(\"f1 neg BMA \", mean(f1_neg))\n",
    "print(\"f1 \", mean([ mean(f1_pos), mean(f1_neg)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_train = list(probs_caps_train[\"file_name\"])\n",
    "ground_truth_train = list(probs_caps_train[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs0_caps_svm = probs_caps_train[\"SVM PROB 0\"]\n",
    "probs0_caps_knn = probs_caps_train[\"KNN PROB 0\"]\n",
    "probs0_caps_mlp = probs_caps_train[\"MLP PROB 0\"]\n",
    "probs0_caps_dtr = probs_caps_train[\"DT PROB 0\"]\n",
    "probs0_caps_nb  = probs_caps_train[\"NB PROB 0\"]\n",
    "\n",
    "probs1_caps_svm = probs_caps_train[\"SVM PROB 1\"]\n",
    "probs1_caps_knn = probs_caps_train[\"KNN PROB 1\"]\n",
    "probs1_caps_mlp = probs_caps_train[\"MLP PROB 1\"]\n",
    "probs1_caps_dtr = probs_caps_train[\"DT PROB 1\"]\n",
    "probs1_caps_nb  = probs_caps_train[\"NB PROB 1\"]\n",
    "\n",
    "\n",
    "probs0_text_svm = probs_text_train[\"SVM PROB 0\"]\n",
    "probs0_text_knn = probs_text_train[\"KNN PROB 0\"]\n",
    "probs0_text_mlp = probs_text_train[\"MLP PROB 0\"]\n",
    "probs0_text_dtr = probs_text_train[\"DT PROB 0\"]\n",
    "probs0_text_nb  = probs_text_train[\"NB PROB 0\"]\n",
    "\n",
    "probs1_text_svm = probs_text_train[\"SVM PROB 1\"]\n",
    "probs1_text_knn = probs_text_train[\"KNN PROB 1\"]\n",
    "probs1_text_mlp = probs_text_train[\"MLP PROB 1\"]\n",
    "probs1_text_dtr = probs_text_train[\"DT PROB 1\"]\n",
    "probs1_text_nb  = probs_text_train[\"NB PROB 1\"]\n",
    "\n",
    "\n",
    "\n",
    "probs0_tags_svm = probs_tags_train[\"SVM PROB 0\"]\n",
    "probs0_tags_knn = probs_tags_train[\"KNN PROB 0\"]\n",
    "probs0_tags_mlp = probs_tags_train[\"MLP PROB 0\"]\n",
    "probs0_tags_dtr = probs_tags_train[\"DT PROB 0\"]\n",
    "probs0_tags_nb  = probs_tags_train[\"NB PROB 0\"]\n",
    "\n",
    "probs1_tags_svm = probs_tags_train[\"SVM PROB 1\"]\n",
    "probs1_tags_knn = probs_tags_train[\"KNN PROB 1\"]\n",
    "probs1_tags_mlp = probs_tags_train[\"MLP PROB 1\"]\n",
    "probs1_tags_dtr = probs_tags_train[\"DT PROB 1\"]\n",
    "probs1_tags_nb  = probs_tags_train[\"NB PROB 1\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = {\"file_name\": file_names_train,\n",
    "         \"CAPS SVM PROB 0\": [item for item in probs0_caps_svm], \n",
    "         \"CAPS SVM PROB 1\": [item for item in probs1_caps_svm], \n",
    "         \"CAPS KNN PROB 0\": [item for item in probs0_caps_knn], \n",
    "         \"CAPS KNN PROB 1\": [item for item in probs1_caps_knn],\n",
    "         \"CAPS NB PROB 0\":  [item for item in probs0_caps_nb ],\n",
    "         \"CAPS NB PROB 1\":  [item for item in probs1_caps_nb ], \n",
    "         \"CAPS DT PROB 0\":  [item for item in probs0_caps_dtr],\n",
    "         \"CAPS DT PROB 1\":  [item for item in probs1_caps_dtr], \n",
    "         \"CAPS MLP PROB 0\": [item for item in probs0_caps_mlp],\n",
    "         \"CAPS MLP PROB 1\": [item for item in probs1_caps_mlp], \n",
    "         \"TAGS SVM PROB 0\": [item for item in probs0_tags_svm], \n",
    "         \"TAGS SVM PROB 1\": [item for item in probs1_tags_svm], \n",
    "         \"TAGS KNN PROB 0\": [item for item in probs0_tags_knn], \n",
    "         \"TAGS KNN PROB 1\": [item for item in probs1_tags_knn],\n",
    "         \"TAGS NB PROB 0\": [item for item in  probs0_tags_nb ],\n",
    "         \"TAGS NB PROB 1\": [item for item in  probs1_tags_nb ], \n",
    "         \"TAGS DT PROB 0\": [item for item in  probs0_tags_dtr],\n",
    "         \"TAGS DT PROB 1\": [item for item in  probs1_tags_dtr], \n",
    "         \"TAGS MLP PROB 0\": [item for item in probs0_tags_mlp],\n",
    "         \"TAGS MLP PROB 1\": [item for item in probs1_tags_mlp],\n",
    "         \"TEXT SVM PROB 0\": [item for item in probs0_text_svm], \n",
    "         \"TEXT SVM PROB 1\": [item for item in probs1_text_svm], \n",
    "         \"TEXT KNN PROB 0\": [item for item in probs0_text_knn], \n",
    "         \"TEXT KNN PROB 1\": [item for item in probs1_text_knn],\n",
    "         \"TEXT NB PROB 0\":  [item for item in probs0_text_nb ],\n",
    "         \"TEXT NB PROB 1\":  [item for item in probs1_text_nb ], \n",
    "         \"TEXT DT PROB 0\":  [item for item in probs0_text_dtr],\n",
    "         \"TEXT DT PROB 1\":  [item for item in probs1_text_dtr], \n",
    "         \"TEXT MLP PROB 0\": [item for item in probs0_text_mlp],\n",
    "         \"TEXT MLP PROB 1\": [item for item in probs1_text_mlp],\n",
    "         \"BMA PROB 0\": [item for item in sum_prob0_bma],\n",
    "         \"BMA PROB 1\": [item for item in sum_prob1_bma],\n",
    "         \"LABELS BMA\": [item for item in predictions_bma],\n",
    "         \"GROUND TRUTH\": ground_truth_train\n",
    "}\n",
    "data_probs_train_clfs = pd.DataFrame(probs_train)\n",
    "#nome_df_test = \"../data/results/BMA/CLFS_PROBS_BMATOT_train_str1.csv\"\n",
    "#data_probs_train_clfs.to_csv(nome_df_test, sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>CAPS SVM PROB 0</th>\n",
       "      <th>CAPS SVM PROB 1</th>\n",
       "      <th>CAPS KNN PROB 0</th>\n",
       "      <th>CAPS KNN PROB 1</th>\n",
       "      <th>CAPS NB PROB 0</th>\n",
       "      <th>CAPS NB PROB 1</th>\n",
       "      <th>CAPS DT PROB 0</th>\n",
       "      <th>CAPS DT PROB 1</th>\n",
       "      <th>CAPS MLP PROB 0</th>\n",
       "      <th>...</th>\n",
       "      <th>TEXT NB PROB 0</th>\n",
       "      <th>TEXT NB PROB 1</th>\n",
       "      <th>TEXT DT PROB 0</th>\n",
       "      <th>TEXT DT PROB 1</th>\n",
       "      <th>TEXT MLP PROB 0</th>\n",
       "      <th>TEXT MLP PROB 1</th>\n",
       "      <th>BMA PROB 0</th>\n",
       "      <th>BMA PROB 1</th>\n",
       "      <th>LABELS BMA</th>\n",
       "      <th>GROUND TRUTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15236.jpg</td>\n",
       "      <td>0.503872</td>\n",
       "      <td>0.496128</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.899648</td>\n",
       "      <td>0.100352</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.557434</td>\n",
       "      <td>...</td>\n",
       "      <td>9.251713e-04</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.425820</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0.485906</td>\n",
       "      <td>0.514094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15805.jpg</td>\n",
       "      <td>0.473416</td>\n",
       "      <td>0.526584</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.565247</td>\n",
       "      <td>0.434753</td>\n",
       "      <td>0.211009</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.432492</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979839e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.293337</td>\n",
       "      <td>0.706663</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16254.jpg</td>\n",
       "      <td>0.629930</td>\n",
       "      <td>0.370070</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.714585</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>...</td>\n",
       "      <td>3.591371e-05</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.391828</td>\n",
       "      <td>0.608172</td>\n",
       "      <td>0.519430</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16191.jpg</td>\n",
       "      <td>0.629930</td>\n",
       "      <td>0.370070</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.714585</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027040e-04</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.978092</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.502859</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15952.jpg</td>\n",
       "      <td>0.375635</td>\n",
       "      <td>0.624365</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.380597</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.287094</td>\n",
       "      <td>...</td>\n",
       "      <td>2.705271e-05</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.984533</td>\n",
       "      <td>0.176870</td>\n",
       "      <td>0.823130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15591.jpg</td>\n",
       "      <td>0.393038</td>\n",
       "      <td>0.606962</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.753545</td>\n",
       "      <td>0.246455</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.514474</td>\n",
       "      <td>...</td>\n",
       "      <td>5.086814e-06</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.354227</td>\n",
       "      <td>0.645773</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.996024</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15049.jpg</td>\n",
       "      <td>0.672930</td>\n",
       "      <td>0.327070</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.771015</td>\n",
       "      <td>0.228985</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.675185</td>\n",
       "      <td>...</td>\n",
       "      <td>8.677676e-05</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.354227</td>\n",
       "      <td>0.645773</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.509327</td>\n",
       "      <td>0.490673</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15363.jpg</td>\n",
       "      <td>0.262229</td>\n",
       "      <td>0.737771</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.110043</td>\n",
       "      <td>0.889957</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.171866</td>\n",
       "      <td>...</td>\n",
       "      <td>3.999350e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.975723</td>\n",
       "      <td>0.137136</td>\n",
       "      <td>0.862864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15199.jpg</td>\n",
       "      <td>0.562285</td>\n",
       "      <td>0.437715</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.708706</td>\n",
       "      <td>0.291294</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.578598</td>\n",
       "      <td>...</td>\n",
       "      <td>1.605313e-04</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.354227</td>\n",
       "      <td>0.645773</td>\n",
       "      <td>0.392976</td>\n",
       "      <td>0.607024</td>\n",
       "      <td>0.479704</td>\n",
       "      <td>0.520296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15853.jpg</td>\n",
       "      <td>0.714045</td>\n",
       "      <td>0.285955</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.832722</td>\n",
       "      <td>0.167278</td>\n",
       "      <td>0.625271</td>\n",
       "      <td>0.374729</td>\n",
       "      <td>0.647502</td>\n",
       "      <td>...</td>\n",
       "      <td>9.992943e-01</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.699591</td>\n",
       "      <td>0.300409</td>\n",
       "      <td>0.804085</td>\n",
       "      <td>0.195915</td>\n",
       "      <td>0.697634</td>\n",
       "      <td>0.302366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  CAPS SVM PROB 0  CAPS SVM PROB 1  CAPS KNN PROB 0  \\\n",
       "0     15236.jpg         0.503872         0.496128         0.666667   \n",
       "1     15805.jpg         0.473416         0.526584         0.380952   \n",
       "2     16254.jpg         0.629930         0.370070         0.619048   \n",
       "3     16191.jpg         0.629930         0.370070         0.619048   \n",
       "4     15952.jpg         0.375635         0.624365         0.095238   \n",
       "...         ...              ...              ...              ...   \n",
       "9995  15591.jpg         0.393038         0.606962         0.666667   \n",
       "9996  15049.jpg         0.672930         0.327070         0.809524   \n",
       "9997  15363.jpg         0.262229         0.737771         0.142857   \n",
       "9998  15199.jpg         0.562285         0.437715         0.619048   \n",
       "9999  15853.jpg         0.714045         0.285955         0.571429   \n",
       "\n",
       "      CAPS KNN PROB 1  CAPS NB PROB 0  CAPS NB PROB 1  CAPS DT PROB 0  \\\n",
       "0            0.333333        0.899648        0.100352        0.480000   \n",
       "1            0.619048        0.565247        0.434753        0.211009   \n",
       "2            0.380952        0.714585        0.285415        0.687672   \n",
       "3            0.380952        0.714585        0.285415        0.687672   \n",
       "4            0.904762        0.001154        0.998846        0.380597   \n",
       "...               ...             ...             ...             ...   \n",
       "9995         0.333333        0.753545        0.246455        0.480000   \n",
       "9996         0.190476        0.771015        0.228985        0.687672   \n",
       "9997         0.857143        0.110043        0.889957        0.135458   \n",
       "9998         0.380952        0.708706        0.291294        0.480000   \n",
       "9999         0.428571        0.832722        0.167278        0.625271   \n",
       "\n",
       "      CAPS DT PROB 1  CAPS MLP PROB 0  ...  TEXT NB PROB 0  TEXT NB PROB 1  \\\n",
       "0           0.520000         0.557434  ...    9.251713e-04        0.999075   \n",
       "1           0.788991         0.432492  ...    3.979839e-09        1.000000   \n",
       "2           0.312328         0.694881  ...    3.591371e-05        0.999964   \n",
       "3           0.312328         0.694881  ...    1.027040e-04        0.999897   \n",
       "4           0.619403         0.287094  ...    2.705271e-05        0.999973   \n",
       "...              ...              ...  ...             ...             ...   \n",
       "9995        0.520000         0.514474  ...    5.086814e-06        0.999995   \n",
       "9996        0.312328         0.675185  ...    8.677676e-05        0.999913   \n",
       "9997        0.864542         0.171866  ...    3.999350e-11        1.000000   \n",
       "9998        0.520000         0.578598  ...    1.605313e-04        0.999839   \n",
       "9999        0.374729         0.647502  ...    9.992943e-01        0.000706   \n",
       "\n",
       "      TEXT DT PROB 0  TEXT DT PROB 1  TEXT MLP PROB 0  TEXT MLP PROB 1  \\\n",
       "0           0.209445        0.790555         0.425820         0.574180   \n",
       "1           0.209445        0.790555         0.007644         0.992356   \n",
       "2           0.209445        0.790555         0.391828         0.608172   \n",
       "3           0.209445        0.790555         0.021908         0.978092   \n",
       "4           0.209445        0.790555         0.015467         0.984533   \n",
       "...              ...             ...              ...              ...   \n",
       "9995        0.354227        0.645773         0.003976         0.996024   \n",
       "9996        0.354227        0.645773         0.000842         0.999158   \n",
       "9997        0.209445        0.790555         0.024277         0.975723   \n",
       "9998        0.354227        0.645773         0.392976         0.607024   \n",
       "9999        0.699591        0.300409         0.804085         0.195915   \n",
       "\n",
       "      BMA PROB 0  BMA PROB 1  LABELS BMA  GROUND TRUTH  \n",
       "0       0.485906    0.514094           1             0  \n",
       "1       0.293337    0.706663           1             1  \n",
       "2       0.519430    0.480570           0             0  \n",
       "3       0.497141    0.502859           1             1  \n",
       "4       0.176870    0.823130           1             0  \n",
       "...          ...         ...         ...           ...  \n",
       "9995    0.405714    0.594286           1             1  \n",
       "9996    0.509327    0.490673           0             0  \n",
       "9997    0.137136    0.862864           1             1  \n",
       "9998    0.479704    0.520296           1             0  \n",
       "9999    0.697634    0.302366           0             0  \n",
       "\n",
       "[10000 rows x 35 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_probs_train_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>SVM PROB 0</th>\n",
       "      <th>SVM PROB 1</th>\n",
       "      <th>KNN PROB 0</th>\n",
       "      <th>KNN PROB 1</th>\n",
       "      <th>NB PROB 0</th>\n",
       "      <th>NB PROB 1</th>\n",
       "      <th>DT PROB 0</th>\n",
       "      <th>DT PROB 1</th>\n",
       "      <th>MLP PROB 0</th>\n",
       "      <th>MLP PROB 1</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15236.jpg</td>\n",
       "      <td>0.503857</td>\n",
       "      <td>0.496143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.899648</td>\n",
       "      <td>0.100352</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.537219</td>\n",
       "      <td>0.462781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15805.jpg</td>\n",
       "      <td>0.473409</td>\n",
       "      <td>0.526591</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.565247</td>\n",
       "      <td>0.434753</td>\n",
       "      <td>0.211009</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.410655</td>\n",
       "      <td>0.589345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16254.jpg</td>\n",
       "      <td>0.630062</td>\n",
       "      <td>0.369938</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714585</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.688542</td>\n",
       "      <td>0.311458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16191.jpg</td>\n",
       "      <td>0.630062</td>\n",
       "      <td>0.369938</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714585</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.688542</td>\n",
       "      <td>0.311458</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15952.jpg</td>\n",
       "      <td>0.375702</td>\n",
       "      <td>0.624298</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.380597</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.271065</td>\n",
       "      <td>0.728935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15591.jpg</td>\n",
       "      <td>0.393418</td>\n",
       "      <td>0.606582</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.753545</td>\n",
       "      <td>0.246455</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.517790</td>\n",
       "      <td>0.482210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15049.jpg</td>\n",
       "      <td>0.672992</td>\n",
       "      <td>0.327008</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.771015</td>\n",
       "      <td>0.228985</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.681949</td>\n",
       "      <td>0.318051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15363.jpg</td>\n",
       "      <td>0.262760</td>\n",
       "      <td>0.737240</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.110043</td>\n",
       "      <td>0.889957</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.820704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15199.jpg</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>0.437400</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.708706</td>\n",
       "      <td>0.291294</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.588976</td>\n",
       "      <td>0.411024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15853.jpg</td>\n",
       "      <td>0.713967</td>\n",
       "      <td>0.286033</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.832722</td>\n",
       "      <td>0.167278</td>\n",
       "      <td>0.625271</td>\n",
       "      <td>0.374729</td>\n",
       "      <td>0.655379</td>\n",
       "      <td>0.344621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  SVM PROB 0  SVM PROB 1  KNN PROB 0  KNN PROB 1  NB PROB 0  \\\n",
       "0     15236.jpg    0.503857    0.496143    0.666667    0.333333   0.899648   \n",
       "1     15805.jpg    0.473409    0.526591    0.380952    0.619048   0.565247   \n",
       "2     16254.jpg    0.630062    0.369938    0.666667    0.333333   0.714585   \n",
       "3     16191.jpg    0.630062    0.369938    0.666667    0.333333   0.714585   \n",
       "4     15952.jpg    0.375702    0.624298    0.095238    0.904762   0.001154   \n",
       "...         ...         ...         ...         ...         ...        ...   \n",
       "9995  15591.jpg    0.393418    0.606582    0.666667    0.333333   0.753545   \n",
       "9996  15049.jpg    0.672992    0.327008    0.809524    0.190476   0.771015   \n",
       "9997  15363.jpg    0.262760    0.737240    0.142857    0.857143   0.110043   \n",
       "9998  15199.jpg    0.562600    0.437400    0.619048    0.380952   0.708706   \n",
       "9999  15853.jpg    0.713967    0.286033    0.571429    0.428571   0.832722   \n",
       "\n",
       "      NB PROB 1  DT PROB 0  DT PROB 1  MLP PROB 0  MLP PROB 1  ground_truth  \n",
       "0      0.100352   0.480000   0.520000    0.537219    0.462781             0  \n",
       "1      0.434753   0.211009   0.788991    0.410655    0.589345             1  \n",
       "2      0.285415   0.687672   0.312328    0.688542    0.311458             0  \n",
       "3      0.285415   0.687672   0.312328    0.688542    0.311458             1  \n",
       "4      0.998846   0.380597   0.619403    0.271065    0.728935             0  \n",
       "...         ...        ...        ...         ...         ...           ...  \n",
       "9995   0.246455   0.480000   0.520000    0.517790    0.482210             1  \n",
       "9996   0.228985   0.687672   0.312328    0.681949    0.318051             0  \n",
       "9997   0.889957   0.135458   0.864542    0.179296    0.820704             1  \n",
       "9998   0.291294   0.480000   0.520000    0.588976    0.411024             0  \n",
       "9999   0.167278   0.625271   0.374729    0.655379    0.344621             0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_tags_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs0_caps_train = probs_caps_train[\"BMA PROB 0\"]\n",
    "probs0_text_train = probs_text_train[\"BMA PROB 0\"]\n",
    "probs0_tags_train = probs_tags_train[\"BMA PROB 0\"]\n",
    "\n",
    "probs1_caps_train = probs_caps_train[\"BMA PROB 1\"]\n",
    "probs1_text_train = probs_text_train[\"BMA PROB 1\"]\n",
    "probs1_tags_train = probs_tags_train[\"BMA PROB 1\"]\n",
    "\n",
    "\n",
    "probs_train_bma = {\"file_name\": [item for item in file_names_train],\n",
    "         \"CAPS PROB 0\": [item for item in probs0_caps_train], \n",
    "         \"CAPS PROB 1\": [item for item in probs1_caps_train], \n",
    "         \"TEXT PROB 0\": [item for item in probs0_text_train], \n",
    "         \"TEXT PROB 1\": [item for item in probs1_text_train],\n",
    "         \"TAGS PROB 0\": [item for item in probs0_tags_train],\n",
    "         \"TAGS PROB 1\": [item for item in probs1_tags_train], \n",
    "         \"BMA PROB 0\": [item for item in sum_prob0_bma],\n",
    "         \"BMA PROB 1\": [item for item in sum_prob1_bma],\n",
    "         \"LABELS BMA\": [item for item in predictions_bma],\n",
    "         \"GROUND TRUTH\": [item for item in ground_truth_train]\n",
    "}\n",
    "\n",
    "probs_train_bma = pd.DataFrame(probs_train)\n",
    "#nome_df_test = \"../data/results/BMA/singoli_BMA_PROBS_train_str1.csv\"\n",
    "#probs_train_bma.to_csv(nome_df_test, sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>CAPS SVM PROB 0</th>\n",
       "      <th>CAPS SVM PROB 1</th>\n",
       "      <th>CAPS KNN PROB 0</th>\n",
       "      <th>CAPS KNN PROB 1</th>\n",
       "      <th>CAPS NB PROB 0</th>\n",
       "      <th>CAPS NB PROB 1</th>\n",
       "      <th>CAPS DT PROB 0</th>\n",
       "      <th>CAPS DT PROB 1</th>\n",
       "      <th>CAPS MLP PROB 0</th>\n",
       "      <th>...</th>\n",
       "      <th>TEXT NB PROB 0</th>\n",
       "      <th>TEXT NB PROB 1</th>\n",
       "      <th>TEXT DT PROB 0</th>\n",
       "      <th>TEXT DT PROB 1</th>\n",
       "      <th>TEXT MLP PROB 0</th>\n",
       "      <th>TEXT MLP PROB 1</th>\n",
       "      <th>BMA PROB 0</th>\n",
       "      <th>BMA PROB 1</th>\n",
       "      <th>LABELS BMA</th>\n",
       "      <th>GROUND TRUTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15236.jpg</td>\n",
       "      <td>0.503872</td>\n",
       "      <td>0.496128</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.899648</td>\n",
       "      <td>0.100352</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.557434</td>\n",
       "      <td>...</td>\n",
       "      <td>9.251713e-04</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.425820</td>\n",
       "      <td>0.574180</td>\n",
       "      <td>0.485906</td>\n",
       "      <td>0.514094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15805.jpg</td>\n",
       "      <td>0.473416</td>\n",
       "      <td>0.526584</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.565247</td>\n",
       "      <td>0.434753</td>\n",
       "      <td>0.211009</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.432492</td>\n",
       "      <td>...</td>\n",
       "      <td>3.979839e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.293337</td>\n",
       "      <td>0.706663</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16254.jpg</td>\n",
       "      <td>0.629930</td>\n",
       "      <td>0.370070</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.714585</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>...</td>\n",
       "      <td>3.591371e-05</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.391828</td>\n",
       "      <td>0.608172</td>\n",
       "      <td>0.519430</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16191.jpg</td>\n",
       "      <td>0.629930</td>\n",
       "      <td>0.370070</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.714585</td>\n",
       "      <td>0.285415</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027040e-04</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.021908</td>\n",
       "      <td>0.978092</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.502859</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15952.jpg</td>\n",
       "      <td>0.375635</td>\n",
       "      <td>0.624365</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.998846</td>\n",
       "      <td>0.380597</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.287094</td>\n",
       "      <td>...</td>\n",
       "      <td>2.705271e-05</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.984533</td>\n",
       "      <td>0.176870</td>\n",
       "      <td>0.823130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15591.jpg</td>\n",
       "      <td>0.393038</td>\n",
       "      <td>0.606962</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.753545</td>\n",
       "      <td>0.246455</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.514474</td>\n",
       "      <td>...</td>\n",
       "      <td>5.086814e-06</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.354227</td>\n",
       "      <td>0.645773</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.996024</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15049.jpg</td>\n",
       "      <td>0.672930</td>\n",
       "      <td>0.327070</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.771015</td>\n",
       "      <td>0.228985</td>\n",
       "      <td>0.687672</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>0.675185</td>\n",
       "      <td>...</td>\n",
       "      <td>8.677676e-05</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.354227</td>\n",
       "      <td>0.645773</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.999158</td>\n",
       "      <td>0.509327</td>\n",
       "      <td>0.490673</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15363.jpg</td>\n",
       "      <td>0.262229</td>\n",
       "      <td>0.737771</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.110043</td>\n",
       "      <td>0.889957</td>\n",
       "      <td>0.135458</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.171866</td>\n",
       "      <td>...</td>\n",
       "      <td>3.999350e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.975723</td>\n",
       "      <td>0.137136</td>\n",
       "      <td>0.862864</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15199.jpg</td>\n",
       "      <td>0.562285</td>\n",
       "      <td>0.437715</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.708706</td>\n",
       "      <td>0.291294</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.578598</td>\n",
       "      <td>...</td>\n",
       "      <td>1.605313e-04</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.354227</td>\n",
       "      <td>0.645773</td>\n",
       "      <td>0.392976</td>\n",
       "      <td>0.607024</td>\n",
       "      <td>0.479704</td>\n",
       "      <td>0.520296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15853.jpg</td>\n",
       "      <td>0.714045</td>\n",
       "      <td>0.285955</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.832722</td>\n",
       "      <td>0.167278</td>\n",
       "      <td>0.625271</td>\n",
       "      <td>0.374729</td>\n",
       "      <td>0.647502</td>\n",
       "      <td>...</td>\n",
       "      <td>9.992943e-01</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.699591</td>\n",
       "      <td>0.300409</td>\n",
       "      <td>0.804085</td>\n",
       "      <td>0.195915</td>\n",
       "      <td>0.697634</td>\n",
       "      <td>0.302366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  CAPS SVM PROB 0  CAPS SVM PROB 1  CAPS KNN PROB 0  \\\n",
       "0     15236.jpg         0.503872         0.496128         0.666667   \n",
       "1     15805.jpg         0.473416         0.526584         0.380952   \n",
       "2     16254.jpg         0.629930         0.370070         0.619048   \n",
       "3     16191.jpg         0.629930         0.370070         0.619048   \n",
       "4     15952.jpg         0.375635         0.624365         0.095238   \n",
       "...         ...              ...              ...              ...   \n",
       "9995  15591.jpg         0.393038         0.606962         0.666667   \n",
       "9996  15049.jpg         0.672930         0.327070         0.809524   \n",
       "9997  15363.jpg         0.262229         0.737771         0.142857   \n",
       "9998  15199.jpg         0.562285         0.437715         0.619048   \n",
       "9999  15853.jpg         0.714045         0.285955         0.571429   \n",
       "\n",
       "      CAPS KNN PROB 1  CAPS NB PROB 0  CAPS NB PROB 1  CAPS DT PROB 0  \\\n",
       "0            0.333333        0.899648        0.100352        0.480000   \n",
       "1            0.619048        0.565247        0.434753        0.211009   \n",
       "2            0.380952        0.714585        0.285415        0.687672   \n",
       "3            0.380952        0.714585        0.285415        0.687672   \n",
       "4            0.904762        0.001154        0.998846        0.380597   \n",
       "...               ...             ...             ...             ...   \n",
       "9995         0.333333        0.753545        0.246455        0.480000   \n",
       "9996         0.190476        0.771015        0.228985        0.687672   \n",
       "9997         0.857143        0.110043        0.889957        0.135458   \n",
       "9998         0.380952        0.708706        0.291294        0.480000   \n",
       "9999         0.428571        0.832722        0.167278        0.625271   \n",
       "\n",
       "      CAPS DT PROB 1  CAPS MLP PROB 0  ...  TEXT NB PROB 0  TEXT NB PROB 1  \\\n",
       "0           0.520000         0.557434  ...    9.251713e-04        0.999075   \n",
       "1           0.788991         0.432492  ...    3.979839e-09        1.000000   \n",
       "2           0.312328         0.694881  ...    3.591371e-05        0.999964   \n",
       "3           0.312328         0.694881  ...    1.027040e-04        0.999897   \n",
       "4           0.619403         0.287094  ...    2.705271e-05        0.999973   \n",
       "...              ...              ...  ...             ...             ...   \n",
       "9995        0.520000         0.514474  ...    5.086814e-06        0.999995   \n",
       "9996        0.312328         0.675185  ...    8.677676e-05        0.999913   \n",
       "9997        0.864542         0.171866  ...    3.999350e-11        1.000000   \n",
       "9998        0.520000         0.578598  ...    1.605313e-04        0.999839   \n",
       "9999        0.374729         0.647502  ...    9.992943e-01        0.000706   \n",
       "\n",
       "      TEXT DT PROB 0  TEXT DT PROB 1  TEXT MLP PROB 0  TEXT MLP PROB 1  \\\n",
       "0           0.209445        0.790555         0.425820         0.574180   \n",
       "1           0.209445        0.790555         0.007644         0.992356   \n",
       "2           0.209445        0.790555         0.391828         0.608172   \n",
       "3           0.209445        0.790555         0.021908         0.978092   \n",
       "4           0.209445        0.790555         0.015467         0.984533   \n",
       "...              ...             ...              ...              ...   \n",
       "9995        0.354227        0.645773         0.003976         0.996024   \n",
       "9996        0.354227        0.645773         0.000842         0.999158   \n",
       "9997        0.209445        0.790555         0.024277         0.975723   \n",
       "9998        0.354227        0.645773         0.392976         0.607024   \n",
       "9999        0.699591        0.300409         0.804085         0.195915   \n",
       "\n",
       "      BMA PROB 0  BMA PROB 1  LABELS BMA  GROUND TRUTH  \n",
       "0       0.485906    0.514094           1             0  \n",
       "1       0.293337    0.706663           1             1  \n",
       "2       0.519430    0.480570           0             0  \n",
       "3       0.497141    0.502859           1             1  \n",
       "4       0.176870    0.823130           1             0  \n",
       "...          ...         ...         ...           ...  \n",
       "9995    0.405714    0.594286           1             1  \n",
       "9996    0.509327    0.490673           0             0  \n",
       "9997    0.137136    0.862864           1             1  \n",
       "9998    0.479704    0.520296           1             0  \n",
       "9999    0.697634    0.302366           0             0  \n",
       "\n",
       "[10000 rows x 35 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_train_bma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_probs_train = pd.DataFrame(probs_train)\n",
    "nome_df = \"BMA_probs-train-1902.csv\"\n",
    "data_probs_train.to_csv(nome_df, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "prec_bma = mean([prec_notmis_bma,prec_mis_bma])\n",
    "rec_bma = mean([rec_neg_bma, rec_pos_bma])\n",
    "f1_bma = mean([f1_0_bma, f1_1_bma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measures</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>NB</th>\n",
       "      <th>DT</th>\n",
       "      <th>MLP</th>\n",
       "      <th>BMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prec pos</td>\n",
       "      <td>0.604436</td>\n",
       "      <td>0.597496</td>\n",
       "      <td>0.604436</td>\n",
       "      <td>0.592150</td>\n",
       "      <td>0.601521</td>\n",
       "      <td>0.599009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prec neg</td>\n",
       "      <td>0.623094</td>\n",
       "      <td>0.623583</td>\n",
       "      <td>0.623094</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.625140</td>\n",
       "      <td>0.628651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rec pos</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.664200</td>\n",
       "      <td>0.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rec neg</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1 pos</td>\n",
       "      <td>0.628242</td>\n",
       "      <td>0.630784</td>\n",
       "      <td>0.628242</td>\n",
       "      <td>0.639042</td>\n",
       "      <td>0.631309</td>\n",
       "      <td>0.635621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1 neg</td>\n",
       "      <td>0.596455</td>\n",
       "      <td>0.584485</td>\n",
       "      <td>0.596455</td>\n",
       "      <td>0.571116</td>\n",
       "      <td>0.590780</td>\n",
       "      <td>0.584875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACC</td>\n",
       "      <td>0.628877</td>\n",
       "      <td>0.642589</td>\n",
       "      <td>0.609668</td>\n",
       "      <td>0.641744</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>0.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.613000</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.612100</td>\n",
       "      <td>0.639748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measures       SVM       KNN        NB        DT       MLP       BMA\n",
       "0  Prec pos  0.604436  0.597496  0.604436  0.592150  0.601521  0.599009\n",
       "1  Prec neg  0.623094  0.623583  0.623094  0.630435  0.625140  0.628651\n",
       "2   Rec pos  0.654000  0.668000  0.654000  0.694000  0.664200  0.677000\n",
       "3   Rec neg  0.572000  0.550000  0.572000  0.522000  0.560000  0.546800\n",
       "4    F1 pos  0.628242  0.630784  0.628242  0.639042  0.631309  0.635621\n",
       "5    F1 neg  0.596455  0.584485  0.596455  0.571116  0.590780  0.584875\n",
       "6       ACC  0.628877  0.642589  0.609668  0.641744  0.659600  0.611900\n",
       "7       AUC  0.607500  0.609000  0.613000  0.608000  0.612100  0.639748"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ris_tags_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train = {\"Modelli\": [\"TAGS\", \"TEXT\", \"CAPS\", \"BMA\"],\n",
    "        \"Prec 0\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Prec neg\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"Prec neg\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Prec neg\",\"BMA\"].values[0], prec_notmis_bma],\n",
    "       \"Prec 1\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Prec pos\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"Prec pos\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Prec pos\",\"BMA\"].values[0], prec_mis_bma],\n",
    "       \"Prec\": [(ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Prec neg\",\"BMA\"].values[0]+ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Prec pos\",\"BMA\"].values[0])/2, \n",
    "                (ris_text_train.loc[ris_text_train[\"measures\"]==\"Prec neg\",\"BMA\"].values[0]+ris_text_train.loc[ris_text_train[\"measures\"]==\"Prec pos\",\"BMA\"].values[0])/2, \n",
    "                (ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Prec neg\",\"BMA\"].values[0]+ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Prec pos\",\"BMA\"].values[0])/2, prec_bma],\n",
    "       \"Rec 0\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Rec neg\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"Rec neg\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Rec neg\",\"BMA\"].values[0], rec_neg_bma],\n",
    "       \"Rec 1\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Rec pos\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"Rec pos\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Rec pos\",\"BMA\"].values[0], rec_pos_bma],\n",
    "       \"Rec\": [(ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Rec neg\",\"BMA\"].values[0]+ris_tags_train.loc[ris_tags_train[\"measures\"]==\"Rec pos\",\"BMA\"].values[0])/2, \n",
    "                (ris_text_train.loc[ris_text_train[\"measures\"]==\"Rec neg\",\"BMA\"].values[0]+ris_text_train.loc[ris_text_train[\"measures\"]==\"Rec pos\",\"BMA\"].values[0])/2, \n",
    "                (ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Rec neg\",\"BMA\"].values[0]+ris_caps_train.loc[ris_caps_train[\"measures\"]==\"Rec pos\",\"BMA\"].values[0])/2,rec_bma],\n",
    "       \"F1 0\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"F1 neg\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"F1 neg\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"F1 neg\",\"BMA\"].values[0], f1_0_bma],\n",
    "       \"F1 1\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"F1 pos\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"F1 pos\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"F1 pos\",\"BMA\"].values[0], f1_1_bma], \n",
    "       \"F1\": [(ris_tags_train.loc[ris_tags_train[\"measures\"]==\"F1 neg\",\"BMA\"].values[0]+ris_tags_train.loc[ris_tags_train[\"measures\"]==\"F1 pos\",\"BMA\"].values[0])/2, \n",
    "                (ris_text_train.loc[ris_text_train[\"measures\"]==\"F1 neg\",\"BMA\"].values[0]+ris_text_train.loc[ris_text_train[\"measures\"]==\"F1 pos\",\"BMA\"].values[0])/2, \n",
    "                (ris_caps_train.loc[ris_caps_train[\"measures\"]==\"F1 neg\",\"BMA\"].values[0]+ris_caps_train.loc[ris_caps_train[\"measures\"]==\"F1 pos\",\"BMA\"].values[0])/2, f1_bma], \n",
    "       \"ACC\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"ACC\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"ACC\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"ACC\",\"BMA\"].values[0], acc_bma],\n",
    "       \"AUC\": [ris_tags_train.loc[ris_tags_train[\"measures\"]==\"AUC\",\"BMA\"].values[0], \n",
    "                ris_text_train.loc[ris_text_train[\"measures\"]==\"AUC\",\"BMA\"].values[0], \n",
    "                ris_caps_train.loc[ris_caps_train[\"measures\"]==\"AUC\",\"BMA\"].values[0], roc_auc_bma]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.628651</td>\n",
       "      <td>0.599009</td>\n",
       "      <td>0.613830</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.584875</td>\n",
       "      <td>0.635621</td>\n",
       "      <td>0.610248</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.639748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.621689</td>\n",
       "      <td>0.582461</td>\n",
       "      <td>0.602075</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.555579</td>\n",
       "      <td>0.633517</td>\n",
       "      <td>0.594548</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.652702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.705366</td>\n",
       "      <td>0.625386</td>\n",
       "      <td>0.665376</td>\n",
       "      <td>0.5348</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.608345</td>\n",
       "      <td>0.692834</td>\n",
       "      <td>0.650590</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.730442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.693851</td>\n",
       "      <td>0.620740</td>\n",
       "      <td>0.657295</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.6488</td>\n",
       "      <td>0.602625</td>\n",
       "      <td>0.685361</td>\n",
       "      <td>0.643993</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.731856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli    Prec 0    Prec 1      Prec   Rec 0   Rec 1     Rec      F1 0  \\\n",
       "0    TAGS  0.628651  0.599009  0.613830  0.5468  0.6770  0.6119  0.584875   \n",
       "1    TEXT  0.621689  0.582461  0.602075  0.5022  0.6944  0.5983  0.555579   \n",
       "2    CAPS  0.705366  0.625386  0.665376  0.5348  0.7766  0.6557  0.608345   \n",
       "3     BMA  0.693851  0.620740  0.657295  0.5326  0.7650  0.6488  0.602625   \n",
       "\n",
       "       F1 1        F1     ACC       AUC  \n",
       "0  0.635621  0.610248  0.6119  0.639748  \n",
       "1  0.633517  0.594548  0.5983  0.652702  \n",
       "2  0.692834  0.650590  0.6557  0.730442  \n",
       "3  0.685361  0.643993  0.6460  0.731856  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_train = pd.DataFrame(res_train)\n",
    "risultati_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "risultati_train.iloc[:,1:] = risultati_train.iloc[:,1:].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.5849</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.6397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.5983</td>\n",
       "      <td>0.6527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.7054</td>\n",
       "      <td>0.6254</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.5348</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6083</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.6506</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.6488</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.7319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli  Prec 0  Prec 1    Prec   Rec 0   Rec 1     Rec    F1 0    F1 1  \\\n",
       "0    TAGS  0.6287  0.5990  0.6138  0.5468  0.6770  0.6119  0.5849  0.6356   \n",
       "1    TEXT  0.6217  0.5825  0.6021  0.5022  0.6944  0.5983  0.5556  0.6335   \n",
       "2    CAPS  0.7054  0.6254  0.6654  0.5348  0.7766  0.6557  0.6083  0.6928   \n",
       "3     BMA  0.6939  0.6207  0.6573  0.5326  0.7650  0.6488  0.6026  0.6854   \n",
       "\n",
       "       F1     ACC     AUC  \n",
       "0  0.6102  0.6119  0.6397  \n",
       "1  0.5945  0.5983  0.6527  \n",
       "2  0.6506  0.6557  0.7304  \n",
       "3  0.6440  0.6460  0.7319  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "risultati_train.to_csv(\"../data/results/BMA/BMA_RESULTS-train-10-03.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/results2strategy/text/test/score_test_text10fold.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7698/1778079976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore_text_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/results2strategy/text/test/score_test_text10fold.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore_caps_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/results2strategy/caps/test/score_test_caps10fold.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscore_tags_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/results2strategy/tags/test/score_test_tags10fold.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bma_text/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/results2strategy/text/test/score_test_text10fold.csv'"
     ]
    }
   ],
   "source": [
    "score_text_test = pd.read_csv(\"../data/results2strategy/text/test/score_test_text10fold.csv\", sep=\"\\t\")\n",
    "score_caps_test = pd.read_csv(\"../data/results2strategy/caps/test/score_test_caps10fold.csv\", sep=\"\\t\")\n",
    "score_tags_test = pd.read_csv(\"../data/results2strategy/tags/test/score_test_tags10fold.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FOLD</th>\n",
       "      <th>SCORE 0 SVM</th>\n",
       "      <th>SCORE 1 SVM</th>\n",
       "      <th>SCORE 0 KNN</th>\n",
       "      <th>SCORE 1 KNN</th>\n",
       "      <th>SCORE 0 NB</th>\n",
       "      <th>SCORE 1 NB</th>\n",
       "      <th>SCORE 0 DT</th>\n",
       "      <th>SCORE 1 DT</th>\n",
       "      <th>SCORE 0 MLP</th>\n",
       "      <th>SCORE 1 MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777320</td>\n",
       "      <td>0.790291</td>\n",
       "      <td>0.755853</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>0.766798</td>\n",
       "      <td>0.761134</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.684266</td>\n",
       "      <td>0.797949</td>\n",
       "      <td>0.807805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776269</td>\n",
       "      <td>0.778717</td>\n",
       "      <td>0.748066</td>\n",
       "      <td>0.791781</td>\n",
       "      <td>0.755898</td>\n",
       "      <td>0.736349</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.686101</td>\n",
       "      <td>0.791792</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.773351</td>\n",
       "      <td>0.775307</td>\n",
       "      <td>0.744665</td>\n",
       "      <td>0.788544</td>\n",
       "      <td>0.758245</td>\n",
       "      <td>0.737574</td>\n",
       "      <td>0.711490</td>\n",
       "      <td>0.677260</td>\n",
       "      <td>0.784497</td>\n",
       "      <td>0.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.776424</td>\n",
       "      <td>0.774064</td>\n",
       "      <td>0.745077</td>\n",
       "      <td>0.785451</td>\n",
       "      <td>0.758226</td>\n",
       "      <td>0.733579</td>\n",
       "      <td>0.702612</td>\n",
       "      <td>0.675725</td>\n",
       "      <td>0.786584</td>\n",
       "      <td>0.783899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.777095</td>\n",
       "      <td>0.772865</td>\n",
       "      <td>0.749783</td>\n",
       "      <td>0.786509</td>\n",
       "      <td>0.759542</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.701727</td>\n",
       "      <td>0.675574</td>\n",
       "      <td>0.789349</td>\n",
       "      <td>0.783367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.780030</td>\n",
       "      <td>0.774911</td>\n",
       "      <td>0.750679</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.761859</td>\n",
       "      <td>0.738370</td>\n",
       "      <td>0.702668</td>\n",
       "      <td>0.679820</td>\n",
       "      <td>0.792014</td>\n",
       "      <td>0.784174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.776909</td>\n",
       "      <td>0.774795</td>\n",
       "      <td>0.749495</td>\n",
       "      <td>0.787158</td>\n",
       "      <td>0.762193</td>\n",
       "      <td>0.742449</td>\n",
       "      <td>0.701464</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>0.790895</td>\n",
       "      <td>0.786488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.778620</td>\n",
       "      <td>0.776116</td>\n",
       "      <td>0.754001</td>\n",
       "      <td>0.789706</td>\n",
       "      <td>0.764678</td>\n",
       "      <td>0.745578</td>\n",
       "      <td>0.706066</td>\n",
       "      <td>0.681173</td>\n",
       "      <td>0.790807</td>\n",
       "      <td>0.785886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.776272</td>\n",
       "      <td>0.776172</td>\n",
       "      <td>0.751362</td>\n",
       "      <td>0.789285</td>\n",
       "      <td>0.760009</td>\n",
       "      <td>0.743914</td>\n",
       "      <td>0.704460</td>\n",
       "      <td>0.680615</td>\n",
       "      <td>0.788415</td>\n",
       "      <td>0.786241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.779607</td>\n",
       "      <td>0.778591</td>\n",
       "      <td>0.756381</td>\n",
       "      <td>0.792180</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.745987</td>\n",
       "      <td>0.709566</td>\n",
       "      <td>0.684606</td>\n",
       "      <td>0.791816</td>\n",
       "      <td>0.788965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  FOLD  SCORE 0 SVM  SCORE 1 SVM  SCORE 0 KNN  SCORE 1 KNN  \\\n",
       "0           0     1     0.777320     0.790291     0.755853     0.801451   \n",
       "1           1     2     0.776269     0.778717     0.748066     0.791781   \n",
       "2           2     3     0.773351     0.775307     0.744665     0.788544   \n",
       "3           3     4     0.776424     0.774064     0.745077     0.785451   \n",
       "4           4     5     0.777095     0.772865     0.749783     0.786509   \n",
       "5           5     6     0.780030     0.774911     0.750679     0.787402   \n",
       "6           6     7     0.776909     0.774795     0.749495     0.787158   \n",
       "7           7     8     0.778620     0.776116     0.754001     0.789706   \n",
       "8           8     9     0.776272     0.776172     0.751362     0.789285   \n",
       "9           9    10     0.779607     0.778591     0.756381     0.792180   \n",
       "\n",
       "   SCORE 0 NB  SCORE 1 NB  SCORE 0 DT  SCORE 1 DT  SCORE 0 MLP  SCORE 1 MLP  \n",
       "0    0.766798    0.761134    0.716049    0.684266     0.797949     0.807805  \n",
       "1    0.755898    0.736349    0.709957    0.686101     0.791792     0.792208  \n",
       "2    0.758245    0.737574    0.711490    0.677260     0.784497     0.785500  \n",
       "3    0.758226    0.733579    0.702612    0.675725     0.786584     0.783899  \n",
       "4    0.759542    0.735294    0.701727    0.675574     0.789349     0.783367  \n",
       "5    0.761859    0.738370    0.702668    0.679820     0.792014     0.784174  \n",
       "6    0.762193    0.742449    0.701464    0.680083     0.790895     0.786488  \n",
       "7    0.764678    0.745578    0.706066    0.681173     0.790807     0.785886  \n",
       "8    0.760009    0.743914    0.704460    0.680615     0.788415     0.786241  \n",
       "9    0.762835    0.745987    0.709566    0.684606     0.791816     0.788965  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 sklearn  0.6656429562116108\n",
      "prec sklearn  0.7008912265322522\n",
      "rec_sklearn 0.6759999999999999\n",
      "f1 1 mio  0.7244897959183673\n",
      "f1 media mio  0.6656429562116108\n",
      "prec mio  0.6301775147928994\n",
      "rec mio 0.852\n",
      "prec media mio  0.7008912265322522\n",
      "rec media  mio 0.6759999999999999\n",
      "Accuracy: 67.60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[250 250]\n",
      " [ 74 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.61       500\n",
      "           1       0.63      0.85      0.72       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.761092\n",
      "ACC BMA  0.676\n",
      "AUC BMA  0.7610920000000001\n",
      "AUC SCORE  0.7610920000000001\n",
      "f1 sklearn  0.6718069896906371\n",
      "prec sklearn  0.699968005119181\n",
      "rec_sklearn 0.6799999999999999\n",
      "f1 1 mio  0.7236614853195165\n",
      "f1 media mio  0.6718069896906371\n",
      "prec mio  0.6367781155015197\n",
      "rec mio 0.838\n",
      "prec media mio  0.699968005119181\n",
      "rec media  mio 0.6799999999999999\n",
      "Accuracy: 68.00\n",
      "\n",
      "Confusion Matrix:\n",
      " [[261 239]\n",
      " [ 81 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62       500\n",
      "           1       0.64      0.84      0.72       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.762360\n",
      "ACC BMA  0.68\n",
      "AUC BMA  0.76236\n",
      "AUC SCORE  0.76236\n",
      "f1 sklearn  0.6749887989041894\n",
      "prec sklearn  0.7030166273945977\n",
      "rec_sklearn 0.683\n",
      "f1 1 mio  0.7260155574762315\n",
      "f1 media mio  0.6749887989041894\n",
      "prec mio  0.639269406392694\n",
      "rec mio 0.84\n",
      "prec media mio  0.7030166273945977\n",
      "rec media  mio 0.683\n",
      "Accuracy: 68.30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[263 237]\n",
      " [ 80 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.53      0.62       500\n",
      "           1       0.64      0.84      0.73       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.760756\n",
      "ACC BMA  0.683\n",
      "AUC BMA  0.760756\n",
      "AUC SCORE  0.760756\n",
      "f1 sklearn  0.6656760390531534\n",
      "prec sklearn  0.6969735852794323\n",
      "rec_sklearn 0.675\n",
      "f1 1 mio  0.7215081405312768\n",
      "f1 media mio  0.6656760390531534\n",
      "prec mio  0.631184407796102\n",
      "rec mio 0.842\n",
      "prec media mio  0.6969735852794323\n",
      "rec media  mio 0.675\n",
      "Accuracy: 67.50\n",
      "\n",
      "Confusion Matrix:\n",
      " [[254 246]\n",
      " [ 79 421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.51      0.61       500\n",
      "           1       0.63      0.84      0.72       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.760388\n",
      "ACC BMA  0.675\n",
      "AUC BMA  0.760388\n",
      "AUC SCORE  0.760388\n",
      "f1 sklearn  0.6738581960050706\n",
      "prec sklearn  0.7021898718427274\n",
      "rec_sklearn 0.6819999999999999\n",
      "f1 1 mio  0.7253886010362693\n",
      "f1 media mio  0.6738581960050706\n",
      "prec mio  0.6382978723404256\n",
      "rec mio 0.84\n",
      "prec media mio  0.7021898718427274\n",
      "rec media  mio 0.6819999999999999\n",
      "Accuracy: 68.20\n",
      "\n",
      "Confusion Matrix:\n",
      " [[262 238]\n",
      " [ 80 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.52      0.62       500\n",
      "           1       0.64      0.84      0.73       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.759752\n",
      "ACC BMA  0.682\n",
      "AUC BMA  0.7597519999999999\n",
      "AUC SCORE  0.7597519999999999\n",
      "f1 sklearn  0.6713911485754962\n",
      "prec sklearn  0.7049746556199294\n",
      "rec_sklearn 0.681\n",
      "f1 1 mio  0.7275832621690864\n",
      "f1 media mio  0.6713911485754962\n",
      "prec mio  0.6348733233979136\n",
      "rec mio 0.852\n",
      "prec media mio  0.7049746556199294\n",
      "rec media  mio 0.681\n",
      "Accuracy: 68.10\n",
      "\n",
      "Confusion Matrix:\n",
      " [[255 245]\n",
      " [ 74 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62       500\n",
      "           1       0.63      0.85      0.73       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.760696\n",
      "ACC BMA  0.681\n",
      "AUC BMA  0.760696\n",
      "AUC SCORE  0.760696\n",
      "f1 sklearn  0.6677334172743647\n",
      "prec sklearn  0.6992247119683401\n",
      "rec_sklearn 0.677\n",
      "f1 1 mio  0.7232219365895458\n",
      "f1 media mio  0.6677334172743647\n",
      "prec mio  0.6326836581709145\n",
      "rec mio 0.844\n",
      "prec media mio  0.6992247119683401\n",
      "rec media  mio 0.677\n",
      "Accuracy: 67.70\n",
      "\n",
      "Confusion Matrix:\n",
      " [[255 245]\n",
      " [ 78 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.51      0.61       500\n",
      "           1       0.63      0.84      0.72       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.758112\n",
      "ACC BMA  0.677\n",
      "AUC BMA  0.7581119999999999\n",
      "AUC SCORE  0.7581119999999999\n",
      "f1 sklearn  0.6677334172743647\n",
      "prec sklearn  0.6992247119683401\n",
      "rec_sklearn 0.677\n",
      "f1 1 mio  0.7232219365895458\n",
      "f1 media mio  0.6677334172743647\n",
      "prec mio  0.6326836581709145\n",
      "rec mio 0.844\n",
      "prec media mio  0.6992247119683401\n",
      "rec media  mio 0.677\n",
      "Accuracy: 67.70\n",
      "\n",
      "Confusion Matrix:\n",
      " [[255 245]\n",
      " [ 78 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.51      0.61       500\n",
      "           1       0.63      0.84      0.72       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.760160\n",
      "ACC BMA  0.677\n",
      "AUC BMA  0.76016\n",
      "AUC SCORE  0.76016\n",
      "f1 sklearn  0.6677334172743647\n",
      "prec sklearn  0.6992247119683401\n",
      "rec_sklearn 0.677\n",
      "f1 1 mio  0.7232219365895458\n",
      "f1 media mio  0.6677334172743647\n",
      "prec mio  0.6326836581709145\n",
      "rec mio 0.844\n",
      "prec media mio  0.6992247119683401\n",
      "rec media  mio 0.677\n",
      "Accuracy: 67.70\n",
      "\n",
      "Confusion Matrix:\n",
      " [[255 245]\n",
      " [ 78 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.51      0.61       500\n",
      "           1       0.63      0.84      0.72       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.70      0.68      0.67      1000\n",
      "weighted avg       0.70      0.68      0.67      1000\n",
      "\n",
      "Area under the ROC curve : 0.758684\n",
      "ACC BMA  0.677\n",
      "AUC BMA  0.758684\n",
      "AUC SCORE  0.758684\n",
      "f1 sklearn  0.664298218515086\n",
      "prec sklearn  0.6967435549525102\n",
      "rec_sklearn 0.6739999999999999\n",
      "f1 1 mio  0.7213675213675212\n",
      "f1 media mio  0.664298218515086\n",
      "prec mio  0.6298507462686567\n",
      "rec mio 0.844\n",
      "prec media mio  0.6967435549525102\n",
      "rec media  mio 0.6739999999999999\n",
      "Accuracy: 67.40\n",
      "\n",
      "Confusion Matrix:\n",
      " [[252 248]\n",
      " [ 78 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.50      0.61       500\n",
      "           1       0.63      0.84      0.72       500\n",
      "\n",
      "    accuracy                           0.67      1000\n",
      "   macro avg       0.70      0.67      0.66      1000\n",
      "weighted avg       0.70      0.67      0.66      1000\n",
      "\n",
      "Area under the ROC curve : 0.759464\n",
      "ACC BMA  0.674\n",
      "AUC BMA  0.7594640000000001\n",
      "AUC SCORE  0.7594640000000001\n",
      "[[2562 2438]\n",
      " [ 780 4220]]\n",
      "2562 2438 780 4220\n",
      "256 243 78 422\n",
      "################  BMA #############################\n",
      "ACC BMA  [0.676, 0.68, 0.683, 0.675, 0.682, 0.681, 0.677, 0.677, 0.677, 0.674]\n",
      "ACC BMA  0.6781999999999999\n",
      "AUC BMA  [0.7610920000000001, 0.76236, 0.760756, 0.760388, 0.7597519999999999, 0.760696, 0.7581119999999999, 0.76016, 0.758684, 0.7594640000000001]\n",
      "AUC BMA  0.7601464\n",
      "precision class 1 of k fold BMA  0.6338239711625112\n",
      "precision class 0 of kfold BMA  0.7666068222621185\n",
      "prec  0.7002153967123148\n",
      "recall class 1 k fold BMA 0.844\n",
      "recall class 0 k fold BMA  0.5124\n",
      "rec  0.6781999999999999\n",
      "f1 pos BMA  0.7239663750214445\n",
      "f1 neg BMA  0.6142411891632702\n",
      "f1  0.6691037820923573\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#y_bma_pred = []\n",
    "predictions_bma = []\n",
    "tp_bma = []\n",
    "tn_bma = []\n",
    "fn_bma = []\n",
    "fp_bma = []\n",
    "auc_bma_list = []\n",
    "acc_bma_list = []\n",
    "rec_pos = []\n",
    "rec_neg = []\n",
    "prec_pos = []\n",
    "prec_neg = []\n",
    "f1_pos = []\n",
    "f1_neg = []\n",
    "verit_assoluta = []\n",
    "for j in range(0, 10):\n",
    "    sum_prob0_bma =[]\n",
    "    sum_prob1_bma =[]\n",
    "    n_fold_tags = f\"../data/results2strategy/tags/test/probs_test_fold_{j+1}_tags.csv\"\n",
    "    n_fold_text = f\"../data/results2strategy/text/test/probs_test_{j+1}_text.csv\"\n",
    "    n_fold_caps = f\"../data/results2strategy/caps/test/probs_test_fold_{j+1}_caps.csv\"\n",
    "    #data_probs = pd.read_csv(n_fold, sep=\"\\t\")\n",
    "    probs_tags_test = pd.read_csv(n_fold_tags, sep=\"\\t\")\n",
    "    probs_text_test = pd.read_csv(n_fold_text, sep=\"\\t\")\n",
    "    probs_caps_test = pd.read_csv(n_fold_caps, sep=\"\\t\")\n",
    "    #probs_tags_test.sort_values(by=['file_name'], ascending=True, inplace=True)\n",
    "    #probs_text_test.sort_values(by=['file_name'], ascending=True, inplace=True)\n",
    "    #probs_caps_test.sort_values(by=['file_name'], ascending=True, inplace=True)\n",
    " \n",
    "    file_names_test = probs_tags_test[\"file_name\"]\n",
    "    y_test = probs_caps_test[\"GROUND TRUTH\"]\n",
    "    labels_bma = []\n",
    "    y_prob_auc = []\n",
    "    \n",
    "    for i in range(0,1000):\n",
    "        tags_prob0 = (probs_tags_test[\"SVM PROB 0\"][i]* score_tags_test[\"SCORE 0 SVM\"][j]) + (probs_tags_test[\"KNN PROB 0\"][i]* score_tags_test[\"SCORE 0 KNN\"][j])+ (probs_tags_test[\"NB PROB 0\"][i]* score_tags_test[\"SCORE 0 NB\"][j]) +  (probs_tags_test[\"DT PROB 0\"][i]* score_tags_test[\"SCORE 0 DT\"][j]) +  (probs_tags_test[\"MLP PROB 0\"][i]* score_tags_test[\"SCORE 0 MLP\"][j])\n",
    "        text_prob0 = (probs_text_test[\"SVM PROB 0\"][i]* score_text_test[\"SCORE 0 SVM\"][j]) + (probs_text_test[\"KNN PROB 0\"][i]* score_text_test[\"SCORE 0 KNN\"][j])+ (probs_text_test[\"NB PROB 0\"][i]* score_text_test[\"SCORE 0 NB\"][j]) +  (probs_text_test[\"DT PROB 0\"][i]* score_text_test[\"SCORE 0 DT\"][j]) +  (probs_text_test[\"MLP PROB 0\"][i]* score_text_test[\"SCORE 0 MLP\"][j])\n",
    "        caps_prob0 = (probs_caps_test[\"SVM PROB 0\"][i]* score_caps_test[\"SCORE 0 SVM\"][j]) + (probs_caps_test[\"KNN PROB 0\"][i]* score_caps_test[\"SCORE 0 KNN\"][j])+ (probs_caps_test[\"NB PROB 0\"][i]* score_caps_test[\"SCORE 0 NB\"][j]) +  (probs_caps_test[\"DT PROB 0\"][i]* score_caps_test[\"SCORE 0 DT\"][j]) +  (probs_caps_test[\"MLP PROB 0\"][i]* score_caps_test[\"SCORE 0 MLP\"][j])\n",
    "        tags_prob1 = (probs_tags_test[\"SVM PROB 1\"][i]* score_tags_test[\"SCORE 1 SVM\"][j]) + (probs_tags_test[\"KNN PROB 1\"][i]* score_tags_test[\"SCORE 1 KNN\"][j])+ (probs_tags_test[\"NB PROB 1\"][i]* score_tags_test[\"SCORE 1 NB\"][j]) +  (probs_tags_test[\"DT PROB 1\"][i]* score_tags_test[\"SCORE 1 DT\"][j]) +  (probs_tags_test[\"MLP PROB 1\"][i]* score_tags_test[\"SCORE 1 MLP\"][j])\n",
    "        text_prob1 = (probs_text_test[\"SVM PROB 1\"][i]* score_text_test[\"SCORE 1 SVM\"][j]) + (probs_text_test[\"KNN PROB 1\"][i]* score_text_test[\"SCORE 1 KNN\"][j])+ (probs_text_test[\"NB PROB 1\"][i]* score_text_test[\"SCORE 1 NB\"][j]) +  (probs_text_test[\"DT PROB 1\"][i]* score_text_test[\"SCORE 1 DT\"][j]) +  (probs_text_test[\"MLP PROB 1\"][i]* score_text_test[\"SCORE 1 MLP\"][j])\n",
    "        caps_prob1 = (probs_caps_test[\"SVM PROB 1\"][i]* score_caps_test[\"SCORE 1 SVM\"][j]) + (probs_caps_test[\"KNN PROB 1\"][i]* score_caps_test[\"SCORE 1 KNN\"][j])+ (probs_caps_test[\"NB PROB 1\"][i]* score_caps_test[\"SCORE 1 NB\"][j]) +  (probs_caps_test[\"DT PROB 1\"][i]* score_caps_test[\"SCORE 1 DT\"][j]) +  (probs_caps_test[\"MLP PROB 1\"][i]* score_caps_test[\"SCORE 1 MLP\"][j])\n",
    "        \n",
    "        marginale_1_ = tags_prob1 + text_prob1 + caps_prob1\n",
    "        marginale_0_ = tags_prob0 + text_prob0 + caps_prob0\n",
    "        \n",
    "        label_norm_0, label_norm_1 = normalize(marginale_0_,marginale_1_)\n",
    "        sum_prob0_bma.append(label_norm_0)\n",
    "        sum_prob1_bma.append(label_norm_1)\n",
    "        #y_neg = nb_probs_neg[i] + svm_probs_neg[i] +rf_probs_neg[i]\n",
    "        #y_pos = nb_probs_pos[i] +svm_probs_pos[i] +rf_probs_pos[i]\n",
    "        y_prob_auc.append(marginale_1_)\n",
    "        if label_norm_0 > label_norm_1:\n",
    "        #if probs_sum_0[i] > probs_sum_1[i]:\n",
    "          labels_bma.append(0)\n",
    "        else:\n",
    "          labels_bma.append(1)\n",
    "        #if y_neg > y_pos:\n",
    "        #  y_bma_pred.append(0)\n",
    "        #else:\n",
    "      #  y_bma_pred.append(1)\n",
    "##########################\n",
    " \n",
    "    \n",
    "    #probs_name = f'../data/results2strategy/tags/sintest/probs_sin_test_fold_{j+1}_tags.csv'\n",
    "    #data_probs.to_csv(probs_name, sep=\"\\t\")\n",
    "    tn_b, fp_b, fn_b, tp_b = confusion_matrix(y_test, labels_bma).ravel()\n",
    "    tp_bma.append(tp_b)\n",
    "    tn_bma.append(tn_b)\n",
    "    fn_bma.append(fn_b)\n",
    "    fp_bma.append(fp_b)\n",
    "    rec_pos_bm = tp_b/ (tp_b + fn_b) ###True postive rate recall classe 1\n",
    "    fn_rate_bm = fn_b/ (tp_b+ fn_b)\n",
    "    prec_mis_bm =  tp_b/ (tp_b + fp_b)\n",
    "    prec_notmis_bm = tn_b/ (tn_b + fn_b)\n",
    "    rec_neg_bm = tn_b / (tn_b+ fp_b)\n",
    "    f1_1_bm= (2* (prec_mis_bm * rec_pos_bm)) / (prec_mis_bm+ rec_pos_bm) \n",
    "    f1_0_bm = (2* (prec_notmis_bm * rec_neg_bm)) / (prec_notmis_bm + rec_neg_bm)\n",
    "    false_positive_rate_bma = fp_b / (fp_b+ tn_b)\n",
    "    rec_pos.append(rec_pos_bm) \n",
    "    rec_neg.append(rec_neg_bm) \n",
    "    f1_pos.append(f1_1_bm)   \n",
    "    f1_neg.append(f1_0_bm)\n",
    "    prec_pos.append(prec_mis_bm)\n",
    "    prec_neg.append(prec_notmis_bm)\n",
    "    \n",
    "    print(\"f1 sklearn \", f1_score(y_test, labels_bma, average=\"macro\"))\n",
    "    print(\"prec sklearn \",precision_score(y_test, labels_bma, average=\"macro\"))\n",
    "    print(\"rec_sklearn\", recall_score(y_test, labels_bma, average=\"macro\")) \n",
    "    \n",
    "    print(\"f1 1 mio \", f1_1_bm)\n",
    "    print(\"f1 media mio \", mean([f1_0_bm, f1_1_bm]))\n",
    "    print(\"prec mio \", prec_mis_bm)\n",
    "    print(\"rec mio\", rec_pos_bm) \n",
    "    print(\"prec media mio \", mean([prec_mis_bm, prec_notmis_bm]))\n",
    "    print(\"rec media  mio\", mean([rec_pos_bm, rec_neg_bm])) \n",
    "    fpr_bma, tpr_bma, thresholds_bma = roc_curve(y_test, y_prob_auc)\n",
    "    roc_auc_bma = auc(fpr_bma, tpr_bma)\n",
    "    \n",
    "    printResult(labels_bma, y_prob_auc, y_test)\n",
    "    auc_bma_list.append(roc_auc_bma)\n",
    "    acc_bma = accuracy_score(y_test,labels_bma)\n",
    "    print(\"ACC BMA \", acc_bma)\n",
    "    print(\"AUC BMA \", roc_auc_bma)\n",
    "    print(\"AUC SCORE \",metrics.roc_auc_score(y_test, y_prob_auc))\n",
    "    acc_bma_list.append(acc_bma)\n",
    "    predictions_bma.append(labels_bma)\n",
    "    verit_assoluta.append(y_test)\n",
    "\n",
    "    probs0_caps_svm = probs_caps_test[\"SVM PROB 0\"]\n",
    "    probs0_caps_knn = probs_caps_test[\"KNN PROB 0\"]\n",
    "    probs0_caps_mlp = probs_caps_test[\"MLP PROB 0\"]\n",
    "    probs0_caps_dtr = probs_caps_test[\"DT PROB 0\"]\n",
    "    probs0_caps_nb  = probs_caps_test[\"NB PROB 0\"]\n",
    "    probs1_caps_svm = probs_caps_test[\"SVM PROB 1\"]\n",
    "    probs1_caps_knn = probs_caps_test[\"KNN PROB 1\"]\n",
    "    probs1_caps_mlp = probs_caps_test[\"MLP PROB 1\"]\n",
    "    probs1_caps_dtr = probs_caps_test[\"DT PROB 1\"]\n",
    "    probs1_caps_nb  = probs_caps_test[\"NB PROB 1\"]\n",
    "    \n",
    "    probs0_text_svm = probs_text_test[\"SVM PROB 0\"]\n",
    "    probs0_text_knn = probs_text_test[\"KNN PROB 0\"]\n",
    "    probs0_text_mlp = probs_text_test[\"MLP PROB 0\"]\n",
    "    probs0_text_dtr = probs_text_test[\"DT PROB 0\"]\n",
    "    probs0_text_nb  = probs_text_test[\"NB PROB 0\"]\n",
    "    probs1_text_svm = probs_text_test[\"SVM PROB 1\"]\n",
    "    probs1_text_knn = probs_text_test[\"KNN PROB 1\"]\n",
    "    probs1_text_mlp = probs_text_test[\"MLP PROB 1\"]\n",
    "    probs1_text_dtr = probs_text_test[\"DT PROB 1\"]\n",
    "    probs1_text_nb  = probs_text_test[\"NB PROB 1\"]\n",
    "\n",
    "    probs0_tags_svm = probs_tags_test[\"SVM PROB 0\"]\n",
    "    probs0_tags_knn = probs_tags_test[\"KNN PROB 0\"]\n",
    "    probs0_tags_mlp = probs_tags_test[\"MLP PROB 0\"]\n",
    "    probs0_tags_dtr = probs_tags_test[\"DT PROB 0\"]\n",
    "    probs0_tags_nb  = probs_tags_test[\"NB PROB 0\"]\n",
    "    probs1_tags_svm = probs_tags_test[\"SVM PROB 1\"]\n",
    "    probs1_tags_knn = probs_tags_test[\"KNN PROB 1\"]\n",
    "    probs1_tags_mlp = probs_tags_test[\"MLP PROB 1\"]\n",
    "    probs1_tags_dtr = probs_tags_test[\"DT PROB 1\"]\n",
    "    probs1_tags_nb  = probs_tags_test[\"NB PROB 1\"]\n",
    "    \n",
    "    probs_test = {\"file_name\": file_names_test,\n",
    "         \"CAPS SVM PROB 0\": [item for item in probs0_caps_svm], \n",
    "         \"CAPS SVM PROB 1\": [item for item in probs1_caps_svm], \n",
    "         \"CAPS KNN PROB 0\": [item for item in probs0_caps_knn], \n",
    "         \"CAPS KNN PROB 1\": [item for item in probs1_caps_knn],\n",
    "         \"CAPS NB PROB 0\":  [item for item in probs0_caps_nb ],\n",
    "         \"CAPS NB PROB 1\":  [item for item in probs1_caps_nb ], \n",
    "         \"CAPS DT PROB 0\":  [item for item in probs0_caps_dtr],\n",
    "         \"CAPS DT PROB 1\":  [item for item in probs1_caps_dtr], \n",
    "         \"CAPS MLP PROB 0\": [item for item in probs0_caps_mlp],\n",
    "         \"CAPS MLP PROB 1\": [item for item in probs1_caps_mlp], \n",
    "         \"TAGS SVM PROB 0\": [item for item in probs0_tags_svm], \n",
    "         \"TAGS SVM PROB 1\": [item for item in probs1_tags_svm], \n",
    "         \"TAGS KNN PROB 0\": [item for item in probs0_tags_knn], \n",
    "         \"TAGS KNN PROB 1\": [item for item in probs1_tags_knn],\n",
    "         \"TAGS NB PROB 0\": [item for item in  probs0_tags_nb ],\n",
    "         \"TAGS NB PROB 1\": [item for item in  probs1_tags_nb ], \n",
    "         \"TAGS DT PROB 0\": [item for item in  probs0_tags_dtr],\n",
    "         \"TAGS DT PROB 1\": [item for item in  probs1_tags_dtr], \n",
    "         \"TAGS MLP PROB 0\": [item for item in probs0_tags_mlp],\n",
    "         \"TAGS MLP PROB 1\": [item for item in probs1_tags_mlp],\n",
    "         \"TEXT SVM PROB 0\": [item for item in probs0_text_svm], \n",
    "         \"TEXT SVM PROB 1\": [item for item in probs1_text_svm], \n",
    "         \"TEXT KNN PROB 0\": [item for item in probs0_text_knn], \n",
    "         \"TEXT KNN PROB 1\": [item for item in probs1_text_knn],\n",
    "         \"TEXT NB PROB 0\":  [item for item in probs0_text_nb ],\n",
    "         \"TEXT NB PROB 1\":  [item for item in probs1_text_nb ], \n",
    "         \"TEXT DT PROB 0\":  [item for item in probs0_text_dtr],\n",
    "         \"TEXT DT PROB 1\":  [item for item in probs1_text_dtr], \n",
    "         \"TEXT MLP PROB 0\": [item for item in probs0_text_mlp],\n",
    "         \"TEXT MLP PROB 1\": [item for item in probs1_text_mlp],\n",
    "         \"BMA PROB 0\": [item for item in sum_prob0_bma],\n",
    "         \"BMA PROB 1\": [item for item in sum_prob1_bma],\n",
    "         \"LABELS BMA\": [item for item in predictions_bma[0]],\n",
    "         \"GROUND TRUTH\": y_test\n",
    "      }\n",
    "    data_probs_test_clfs = pd.DataFrame(probs_test)\n",
    "    nome_df_test = f\"../data/results2strategy/bma/test/CLFS_PROBS_BMATOT_test_str2_fold_{j+1}.csv\"\n",
    "    data_probs_test_clfs.to_csv(nome_df_test, sep=\"\\t\")\n",
    "#print(\"PROBS POS PER AUC \", y_prob_auc)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_test, y_bma_pred).ravel()\n",
    "#print(tn,fp,fn,tp)\n",
    "#true_postives_bma.append(tp)\n",
    "#true_negatives_bma.append(tn)\n",
    "#false_negative_bma.append(fn)\n",
    "#false_positives_bma.append(fp)\n",
    "\n",
    "#auc_score_bma = roc_auc_score(y_test, y_prob_auc)\n",
    "verit_assoluta = [item for sublist in verit_assoluta for item in sublist]\n",
    "predictions_bma = [item for sublist in predictions_bma for item in sublist]\n",
    "print(confusion_matrix(verit_assoluta, predictions_bma ))\n",
    "tn, fp, fn, tp = confusion_matrix(verit_assoluta, predictions_bma).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "cm = confusion_matrix(verit_assoluta, predictions_bma)\n",
    "print(mean(tn_bma), mean(fp_bma), mean(fn_bma), mean(tp_bma))\n",
    "#print(\"################  BMA calcolo alternativo #############################\")\n",
    "rec_pos_bma = sum(tp_bma)/ (sum(tp_bma) + sum(fn_bma)) ###True postive rate recall classe 1\n",
    "fn_rate_bma = sum(fn_bma)/ (sum(tp_bma)+ sum(fn_bma))\n",
    "prec_mis_bma = sum(tp_bma)/ (sum(tp_bma) + sum(fp_bma))\n",
    "prec_notmis_bma = sum(tn_bma)/ (sum(tn_bma) + sum(fn_bma))\n",
    "rec_neg_bma = sum(tn_bma) / (sum(tn_bma)+ sum(fp_bma))\n",
    "false_positive_rate_bma = sum(fp_bma) / (sum(fp_bma)+ sum(tn_bma))\n",
    "f1_1_bma= (2* (prec_mis_bma * rec_pos_bma)) / (prec_mis_bma+ rec_pos_bma) \n",
    "f1_0_bma = (2* (prec_notmis_bma * rec_neg_bma)) / (prec_notmis_bma + rec_neg_bma)\n",
    "\n",
    "\n",
    "\n",
    "print(\"################  BMA #############################\")\n",
    "print(\"ACC BMA \", acc_bma_list)\n",
    "print(\"ACC BMA \", sum(acc_bma_list)/10)\n",
    "print(\"AUC BMA \", auc_bma_list)\n",
    "print(\"AUC BMA \", sum(auc_bma_list)/10)\n",
    "\n",
    "print(\"precision class 1 of k fold BMA \", prec_mis_bma)\n",
    "print(\"precision class 0 of kfold BMA \", prec_notmis_bma)\n",
    "print(\"prec \", mean([prec_mis_bma, prec_notmis_bma]))\n",
    "\n",
    "print(\"recall class 1 k fold BMA\", rec_pos_bma)\n",
    "print(\"recall class 0 k fold BMA \", rec_neg_bma)\n",
    "print(\"rec \", mean([rec_pos_bma, rec_neg_bma]))\n",
    "\n",
    "print(\"f1 pos BMA \", f1_1_bma)\n",
    "print(\"f1 neg BMA \", f1_0_bma)\n",
    "print(\"f1 \", mean([f1_0_bma, f1_1_bma]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'not misogynous'), Text(0, 1.5, 'misogynous')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "\n",
    "sns.heatmap([[mean(tn_bma), mean(fp_bma)],[ mean(fn_bma), mean(tp_bma)]], annot=True, fmt='g', cmap=\"Blues\", ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['not misogynous', 'misogynous']); ax.yaxis.set_ticklabels(['not misogynous', 'misogynous'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "prec_bma = mean([prec_notmis_bma,prec_mis_bma])\n",
    "rec_bma = mean([rec_neg_bma, rec_pos_bma])\n",
    "f1_bma = mean([f1_0_bma, f1_1_bma])\n",
    "acc_bma = sum(acc_bma_list)/10\n",
    "roc_auc_bma =  sum(auc_bma_list)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = {\"Modelli\": [\"TAGS\", \"TEXT\", \"CAPS\", \"BMA\"],\n",
    "        \"Prec 0\": [ris_tags_test[\"Prec 0\"][5], ris_text_test[\"Prec 0\"][5], ris_caps_test[\"Prec 0\"][5], prec_notmis_bma],\n",
    "       \"Prec 1\": [ris_tags_test[\"Prec 1\"][5], ris_text_test[\"Prec 1\"][5], ris_caps_test[\"Prec 1\"][5], prec_mis_bma],\n",
    "       \"Prec\": [ris_tags_test[\"Prec\"][5], ris_text_test[\"Prec\"][5], ris_caps_test[\"Prec\"][5], prec_bma],\n",
    "       \"Rec 0\": [ris_tags_test[\"Rec 0\"][5], ris_text_test[\"Rec 0\"][5], ris_caps_test[\"Rec 0\"][5], rec_neg_bma],\n",
    "       \"Rec 1\": [ris_tags_test[\"Rec 1\"][5], ris_text_test[\"Rec 1\"][5], ris_caps_test[\"Rec 1\"][5], rec_pos_bma],\n",
    "       \"Rec\": [ris_tags_test[\"Rec\"][5], ris_text_test[\"Rec\"][5], ris_caps_test[\"Rec\"][5],rec_bma],\n",
    "       \"F1 0\": [ris_tags_test[\"F1 0\"][5], ris_text_test[\"F1 0\"][5], ris_caps_test[\"F1 0\"][5], f1_0_bma],\n",
    "       \"F1 1\": [ris_tags_test[\"F1 1\"][5], ris_text_test[\"F1 1\"][5], ris_caps_test[\"F1 1\"][5], f1_1_bma], \n",
    "       \"F1\": [ris_tags_test[\"F1 \"][5], ris_text_test[\"F1 \"][5], ris_caps_test[\"F1 \"][5], f1_bma], \n",
    "       \"ACC\": [ris_tags_test[\"ACC\"][5], ris_text_test[\"ACC\"][5], ris_caps_test[\"ACC\"][5], acc_bma],\n",
    "       \"AUC\": [ris_tags_test[\"AUC\"][5], ris_text_test[\"AUC\"][5], ris_caps_test[\"AUC\"][5], roc_auc_bma]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.650800</td>\n",
       "      <td>0.609700</td>\n",
       "      <td>0.630300</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.624700</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.628800</td>\n",
       "      <td>0.671700</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.612600</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.606600</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.597800</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.614400</td>\n",
       "      <td>0.596200</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.766607</td>\n",
       "      <td>0.633824</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.614241</td>\n",
       "      <td>0.723966</td>\n",
       "      <td>0.669104</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.760146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli    Prec 0    Prec 1      Prec   Rec 0  Rec 1     Rec      F1 0  \\\n",
       "0    TAGS  0.650800  0.609700  0.630300  0.5480  0.706  0.6270  0.595000   \n",
       "1    TEXT  0.714700  0.628800  0.671700  0.5360  0.786  0.6610  0.612600   \n",
       "2    CAPS  0.606600  0.589000  0.597800  0.5520  0.642  0.5970  0.578000   \n",
       "3     BMA  0.766607  0.633824  0.700215  0.5124  0.844  0.6782  0.614241   \n",
       "\n",
       "       F1 1        F1     ACC       AUC  \n",
       "0  0.654300  0.624700  0.6270  0.687000  \n",
       "1  0.698700  0.655600  0.6610  0.733400  \n",
       "2  0.614400  0.596200  0.5970  0.643400  \n",
       "3  0.723966  0.669104  0.6782  0.760146  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_test = pd.DataFrame(res_test)\n",
    "risultati_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.6303</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.6543</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.6870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.7147</td>\n",
       "      <td>0.6288</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>0.6987</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.7334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.5978</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.6144</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.6434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.7601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli  Prec 0  Prec 1    Prec   Rec 0  Rec 1     Rec    F1 0    F1 1  \\\n",
       "0    TAGS  0.6508  0.6097  0.6303  0.5480  0.706  0.6270  0.5950  0.6543   \n",
       "1    TEXT  0.7147  0.6288  0.6717  0.5360  0.786  0.6610  0.6126  0.6987   \n",
       "2    CAPS  0.6066  0.5890  0.5978  0.5520  0.642  0.5970  0.5780  0.6144   \n",
       "3     BMA  0.7666  0.6338  0.7002  0.5124  0.844  0.6782  0.6142  0.7240   \n",
       "\n",
       "       F1     ACC     AUC  \n",
       "0  0.6247  0.6270  0.6870  \n",
       "1  0.6556  0.6610  0.7334  \n",
       "2  0.5962  0.5970  0.6434  \n",
       "3  0.6691  0.6782  0.7601  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_test.iloc[:,1:] = risultati_test.iloc[:,1:].round(4)\n",
    "risultati_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "risultati_test.to_csv(\"../data/results2strategy/bma/test/BMA_RESULTS-test-803.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.650831</td>\n",
       "      <td>0.609672</td>\n",
       "      <td>0.630252</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.595005</td>\n",
       "      <td>0.654310</td>\n",
       "      <td>0.624657</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.687028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.714667</td>\n",
       "      <td>0.628800</td>\n",
       "      <td>0.671733</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.612571</td>\n",
       "      <td>0.698667</td>\n",
       "      <td>0.655619</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.733360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.606593</td>\n",
       "      <td>0.588991</td>\n",
       "      <td>0.597792</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.578010</td>\n",
       "      <td>0.614354</td>\n",
       "      <td>0.596182</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.643388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.629851</td>\n",
       "      <td>0.696744</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.607229</td>\n",
       "      <td>0.721368</td>\n",
       "      <td>0.664298</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.758520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli    Prec 0    Prec 1      Prec  Rec 0  Rec 1    Rec      F1 0  \\\n",
       "0    TAGS  0.650831  0.609672  0.630252  0.548  0.706  0.627  0.595005   \n",
       "1    TEXT  0.714667  0.628800  0.671733  0.536  0.786  0.661  0.612571   \n",
       "2    CAPS  0.606593  0.588991  0.597792  0.552  0.642  0.597  0.578010   \n",
       "3     BMA  0.763636  0.629851  0.696744  0.504  0.844  0.674  0.607229   \n",
       "\n",
       "       F1 1        F1    ACC       AUC  \n",
       "0  0.654310  0.624657  0.627  0.687028  \n",
       "1  0.698667  0.655619  0.661  0.733360  \n",
       "2  0.614354  0.596182  0.597  0.643388  \n",
       "3  0.721368  0.664298  0.674  0.758520  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_test = pd.DataFrame(res_test)\n",
    "risultati_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECK RESULTS TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.read_csv(\"../data/results2strategy/bma/test/BMA_RESULTS-test-22-02.csv\", sep=\"\\t\")\n",
    "probs = pd.read_csv(\"../data/results2strategy/bma/test/CLFS_PROBS_BMATOT_test_str2_fold_1.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>CAPS SVM PROB 0</th>\n",
       "      <th>CAPS SVM PROB 1</th>\n",
       "      <th>CAPS KNN PROB 0</th>\n",
       "      <th>CAPS KNN PROB 1</th>\n",
       "      <th>CAPS NB PROB 0</th>\n",
       "      <th>CAPS NB PROB 1</th>\n",
       "      <th>CAPS DT PROB 0</th>\n",
       "      <th>CAPS DT PROB 1</th>\n",
       "      <th>...</th>\n",
       "      <th>TEXT NB PROB 0</th>\n",
       "      <th>TEXT NB PROB 1</th>\n",
       "      <th>TEXT DT PROB 0</th>\n",
       "      <th>TEXT DT PROB 1</th>\n",
       "      <th>TEXT MLP PROB 0</th>\n",
       "      <th>TEXT MLP PROB 1</th>\n",
       "      <th>BMA PROB 0</th>\n",
       "      <th>BMA PROB 1</th>\n",
       "      <th>LABELS BMA</th>\n",
       "      <th>GROUND TRUTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15236.jpg</td>\n",
       "      <td>0.633209</td>\n",
       "      <td>0.366791</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.541347</td>\n",
       "      <td>0.458653</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.338338</td>\n",
       "      <td>...</td>\n",
       "      <td>9.255980e-04</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.191855</td>\n",
       "      <td>0.808145</td>\n",
       "      <td>0.463263</td>\n",
       "      <td>0.536737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15805.jpg</td>\n",
       "      <td>0.214705</td>\n",
       "      <td>0.785295</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.062292</td>\n",
       "      <td>0.937708</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>0.825194</td>\n",
       "      <td>...</td>\n",
       "      <td>3.859020e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.998531</td>\n",
       "      <td>0.204589</td>\n",
       "      <td>0.795411</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16254.jpg</td>\n",
       "      <td>0.684182</td>\n",
       "      <td>0.315818</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.970856</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.338338</td>\n",
       "      <td>...</td>\n",
       "      <td>3.643728e-05</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.413663</td>\n",
       "      <td>0.586337</td>\n",
       "      <td>0.530338</td>\n",
       "      <td>0.469662</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16191.jpg</td>\n",
       "      <td>0.685932</td>\n",
       "      <td>0.314068</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.978950</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.338338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012002e-04</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.046010</td>\n",
       "      <td>0.953990</td>\n",
       "      <td>0.510928</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15952.jpg</td>\n",
       "      <td>0.348980</td>\n",
       "      <td>0.651020</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.032550</td>\n",
       "      <td>0.967450</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>2.784791e-05</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.991121</td>\n",
       "      <td>0.369518</td>\n",
       "      <td>0.630482</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>15591.jpg</td>\n",
       "      <td>0.190842</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.998346</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>0.825194</td>\n",
       "      <td>...</td>\n",
       "      <td>5.094154e-06</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.332155</td>\n",
       "      <td>0.667845</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.998319</td>\n",
       "      <td>0.170026</td>\n",
       "      <td>0.829974</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>15049.jpg</td>\n",
       "      <td>0.207205</td>\n",
       "      <td>0.792795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.983996</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>0.825194</td>\n",
       "      <td>...</td>\n",
       "      <td>8.757838e-05</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.332155</td>\n",
       "      <td>0.667845</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.998627</td>\n",
       "      <td>0.257660</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>15363.jpg</td>\n",
       "      <td>0.177230</td>\n",
       "      <td>0.822770</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.013309</td>\n",
       "      <td>0.986691</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>0.825194</td>\n",
       "      <td>...</td>\n",
       "      <td>3.985271e-11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.996958</td>\n",
       "      <td>0.136798</td>\n",
       "      <td>0.863202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>15199.jpg</td>\n",
       "      <td>0.693155</td>\n",
       "      <td>0.306845</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.921920</td>\n",
       "      <td>0.078080</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.338338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597106e-04</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.332155</td>\n",
       "      <td>0.667845</td>\n",
       "      <td>0.287095</td>\n",
       "      <td>0.712905</td>\n",
       "      <td>0.479548</td>\n",
       "      <td>0.520452</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>15853.jpg</td>\n",
       "      <td>0.213462</td>\n",
       "      <td>0.786538</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.997999</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>0.825194</td>\n",
       "      <td>...</td>\n",
       "      <td>9.992813e-01</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.698774</td>\n",
       "      <td>0.301226</td>\n",
       "      <td>0.885893</td>\n",
       "      <td>0.114107</td>\n",
       "      <td>0.549370</td>\n",
       "      <td>0.450630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  file_name  CAPS SVM PROB 0  CAPS SVM PROB 1  CAPS KNN PROB 0  \\\n",
       "0             0  15236.jpg         0.633209         0.366791         0.714286   \n",
       "1             1  15805.jpg         0.214705         0.785295         0.571429   \n",
       "2             2  16254.jpg         0.684182         0.315818         0.571429   \n",
       "3             3  16191.jpg         0.685932         0.314068         0.857143   \n",
       "4             4  15952.jpg         0.348980         0.651020         0.571429   \n",
       "..          ...        ...              ...              ...              ...   \n",
       "995         995  15591.jpg         0.190842         0.809158         0.142857   \n",
       "996         996  15049.jpg         0.207205         0.792795         0.000000   \n",
       "997         997  15363.jpg         0.177230         0.822770         0.428571   \n",
       "998         998  15199.jpg         0.693155         0.306845         0.571429   \n",
       "999         999  15853.jpg         0.213462         0.786538         0.285714   \n",
       "\n",
       "     CAPS KNN PROB 1  CAPS NB PROB 0  CAPS NB PROB 1  CAPS DT PROB 0  \\\n",
       "0           0.285714        0.541347        0.458653        0.661662   \n",
       "1           0.428571        0.062292        0.937708        0.174806   \n",
       "2           0.428571        0.970856        0.029144        0.661662   \n",
       "3           0.142857        0.978950        0.021050        0.661662   \n",
       "4           0.428571        0.032550        0.967450        0.666667   \n",
       "..               ...             ...             ...             ...   \n",
       "995         0.857143        0.001654        0.998346        0.174806   \n",
       "996         1.000000        0.016004        0.983996        0.174806   \n",
       "997         0.571429        0.013309        0.986691        0.174806   \n",
       "998         0.428571        0.921920        0.078080        0.661662   \n",
       "999         0.714286        0.002001        0.997999        0.174806   \n",
       "\n",
       "     CAPS DT PROB 1  ...  TEXT NB PROB 0  TEXT NB PROB 1  TEXT DT PROB 0  \\\n",
       "0          0.338338  ...    9.255980e-04        0.999074        0.209445   \n",
       "1          0.825194  ...    3.859020e-09        1.000000        0.209445   \n",
       "2          0.338338  ...    3.643728e-05        0.999964        0.209445   \n",
       "3          0.338338  ...    1.012002e-04        0.999899        0.209445   \n",
       "4          0.333333  ...    2.784791e-05        0.999972        0.209445   \n",
       "..              ...  ...             ...             ...             ...   \n",
       "995        0.825194  ...    5.094154e-06        0.999995        0.332155   \n",
       "996        0.825194  ...    8.757838e-05        0.999912        0.332155   \n",
       "997        0.825194  ...    3.985271e-11        1.000000        0.209445   \n",
       "998        0.338338  ...    1.597106e-04        0.999840        0.332155   \n",
       "999        0.825194  ...    9.992813e-01        0.000719        0.698774   \n",
       "\n",
       "     TEXT DT PROB 1  TEXT MLP PROB 0  TEXT MLP PROB 1  BMA PROB 0  BMA PROB 1  \\\n",
       "0          0.790555         0.191855         0.808145    0.463263    0.536737   \n",
       "1          0.790555         0.001469         0.998531    0.204589    0.795411   \n",
       "2          0.790555         0.413663         0.586337    0.530338    0.469662   \n",
       "3          0.790555         0.046010         0.953990    0.510928    0.489072   \n",
       "4          0.790555         0.008879         0.991121    0.369518    0.630482   \n",
       "..              ...              ...              ...         ...         ...   \n",
       "995        0.667845         0.001681         0.998319    0.170026    0.829974   \n",
       "996        0.667845         0.001373         0.998627    0.257660    0.742340   \n",
       "997        0.790555         0.003042         0.996958    0.136798    0.863202   \n",
       "998        0.667845         0.287095         0.712905    0.479548    0.520452   \n",
       "999        0.301226         0.885893         0.114107    0.549370    0.450630   \n",
       "\n",
       "     LABELS BMA  GROUND TRUTH  \n",
       "0             1             0  \n",
       "1             1             1  \n",
       "2             0             0  \n",
       "3             0             1  \n",
       "4             1             0  \n",
       "..          ...           ...  \n",
       "995           1             1  \n",
       "996           1             0  \n",
       "997           1             1  \n",
       "998           1             0  \n",
       "999           0             0  \n",
       "\n",
       "[1000 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "count = 0\n",
    "probs0_text = []\n",
    "probs0_tags = []\n",
    "probs0_caps = []\n",
    "probs1_text = []\n",
    "probs1_tags = []\n",
    "probs1_caps = []\n",
    "\n",
    "labels_dt = []\n",
    "labels_mlp = []\n",
    "for i in range(0, 1000):\n",
    "        #print(score[\"FOLD\"][j])\n",
    "        #print(i)\n",
    "        marginale_0_ = (probs[\"CAPS PROB 0\"][i]* score[\"F1 0\"][2]) + (probs[\"TAGS PROB 0\"][i]* score[\"F1 0\"][0]) + (probs[\"TEXT PROB 0\"][i]* score[\"F1 0\"][1])\n",
    "        marginale_1_ = (probs[\"CAPS PROB 1\"][i]* score[\"F1 1\"][2]) + (probs[\"TAGS PROB 1\"][i]* score[\"F1 1\"][0]) + (probs[\"TEXT PROB 1\"][i]* score[\"F1 1\"][1])\n",
    "        marginale_0, marginale_1 = normalize(marginale_0_, marginale_1_)\n",
    "        marginale_0 = round(marginale_0, 4)\n",
    "        marginale_1 = round(marginale_1, 4)\n",
    "        prob_bma0 = round(probs[\"BMA PROB 0\"][i], 4)\n",
    "        prob_bma1 = round(probs[\"BMA PROB 1\"][i], 4)\n",
    "        #print(marginale_0, prob_bma0)\n",
    "        if marginale_0 != prob_bma0:\n",
    "                print(\"calcolo sbagliato \", i)\n",
    "                print(marginale_0, \" != \", round(probs[\"BMA PROB 0\"][i],4))\n",
    "        if marginale_1 != prob_bma1:\n",
    "                print(\"calcolo sbagliato \", i)\n",
    "        if marginale_0 > marginale_1:\n",
    "                label = 0\n",
    "               #print(label)\n",
    "        else:\n",
    "                label = 1\n",
    "        if label != probs[\"LABELS BMA\"][i]:\n",
    "                print(marginale_0, \" \", marginale_1)\n",
    "                print(\"LABEL \", label, \" ground truth\", probs[\"GROUND TRUTH\"][i])\n",
    "                print(\"LABEL NON CORRETTA \" , i)\n",
    "        #p0_svm = probs[\"SVM PROB 0\"][i]  \n",
    "        #p1_svm = probs[\"SVM PROB 1\"][i]  \n",
    "        #if p0_svm > p1_svm:\n",
    "        #    label_svm = 0\n",
    "        #else:\n",
    "        #    label_svm = 1\n",
    "        #p0_knn = probs[\"KNN PROB 0\"][i]  \n",
    "        #p1_knn = probs[\"KNN PROB 1\"][i]  \n",
    "        #if p0_knn > p1_knn:\n",
    "        #    label_knn = 0\n",
    "        #else:\n",
    "        #    label_knn = 1\n",
    "        #p0_dt = probs[\"DT PROB 0\"][i]  \n",
    "        #p1_dt = probs[\"DT PROB 1\"][i]\n",
    "        #if p0_dt > p1_dt:\n",
    "        #    label_dt = 0\n",
    "        #else:\n",
    "        #    label_dt = 1\n",
    "        #p0_nb = probs[\"NB PROB 0\"][i]  \n",
    "        #p1_nb = probs[\"NB PROB 1\"][i]  \n",
    "        #if p0_nb > p1_nb:\n",
    "        #    label_nb = 0\n",
    "        #else:\n",
    "        #    label_nb = 1\n",
    "#\n",
    "        #p0_mlp = probs[\"MLP PROB 0\"][i]  \n",
    "        #p1_mlp = probs[\"MLP PROB 1\"][i]  \n",
    "        #if p0_mlp > p1_mlp:\n",
    "        #    label_mlp = 0\n",
    "        #else:\n",
    "        #    label_mlp = 1\n",
    "        #labels_svm.append(label_svm)\n",
    "        #labels_knn.append(label_knn)\n",
    "        #labels_dt.append(label_dt)\n",
    "        #labels_nb.append(label_nb)\n",
    "        #labels_mlp.append(label_mlp)\n",
    "        #\n",
    "        #if label_svm != probs[\"LABELS BMA\"][i] and probs[\"LABELS BMA\"][i] != probs[\"GROUND TRUTH\"][i]:\n",
    "        #    count +=1\n",
    "        #    print(\"SVM-BMA label invertita index: \", i)\n",
    "        #    print(\"LABEL SVM \", label_svm, \" LABEL BMA \", probs[\"LABELS BMA\"][i], \" GROUND TRUTH \", probs[\"GROUND TRUTH\"][i])\n",
    "        #    if probs[\"LABELS BMA\"][i] == 0:\n",
    "        #        print(\"VOTO \", \"SVM \", label_svm, \" KNN \", label_knn, \" DT \", label_dt, \" NB \", label_nb, \" MLP \", label_mlp)\n",
    "        #        print(\"SVM(\",probs[\"SVM PROB 0\"][i], \" * \", score[\"SCORE 0 SVM\"][j], \") + KNN(\",  probs[\"KNN PROB 0\"][i], \" * \", score[\"SCORE 0 KNN\"][j], \") + NB(\", probs[\"NB PROB 0\"][i], \" * \", score[\"SCORE 0 NB\"][j],  \") + DT(\" ,probs[\"DT PROB 0\"][i], \" * \",score[\"SCORE 0 DT\"][j], \") + MLP(\" ,probs[\"MLP PROB 0\"][i],\" * \",score[\"SCORE 0 MLP\"][j] , \")= \", marginale_0)\n",
    "        #    else:\n",
    "         #       print(\"VOTO \", \"SVM \", label_svm, \" KNN \", label_knn, \" DT \", label_dt, \" NB \", label_nb, \" MLP \", label_mlp)\n",
    "         #       print(\"SVM (\",probs[\"SVM PROB 1\"][i], \" * \", score[\"SCORE 1 SVM\"][j], \") + KNN(\",  probs[\"KNN PROB 1\"][i], \" * \", score[\"SCORE 1 KNN\"][j], \") + NB(\", probs[\"NB PROB 1\"][i], \" * \", score[\"SCORE 1 NB\"][j],  \") + DT(\" ,probs[\"DT PROB 1\"][i], \" * \",score[\"SCORE 1 DT\"][j], \") + MLP(\" ,probs[\"MLP PROB 1\"][i],\" * \",score[\"SCORE 1 MLP\"][j] , \")= \", marginale_1)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.6304</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>0.6866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.6288</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.6058</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.5510</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.6137</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>0.6455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BMA</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.7595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Modelli  Prec 0  Prec 1    Prec   Rec 0   Rec 1     Rec    F1 0  \\\n",
       "0           0    TAGS  0.6507  0.6100  0.6304  0.5492  0.7052  0.6272  0.5957   \n",
       "1           1    TEXT  0.7104  0.6288  0.6696  0.5396  0.7800  0.6598  0.6133   \n",
       "2           2    CAPS  0.6058  0.5882  0.5970  0.5510  0.6414  0.5962  0.5771   \n",
       "3           3     BMA  0.7666  0.6338  0.7002  0.5124  0.8440  0.6782  0.6142   \n",
       "\n",
       "     F1 1      F1     ACC     AUC  \n",
       "0  0.6542  0.6249  0.6272  0.6866  \n",
       "1  0.6963  0.6548  0.6598  0.7329  \n",
       "2  0.6137  0.5954  0.5962  0.6455  \n",
       "3  0.7240  0.6691  0.6740  0.7595  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3831/750384745.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'probs_test' is not defined"
     ]
    }
   ],
   "source": [
    "probs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    n_fold_tags = f\"../data/results2strategy/tags/test/probs_test_fold_1_tags.csv\"\n",
    "    n_fold_text = f\"../data/results2strategy/text/test/probs_test_1_text.csv\"\n",
    "    n_fold_caps = f\"../data/results2strategy/caps/test/probs_test_fold_1_caps.csv\"\n",
    "    #data_probs = pd.read_csv(n_fold, sep=\"\\t\")\n",
    "    probs_tags_test = pd.read_csv(n_fold_tags, sep=\"\\t\")\n",
    "    probs_text_test = pd.read_csv(n_fold_text, sep=\"\\t\")\n",
    "    probs_caps_test = pd.read_csv(n_fold_caps, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = probs_caps_test[\"GROUND TRUTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FOLD</th>\n",
       "      <th>SCORE 0 SVM</th>\n",
       "      <th>SCORE 1 SVM</th>\n",
       "      <th>SCORE 0 KNN</th>\n",
       "      <th>SCORE 1 KNN</th>\n",
       "      <th>SCORE 0 NB</th>\n",
       "      <th>SCORE 1 NB</th>\n",
       "      <th>SCORE 0 DT</th>\n",
       "      <th>SCORE 1 DT</th>\n",
       "      <th>SCORE 0 MLP</th>\n",
       "      <th>SCORE 1 MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707340</td>\n",
       "      <td>0.677182</td>\n",
       "      <td>0.721254</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>0.701051</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.714015</td>\n",
       "      <td>0.680085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.718356</td>\n",
       "      <td>0.675632</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.624105</td>\n",
       "      <td>0.699387</td>\n",
       "      <td>0.661350</td>\n",
       "      <td>0.706144</td>\n",
       "      <td>0.623717</td>\n",
       "      <td>0.726091</td>\n",
       "      <td>0.680390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.725016</td>\n",
       "      <td>0.681066</td>\n",
       "      <td>0.732102</td>\n",
       "      <td>0.634069</td>\n",
       "      <td>0.705994</td>\n",
       "      <td>0.670671</td>\n",
       "      <td>0.708876</td>\n",
       "      <td>0.624427</td>\n",
       "      <td>0.731542</td>\n",
       "      <td>0.685487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.732192</td>\n",
       "      <td>0.684984</td>\n",
       "      <td>0.738116</td>\n",
       "      <td>0.640569</td>\n",
       "      <td>0.715997</td>\n",
       "      <td>0.676997</td>\n",
       "      <td>0.715281</td>\n",
       "      <td>0.615972</td>\n",
       "      <td>0.739770</td>\n",
       "      <td>0.689863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.733097</td>\n",
       "      <td>0.690564</td>\n",
       "      <td>0.737679</td>\n",
       "      <td>0.640266</td>\n",
       "      <td>0.714313</td>\n",
       "      <td>0.677454</td>\n",
       "      <td>0.716652</td>\n",
       "      <td>0.618992</td>\n",
       "      <td>0.741685</td>\n",
       "      <td>0.695292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.733499</td>\n",
       "      <td>0.692970</td>\n",
       "      <td>0.738212</td>\n",
       "      <td>0.644121</td>\n",
       "      <td>0.712488</td>\n",
       "      <td>0.676001</td>\n",
       "      <td>0.719454</td>\n",
       "      <td>0.622630</td>\n",
       "      <td>0.741746</td>\n",
       "      <td>0.696629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.732428</td>\n",
       "      <td>0.696448</td>\n",
       "      <td>0.736121</td>\n",
       "      <td>0.644653</td>\n",
       "      <td>0.710394</td>\n",
       "      <td>0.677239</td>\n",
       "      <td>0.717150</td>\n",
       "      <td>0.619662</td>\n",
       "      <td>0.740564</td>\n",
       "      <td>0.698579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.732179</td>\n",
       "      <td>0.697458</td>\n",
       "      <td>0.738240</td>\n",
       "      <td>0.647300</td>\n",
       "      <td>0.711481</td>\n",
       "      <td>0.680711</td>\n",
       "      <td>0.719060</td>\n",
       "      <td>0.621165</td>\n",
       "      <td>0.738756</td>\n",
       "      <td>0.697762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.729037</td>\n",
       "      <td>0.698439</td>\n",
       "      <td>0.735480</td>\n",
       "      <td>0.647844</td>\n",
       "      <td>0.708998</td>\n",
       "      <td>0.681786</td>\n",
       "      <td>0.716709</td>\n",
       "      <td>0.624645</td>\n",
       "      <td>0.736403</td>\n",
       "      <td>0.698881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.729988</td>\n",
       "      <td>0.696677</td>\n",
       "      <td>0.736907</td>\n",
       "      <td>0.648604</td>\n",
       "      <td>0.708254</td>\n",
       "      <td>0.679606</td>\n",
       "      <td>0.717350</td>\n",
       "      <td>0.619930</td>\n",
       "      <td>0.736793</td>\n",
       "      <td>0.696317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  FOLD  SCORE 0 SVM  SCORE 1 SVM  SCORE 0 KNN  SCORE 1 KNN  \\\n",
       "0           0     1     0.707340     0.677182     0.721254     0.624413   \n",
       "1           1     2     0.718356     0.675632     0.728916     0.624105   \n",
       "2           2     3     0.725016     0.681066     0.732102     0.634069   \n",
       "3           3     4     0.732192     0.684984     0.738116     0.640569   \n",
       "4           4     5     0.733097     0.690564     0.737679     0.640266   \n",
       "5           5     6     0.733499     0.692970     0.738212     0.644121   \n",
       "6           6     7     0.732428     0.696448     0.736121     0.644653   \n",
       "7           7     8     0.732179     0.697458     0.738240     0.647300   \n",
       "8           8     9     0.729037     0.698439     0.735480     0.647844   \n",
       "9           9    10     0.729988     0.696677     0.736907     0.648604   \n",
       "\n",
       "   SCORE 0 NB  SCORE 1 NB  SCORE 0 DT  SCORE 1 DT  SCORE 0 MLP  SCORE 1 MLP  \n",
       "0    0.701051    0.671563    0.705036    0.630631     0.714015     0.680085  \n",
       "1    0.699387    0.661350    0.706144    0.623717     0.726091     0.680390  \n",
       "2    0.705994    0.670671    0.708876    0.624427     0.731542     0.685487  \n",
       "3    0.715997    0.676997    0.715281    0.615972     0.739770     0.689863  \n",
       "4    0.714313    0.677454    0.716652    0.618992     0.741685     0.695292  \n",
       "5    0.712488    0.676001    0.719454    0.622630     0.741746     0.696629  \n",
       "6    0.710394    0.677239    0.717150    0.619662     0.740564     0.698579  \n",
       "7    0.711481    0.680711    0.719060    0.621165     0.738756     0.697762  \n",
       "8    0.708998    0.681786    0.716709    0.624645     0.736403     0.698881  \n",
       "9    0.708254    0.679606    0.717350    0.619930     0.736793     0.696317  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tags_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15560.jpg\n",
      "0 0 1 1\n",
      "16056.jpg\n",
      "0 0 1 1\n",
      "16165.jpg\n",
      "1 1 0 0\n",
      "17018.jpg\n",
      "1 1 0 0\n",
      "15504.jpg\n",
      "1 1 0 0\n",
      "15659.jpg\n",
      "1 1 0 0\n",
      "16124.jpg\n",
      "1 1 0 0\n",
      "15051.jpg\n",
      "1 1 0 0\n",
      "16127.jpg\n",
      "1 1 0 0\n",
      "15281.jpg\n",
      "1 1 0 0\n",
      "16067.jpg\n",
      "1 1 0 0\n",
      "15667.jpg\n",
      "1 1 0 0\n",
      "15112.jpg\n",
      "1 1 0 0\n",
      "17046.jpg\n",
      "1 1 0 0\n",
      "15771.jpg\n",
      "1 1 0 0\n",
      "15911.jpg\n",
      "1 1 0 0\n",
      "15211.jpg\n",
      "1 1 0 0\n",
      "15113.jpg\n",
      "1 1 0 0\n",
      "16256.jpg\n",
      "1 1 0 0\n",
      "15468.jpg\n",
      "1 1 0 0\n",
      "15700.jpg\n",
      "0 0 1 1\n",
      "15898.jpg\n",
      "1 1 0 0\n",
      "15102.jpg\n",
      "1 1 0 0\n",
      "15524.jpg\n",
      "0 0 1 1\n",
      "16258.jpg\n",
      "1 1 0 0\n",
      "15425.jpg\n",
      "1 1 0 0\n",
      "16119.jpg\n",
      "1 1 0 0\n",
      "16251.jpg\n",
      "1 1 0 0\n",
      "17029.jpg\n",
      "1 1 0 0\n",
      "15766.jpg\n",
      "1 1 0 0\n",
      "15442.jpg\n",
      "1 1 0 0\n",
      "17075.jpg\n",
      "1 1 0 0\n",
      "15989.jpg\n",
      "0 0 1 1\n",
      "15653.jpg\n",
      "0 0 1 1\n",
      "15498.jpg\n",
      "1 1 0 0\n",
      "15050.jpg\n",
      "1 1 0 0\n",
      "15202.jpg\n",
      "1 1 0 0\n",
      "15143.jpg\n",
      "1 1 0 0\n",
      "15714.jpg\n",
      "1 1 0 0\n",
      "15699.jpg\n",
      "0 0 1 1\n",
      "15257.jpg\n",
      "1 1 0 0\n",
      "15088.jpg\n",
      "1 1 0 0\n",
      "15901.jpg\n",
      "1 1 0 0\n",
      "16078.jpg\n",
      "1 1 0 0\n",
      "15937.jpg\n",
      "1 1 0 0\n",
      "16307.jpg\n",
      "1 1 0 0\n",
      "15473.jpg\n",
      "1 1 0 0\n",
      "15240.jpg\n",
      "1 1 0 0\n",
      "16309.jpg\n",
      "1 1 0 0\n",
      "15578.jpg\n",
      "0 0 1 1\n",
      "15854.jpg\n",
      "1 1 0 0\n",
      "17079.jpg\n",
      "1 1 0 0\n",
      "16324.jpg\n",
      "1 1 0 0\n",
      "15241.jpg\n",
      "0 0 1 1\n",
      "15598.jpg\n",
      "1 1 0 0\n",
      "15987.jpg\n",
      "1 1 0 0\n",
      "16026.jpg\n",
      "1 1 0 0\n",
      "15303.jpg\n",
      "0 0 1 1\n",
      "15588.jpg\n",
      "1 1 0 0\n",
      "15255.jpg\n",
      "1 1 0 0\n",
      "15648.jpg\n",
      "1 1 0 0\n",
      "15860.jpg\n",
      "0 0 1 1\n",
      "15924.jpg\n",
      "1 1 0 0\n",
      "15925.jpg\n",
      "1 1 0 0\n",
      "16305.jpg\n",
      "1 1 0 0\n",
      "15777.jpg\n",
      "1 1 0 0\n",
      "15551.jpg\n",
      "1 1 0 0\n",
      "15790.jpg\n",
      "1 1 0 0\n",
      "17031.jpg\n",
      "1 1 0 0\n",
      "15782.jpg\n",
      "1 1 0 0\n",
      "15146.jpg\n",
      "1 1 0 0\n",
      "16282.jpg\n",
      "1 1 0 0\n",
      "16054.jpg\n",
      "1 1 0 0\n",
      "17036.jpg\n",
      "1 1 0 0\n",
      "16147.jpg\n",
      "1 1 0 0\n",
      "15660.jpg\n",
      "1 1 0 0\n",
      "15716.jpg\n",
      "1 1 0 0\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "count = 0\n",
    "probs0_text = []\n",
    "probs0_tags = []\n",
    "probs0_caps = []\n",
    "probs1_text = []\n",
    "probs1_tags = []\n",
    "probs1_caps = []\n",
    "\n",
    "labels_dt = []\n",
    "labels_mlp = []\n",
    "for i in range(0, 1000):\n",
    "        #print(score[\"FOLD\"][j])\n",
    "        #print(i)\n",
    "        tags_prob0 = (probs_tags_test[\"SVM PROB 0\"][i]* score_tags_test[\"SCORE 0 SVM\"][j]) + (probs_tags_test[\"KNN PROB 0\"][i]* score_tags_test[\"SCORE 0 KNN\"][j])+ (probs_tags_test[\"NB PROB 0\"][i]* score_tags_test[\"SCORE 0 NB\"][j]) +  (probs_tags_test[\"DT PROB 0\"][i]* score_tags_test[\"SCORE 0 DT\"][j]) +  (probs_tags_test[\"MLP PROB 0\"][i]* score_tags_test[\"SCORE 0 MLP\"][j])\n",
    "        text_prob0 = (probs_text_test[\"SVM PROB 0\"][i]* score_text_test[\"SCORE 0 SVM\"][j]) + (probs_text_test[\"KNN PROB 0\"][i]* score_text_test[\"SCORE 0 KNN\"][j])+ (probs_text_test[\"NB PROB 0\"][i]* score_text_test[\"SCORE 0 NB\"][j]) +  (probs_text_test[\"DT PROB 0\"][i]* score_text_test[\"SCORE 0 DT\"][j]) +  (probs_text_test[\"MLP PROB 0\"][i]* score_text_test[\"SCORE 0 MLP\"][j])\n",
    "        caps_prob0 = (probs_caps_test[\"SVM PROB 0\"][i]* score_caps_test[\"SCORE 0 SVM\"][j]) + (probs_caps_test[\"KNN PROB 0\"][i]* score_caps_test[\"SCORE 0 KNN\"][j])+ (probs_caps_test[\"NB PROB 0\"][i]* score_caps_test[\"SCORE 0 NB\"][j]) +  (probs_caps_test[\"DT PROB 0\"][i]* score_caps_test[\"SCORE 0 DT\"][j]) +  (probs_caps_test[\"MLP PROB 0\"][i]* score_caps_test[\"SCORE 0 MLP\"][j])\n",
    "        tags_prob1 = (probs_tags_test[\"SVM PROB 1\"][i]* score_tags_test[\"SCORE 1 SVM\"][j]) + (probs_tags_test[\"KNN PROB 1\"][i]* score_tags_test[\"SCORE 1 KNN\"][j])+ (probs_tags_test[\"NB PROB 1\"][i]* score_tags_test[\"SCORE 1 NB\"][j]) +  (probs_tags_test[\"DT PROB 1\"][i]* score_tags_test[\"SCORE 1 DT\"][j]) +  (probs_tags_test[\"MLP PROB 1\"][i]* score_tags_test[\"SCORE 1 MLP\"][j])\n",
    "        text_prob1 = (probs_text_test[\"SVM PROB 1\"][i]* score_text_test[\"SCORE 1 SVM\"][j]) + (probs_text_test[\"KNN PROB 1\"][i]* score_text_test[\"SCORE 1 KNN\"][j])+ (probs_text_test[\"NB PROB 1\"][i]* score_text_test[\"SCORE 1 NB\"][j]) +  (probs_text_test[\"DT PROB 1\"][i]* score_text_test[\"SCORE 1 DT\"][j]) +  (probs_text_test[\"MLP PROB 1\"][i]* score_text_test[\"SCORE 1 MLP\"][j])\n",
    "        caps_prob1 = (probs_caps_test[\"SVM PROB 1\"][i]* score_caps_test[\"SCORE 1 SVM\"][j]) + (probs_caps_test[\"KNN PROB 1\"][i]* score_caps_test[\"SCORE 1 KNN\"][j])+ (probs_caps_test[\"NB PROB 1\"][i]* score_caps_test[\"SCORE 1 NB\"][j]) +  (probs_caps_test[\"DT PROB 1\"][i]* score_caps_test[\"SCORE 1 DT\"][j]) +  (probs_caps_test[\"MLP PROB 1\"][i]* score_caps_test[\"SCORE 1 MLP\"][j])\n",
    "        marginale_1_ = tags_prob1 + text_prob1 + caps_prob1\n",
    "        marginale_0_ = tags_prob0 + text_prob0 + caps_prob0\n",
    "\n",
    "        text_vote_0, text_vote_1 = normalize(text_prob0, text_prob1)\n",
    "        caps_vote_0, caps_vote_1 = normalize(caps_prob0, caps_prob1)\n",
    "        tags_vote_0, tags_vote_1 = normalize(tags_prob0, tags_prob1)\n",
    "        marginale_0, marginale_1 = normalize(marginale_0_, marginale_1_)\n",
    "        \n",
    "        if marginale_0 > marginale_1:\n",
    "                label_bma = 0\n",
    "        else:\n",
    "                label_bma = 1\n",
    "        \n",
    "        if text_vote_0 > text_vote_1:\n",
    "                text_label = 0\n",
    "        else:\n",
    "                text_label = 1\n",
    "        if caps_vote_0 > caps_vote_1:\n",
    "                caps_label = 0\n",
    "        else:\n",
    "                caps_label = 1\n",
    "        if tags_vote_0 > tags_vote_1:\n",
    "                tags_label = 0\n",
    "        else:\n",
    "                tags_label = 1\n",
    "        \n",
    "        if text_label == label_bma  and tags_label!= label_bma and caps_label != label_bma and label_bma == y_test[i]:\n",
    "                print(probs_caps_test[\"file_name\"][i])\n",
    "                print(label_bma, text_label, caps_label, tags_label)\n",
    "                count +=1\n",
    "                \n",
    "        #print(marginale_0, prob_bma0)\n",
    "        #if marginale_0 != prob_bma0:\n",
    "        #        print(\"calcolo sbagliato \", i)\n",
    "        #        print(marginale_0, \" != \", round(probs[\"BMA PROB 0\"][i],4))\n",
    "        #if marginale_1 != prob_bma1:\n",
    "        #        print(\"calcolo sbagliato \", i)\n",
    "        #if marginale_0 > marginale_1:\n",
    "        #        label = 0\n",
    "        #       #print(label)\n",
    "        #else:\n",
    "        #        label = 1\n",
    "        #if label != probs[\"LABELS BMA\"][i]:\n",
    "        #        print(marginale_0, \" \", marginale_1)\n",
    "        #        print(\"LABEL \", label, \" ground truth\", probs[\"GROUND TRUTH\"][i])\n",
    "        #        print(\"LABEL NON CORRETTA \" , i)\n",
    "        #p0_svm = probs[\"SVM PROB 0\"][i]  \n",
    "        #p1_svm = probs[\"SVM PROB 1\"][i]  \n",
    "        #if p0_svm > p1_svm:\n",
    "        #    label_svm = 0\n",
    "        #else:\n",
    "        #    label_svm = 1\n",
    "        #p0_knn = probs[\"KNN PROB 0\"][i]  \n",
    "        #p1_knn = probs[\"KNN PROB 1\"][i]  \n",
    "        #if p0_knn > p1_knn:\n",
    "        #    label_knn = 0\n",
    "        #else:\n",
    "        #    label_knn = 1\n",
    "        #p0_dt = probs[\"DT PROB 0\"][i]  \n",
    "        #p1_dt = probs[\"DT PROB 1\"][i]\n",
    "        #if p0_dt > p1_dt:\n",
    "        #    label_dt = 0\n",
    "        #else:\n",
    "        #    label_dt = 1\n",
    "        #p0_nb = probs[\"NB PROB 0\"][i]  \n",
    "        #p1_nb = probs[\"NB PROB 1\"][i]  \n",
    "        #if p0_nb > p1_nb:\n",
    "        #    label_nb = 0\n",
    "        #else:\n",
    "        #    label_nb = 1\n",
    "#\n",
    "        #p0_mlp = probs[\"MLP PROB 0\"][i]  \n",
    "        #p1_mlp = probs[\"MLP PROB 1\"][i]  \n",
    "        #if p0_mlp > p1_mlp:\n",
    "        #    label_mlp = 0\n",
    "        #else:\n",
    "        #    label_mlp = 1\n",
    "        #labels_svm.append(label_svm)\n",
    "        #labels_knn.append(label_knn)\n",
    "        #labels_dt.append(label_dt)\n",
    "        #labels_nb.append(label_nb)\n",
    "        #labels_mlp.append(label_mlp)\n",
    "        #\n",
    "        #if label_svm != probs[\"LABELS BMA\"][i] and probs[\"LABELS BMA\"][i] != probs[\"GROUND TRUTH\"][i]:\n",
    "        #    count +=1\n",
    "        #    print(\"SVM-BMA label invertita index: \", i)\n",
    "        #    print(\"LABEL SVM \", label_svm, \" LABEL BMA \", probs[\"LABELS BMA\"][i], \" GROUND TRUTH \", probs[\"GROUND TRUTH\"][i])\n",
    "        #    if probs[\"LABELS BMA\"][i] == 0:\n",
    "        #        print(\"VOTO \", \"SVM \", label_svm, \" KNN \", label_knn, \" DT \", label_dt, \" NB \", label_nb, \" MLP \", label_mlp)\n",
    "        #        print(\"SVM(\",probs[\"SVM PROB 0\"][i], \" * \", score[\"SCORE 0 SVM\"][j], \") + KNN(\",  probs[\"KNN PROB 0\"][i], \" * \", score[\"SCORE 0 KNN\"][j], \") + NB(\", probs[\"NB PROB 0\"][i], \" * \", score[\"SCORE 0 NB\"][j],  \") + DT(\" ,probs[\"DT PROB 0\"][i], \" * \",score[\"SCORE 0 DT\"][j], \") + MLP(\" ,probs[\"MLP PROB 0\"][i],\" * \",score[\"SCORE 0 MLP\"][j] , \")= \", marginale_0)\n",
    "        #    else:\n",
    "         #       print(\"VOTO \", \"SVM \", label_svm, \" KNN \", label_knn, \" DT \", label_dt, \" NB \", label_nb, \" MLP \", label_mlp)\n",
    "         #       print(\"SVM (\",probs[\"SVM PROB 1\"][i], \" * \", score[\"SCORE 1 SVM\"][j], \") + KNN(\",  probs[\"KNN PROB 1\"][i], \" * \", score[\"SCORE 1 KNN\"][j], \") + NB(\", probs[\"NB PROB 1\"][i], \" * \", score[\"SCORE 1 NB\"][j],  \") + DT(\" ,probs[\"DT PROB 1\"][i], \" * \",score[\"SCORE 1 DT\"][j], \") + MLP(\" ,probs[\"MLP PROB 1\"][i],\" * \",score[\"SCORE 1 MLP\"][j] , \")= \", marginale_1)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinthetic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_tags_sintest = pd.read_csv(\"../data/results/sin_test/tags_probs_sin_test1902.csv\", sep=\"\\t\")\n",
    "probs_text_sintest = pd.read_csv(\"../data/results/sin_test/text_probs_bma_sin_test2102.csv\", sep=\"\\t\")\n",
    "probs_caps_sintest = pd.read_csv(\"../data/results/sin_test/caps_probs_bma_sin_test1902.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_text_test = pd.read_csv(\"../data/results2strategy/text/sintest/score_sin_test_text10fold.csv\", sep=\"\\t\")\n",
    "score_caps_test = pd.read_csv(\"../data/results2strategy/caps/sintest/score_sin_test_caps10fold.csv\", sep=\"\\t\")\n",
    "score_tags_test = pd.read_csv(\"../data/results2strategy/tags/sintest/score_sin_test_tags10fold.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics.printResult\n",
    "evaluation_metrics.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.00\n",
      "\n",
      "Confusion Matrix:\n",
      " [[51 24]\n",
      " [15 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72        75\n",
      "           1       0.71      0.80      0.75        75\n",
      "\n",
      "    accuracy                           0.74       150\n",
      "   macro avg       0.74      0.74      0.74       150\n",
      "weighted avg       0.74      0.74      0.74       150\n",
      "\n",
      "Area under the ROC curve : 0.810667\n",
      "ACC BMA  0.74\n",
      "AUC BMA  0.8106666666666666\n",
      "Accuracy: 75.33\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54 21]\n",
      " [16 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74        75\n",
      "           1       0.74      0.79      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.814756\n",
      "ACC BMA  0.7533333333333333\n",
      "AUC BMA  0.8147555555555556\n",
      "Accuracy: 74.67\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52 23]\n",
      " [15 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73        75\n",
      "           1       0.72      0.80      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.813511\n",
      "ACC BMA  0.7466666666666667\n",
      "AUC BMA  0.8135111111111111\n",
      "Accuracy: 74.67\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53 22]\n",
      " [16 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        75\n",
      "           1       0.73      0.79      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.811022\n",
      "ACC BMA  0.7466666666666667\n",
      "AUC BMA  0.8110222222222223\n",
      "Accuracy: 76.00\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54 21]\n",
      " [15 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75        75\n",
      "           1       0.74      0.80      0.77        75\n",
      "\n",
      "    accuracy                           0.76       150\n",
      "   macro avg       0.76      0.76      0.76       150\n",
      "weighted avg       0.76      0.76      0.76       150\n",
      "\n",
      "Area under the ROC curve : 0.811556\n",
      "ACC BMA  0.76\n",
      "AUC BMA  0.8115555555555556\n",
      "Accuracy: 74.67\n",
      "\n",
      "Confusion Matrix:\n",
      " [[52 23]\n",
      " [15 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73        75\n",
      "           1       0.72      0.80      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.810489\n",
      "ACC BMA  0.7466666666666667\n",
      "AUC BMA  0.8104888888888889\n",
      "Accuracy: 74.67\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53 22]\n",
      " [16 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        75\n",
      "           1       0.73      0.79      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.810311\n",
      "ACC BMA  0.7466666666666667\n",
      "AUC BMA  0.8103111111111111\n",
      "Accuracy: 74.67\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53 22]\n",
      " [16 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        75\n",
      "           1       0.73      0.79      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.812089\n",
      "ACC BMA  0.7466666666666667\n",
      "AUC BMA  0.812088888888889\n",
      "Accuracy: 74.67\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53 22]\n",
      " [16 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        75\n",
      "           1       0.73      0.79      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.810133\n",
      "ACC BMA  0.7466666666666667\n",
      "AUC BMA  0.8101333333333334\n",
      "Accuracy: 75.33\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54 21]\n",
      " [16 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74        75\n",
      "           1       0.74      0.79      0.76        75\n",
      "\n",
      "    accuracy                           0.75       150\n",
      "   macro avg       0.75      0.75      0.75       150\n",
      "weighted avg       0.75      0.75      0.75       150\n",
      "\n",
      "Area under the ROC curve : 0.812089\n",
      "ACC BMA  0.7533333333333333\n",
      "AUC BMA  0.8120888888888889\n",
      "################  BMA #############################\n",
      "ACC BMA  [0.74, 0.7533333333333333, 0.7466666666666667, 0.7466666666666667, 0.76, 0.7466666666666667, 0.7466666666666667, 0.7466666666666667, 0.7466666666666667, 0.7533333333333333]\n",
      "ACC BMA  0.7486666666666667\n",
      "AUC BMA  [0.8106666666666666, 0.8147555555555556, 0.8135111111111111, 0.8110222222222223, 0.8115555555555556, 0.8104888888888889, 0.8103111111111111, 0.812088888888889, 0.8101333333333334, 0.8120888888888889]\n",
      "AUC BMA  0.8116622222222223\n",
      "precision class 1 of k fold BMA  0.7288343558282209\n",
      "precision class 0 of kfold BMA  0.7722627737226277\n",
      "prec  0.7505485647754243\n",
      "recall class 1 k fold BMA 0.792\n",
      "recall class 0 k fold BMA  0.7053333333333334\n",
      "rec  0.7486666666666667\n",
      "f1 pos BMA  0.7591054313099042\n",
      "f1 neg BMA  0.7372822299651568\n",
      "f1  0.7481938306375304\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABDZ0lEQVR4nO2deXxU1fn/3w9JIEBYBJQKyKIgBBCDRKnigrigovjVghaL20+rUpHWfWcRa20VtQrWpSq2FGi1ooAoLSiCUpWwh01RIRCUTWQLS0ie3x/3zuRmMkkmySyZmef9et3X3HPvufc8ZzK5zz3POedzRFUxDMMwkpc6sTbAMAzDiC3mCAzDMJIccwSGYRhJjjkCwzCMJMccgWEYRpJjjsAwDCPJMUdgVAsRWSUifWNtR6wRkZdE5NEolzlRRB6PZpmRQkR+JSL/qea19hsME2LzCOIfEdkAtASKgH3Ah8BwVd0XS7sSDRG5AbhZVc+MsR0Tgc2q+kiM7RgNdFTVoVEoayK1oM6JirUIEofLVDUDyAJ6Ag/G1pyqIyKpyVh2LLHv3ABzBAmHqv4AzMZxCACIyM9FZKGI/CQiy73NaRFpJiJviMgWEdklIu96zl0qIsvc6xaKSA/PuQ0icr6ItBKRAyLSzHOup4jsEJE0N/3/RGSNe//ZItLOk1dF5HYR+Rr4OlidRGSgGwb4SUTmiUhmgB0Pishq9/5viEh6Fepwv4isAPaLSKqIPCAi34jIXveeV7h5M4GXgNNFZJ+I/OQe94dpRKSviGwWkbtFZJuIfC8iN3rKay4iM0Rkj4gsEpHHReTT8v6WInKm5++2yW2R+DhKRN537fxCRE7wXPdnN/8eEVksImd5zo0WkbdFZJKI7AFuEJHTROR/bjnfi8h4EanruaabiPxXRH4Uka0i8pCIXAQ8BFztfh/L3bxNROQ19z75bh1T3HM3iMhnIvKsiOwERrvHPnXPi3tum2v7ShHpLiK3AL8C7nPLmuH5+53v7qe4dvn+dotF5LjyvlsjAFW1Lc43YANwvrvfBlgJ/NlNtwZ2ApfgOP4L3PTR7vn3gX8CRwFpwDnu8Z7ANqA3kAJc75ZTL0iZHwG/9tjzFPCSu385sB7IBFKBR4CFnrwK/BdoBtQPUrcTgf2u3WnAfe796nrsyAWOc+/xGfB4FeqwzL22vntsMNDK/a6udss+1j13A/BpgH0TPeX1BY4Aj7m2XgIUAEe556e6WwOgK7Ap8H6e+7YD9gJD3Hs1B7I8Ze4ETnO/038AUz3XDnXzpwJ3Az8A6e650UAh8H9uHesDvYCfu/nbA2uA37n5GwHfu/dJd9O9PfeaFGD3NOBloCFwDPAlcKvn+zsC3OGWVd/7nQL9gcVAU0BwfjPHBn7P5fzu78X53Xd2rz0ZaB7r/8142WJugG1h+CM6/xD73AeHAnOBpu65+4G/B+SfjfNQPBYo9j2oAvL8BRgbcGwdJY7C+094M/CRuy/uA+5sN/0BcJPnHnVwHo7t3LQC/Sqo26PAvwKuzwf6euy4zXP+EuCbKtTh/1Xy3S4DLnf3/Q8tz3n/AwrHERwAUj3nt+E8ZFNwHsCdPeceD7yf59yDwLRyzk0E/hpQ57UV1GEXcLK7PxqYX0mdf+crG8cRLS0n32g8jgCnn+oQHofuXv+x5/vLC7iH/zsF+gFfud9XnfK+54Dfve83uM73d7Kt6puFhhKH/1PVRjgPoy5AC/d4O2Cw2+z/yQ1pnInjBI4DflTVXUHu1w64O+C643DelgP5N07I5FjgbBznssBznz977vEjjrNo7bl+UwX1agVs9CVUtdjNX971Gz02hlKHUmWLyHWeUNJPQHdKvstQ2KmqRzzpAiADOBrnLdhbXkX1Pg74poLzPwQpAwARuUecUNxutw5NKF2HwDqfKCIzReQHN1z0hCd/ZXZ4aYfTevne8/29jNMyCFq2F1X9CBgPTAC2icgrItI4xLKrYqcRgDmCBENVP8F5e3raPbQJp0XQ1LM1VNUn3XPNRKRpkFttAn4fcF0DVZ0SpMxdwH9wQinX4IQp1HOfWwPuU19VF3pvUUGVtuA8YAAnjozzT5/vyeONBbd1rwm1Dv6yxem7eBUYjhNWaIoTdpIQ7KyM7ThhkTbl2B3IJuCECs4Hxe0PuA+4Cqel1xTYTUkdoGw9/gKsBTqpamOc2L8v/ybg+HKKC7zPJpwWQQvP991YVbtVcE3pG6o+r6q9cEJnJ+KEfCq9jmp+X4aDOYLE5DngAhE5GZgEXCYi/d0OtXS3U7ONqn6PE7p5UUSOEpE0ETnbvcerwG0i0tvtxGsoIgNEpFE5ZU4GrgMGufs+XgIeFJFu4O9MHFyFuvwLGCAi54nT+Xw3zsPG60huF5E24nRYP4zT51GdOjTEeeBsd229EadF4GMr0MbbkRoqqloEvIPTQdpARLrgfF/l8Q/gfBG5SpxO7OYikhVCUY1wHM52IFVERgKVvVU3AvYA+1y7hnnOzQSOFZHfiUg9EWkkIr3dc1uB9iJSx63j9zgvBONEpLGI1BGRE0TknBDsRkROdf9WaTh9MwdxWpe+sspzSAB/BcaKSCf3b91DRJqHUq5hjiAhUdXtwN+Akaq6CafD9iGch8MmnLcs39/+WpzY9VqcePbv3HvkAL/GaarvwumgvaGCYqcDnYAfVHW5x5ZpwB+BqW7YIRe4uAp1WYfT+fkCsAO4DGeo7GFPtsk4D6BvccIDj1enDqq6GhgH/A/nwXMSTuezj4+AVcAPIrIj1Dp4GI4TpvkB+DswBcepBbMlDyf2fzdOOG0ZTgdoZczGmUfyFU6Y7CAVh6AA7sFpye3FcZ4+R4qq7sXpqL/Mtftr4Fz39Fvu504RWeLuXwfUBVbjfOdv44QhQ6GxW/4u1/adOAMPAF4Durohp3eDXPsMzkvDf3Cc2ms4ndFGCNiEMiOuEWcy3c2qOifWtlQVEfkj8DNVvT7WthjJjbUIDCNKiEgXN2QhInIacBPOcEvDiCk2s88wokcjnHBQK5zQ0zjgvZhaZBhYaMgwDCPpsdCQYRhGkhN3oaEWLVpo+/btY22GYRhGXLF48eIdqnp0sHNx5wjat29PTk5OrM0wDMOIK0RkY3nnLDRkGIaR5JgjMAzDSHLMERiGYSQ55ggMwzCSHHMEhmEYSU7EHIGIvO4uOZdbznkRkedFZL2IrBCRUyJli2EYhlE+kWwRTAQuquD8xThqlZ2AW3A00Q3DMIwoEzFHoKrzceRzy+Ny4G/q8DnQ1F3hyjAMo3bTuzekppZsIhHdjkgd9kuak44AsewjaE1pnfTNlF5+0I+I3CIiOSKSs3379qgYZxiGUS6LF0NRUVSK2k59vqQ1qzjGv0pPuImLmcWq+grwCkB2drap5BmGEXtSUuCIuzy1703dJ+KZ6j5ajxwpe12IjB07j5EjP/GnGzWqy549D1b7fhURyxZBPqXXbG1D6XVoDcMwHAJDMSkpEQ/HVLgVFTmbL+3DZ18NWwt5eTtKOYF33hkUMScAsXUE04Hr3NFDPwd2u2ueGoZhlCYwFFMcqSBJmEhJgV69qnzZPfd8SEFBAW3btiA1VfjZzxqiOoorrugWASNLiFhoSESmAH2BFiKyGRgFpAGo6kvALJw1WdcDBcCNkbLFMIwEwBuK6dvX+Zw3L3jepk2dz59+cj4DQzWVXR9lCgoKyMh4ClUYN+4LVEdRWDgyauVHzBGo6pBKzitwe6TKNwyjlvDKKzB5culjW7bAtm3lX1NQAIWFZY/7HuDLlkFWVvll7NnjxOt9DsHXmijv+hgyYMAkZs36xp/u0qV51G2Ii85iwzDimMmTyz54t22DffsgIyP4NcGcQKNGJftZWXDNNeWXEWzlxTqeSHjg9TEiJWVMqSjXxo2307Zti6jbEXdLVWZnZ6utR2AYHjp0gA0bYm1F7aRJE+dz925n3xcqqiXUr/84Bw8WcdZZxzF//v+LaFkislhVs4OdsxaBYcQ75gSCk5JSst+kCVx6aexscVm7dgeZmRMAUB3FgQOPUFBQQIMGDWJqlzkCw0gUfK37wI7QyjpKa1nHaaLSvv0zbNy415/2OYBYOwEwR2AYsad3b2d4pI/qjkEPlB8ITPs6Tn2x+VrYcZqIfPTRN5x33iR/OjVV2L37nlrhAHyYDLVhxJpoyBV4wyQZGXDMMSXpWtJxmqjceutM//7dd/emsHBkrXICYC0Cw4g+Q4fCzJKHQ7lOwPfwLipy9s8800l/+qnzMK9lHZ9GCa++msOtt75PcfEovv76t/Tp8xqffXZTrM0qF3MEhhFtZs4sGcUSCikp0NwztjwjA1q2jIxtRo1p0OD3HDjg9Md06zaBVatur9VOAMwRGEZs8A5l9MXyfZ25lQmW+WL7Rq1i1Ki5PPbYp/5048Z1WbUqPubMmiMwjHATOMt1zRrYubMk7QsFpQb8+3lnwXpj+oH3s87dWkde3o5STmDWrCFcfPGJMbSoalhnsWGEG98sVx87d1atMzgwFBR4P+vcrTXccccsduzwicTVoVWrDFRHxZUTAGsRGEZkyMoqGZcfKIBWniCaLx0s9OO9nxFzvCJx48cvckXiHo21WdXGHIFhVERgWCZQLK08cTSofFy/jfOPS84//03mzt3gT3fvfnTsjAkT5ggMoyICxcwCxdLKcwJVJXCcv3dUkIWCag116owppWe3ffu9tGhRu+YEVAdzBIZREWvWOA9+X4zeJ2+8b1/V73XOOc6nz7FYqCfuqFcvhYMHizjvvPbMmXN9rM0JG+YIDKMiAjt6q6vWW5GEslFrWbJkE716vQ7ULpG4cGOOwDAqIyWl8o5e75j/wDxGXNK27Tg2bSpp+dUmkbhwY47ASG4CO4OXLIG9e8vmC7WjF6o2a9iodXzwwVdccskUfzo1VaK6bGQssHkERnITOEY/mBOoDG9HL9Qa7XujeowY8YF/f+TIMxPeCYC1CAyjdMdtYKjH9+bv6xuwsE9CEigSd/bZr0d8xbDahDkCI7nxzQvwjdn3dQyXF/qxsE/C4VsuEkpE4pLJCYCFhoxkxzcvIFQs7JMw3HPPh4iM8TuBpk3rxY1IXLixFoER31Q287cydu92Pj/5pPTxWr7ouVEz8vJ2MG7cF/50vInEhRtrERjxTWBnb1Xf8CvDWgAJxbBhM0qJxLVt2yguReLCjbUIjPjH29lb1YXYAzuDAwXgjITAKxL30ktL4l4kLtyYIzDim++/h61bSxzAwoWO/o/vgR6q/LM3f+BwUCOu6dv3DT75JM+fzsqy1d0CMUdgxDdbt5YOBdVUBC4lBXr1qtk9jFpDoorEhRtzBEb8k5FR/jyAypZ9tHkBCU16egoHDhTRv//xfPjhtbE2p9ZijsCILwJHCflG/QSGggLTXgkILzYvIKEIFIkrKHgkxhbFB+YIjPgicH2AmmKjghKG1q3HsWVLWZE4o3LMERjhJfCNPZDA8frVJfA+gZ3CvoVjbB5AwjNt2iquvPJtfzo1tY6NCKoiEZ1HICIXicg6EVkvIg8EOd9WRD4WkaUiskJELomkPUYUCBzXHwu8o37sjT/hefDBj/z7jkicOYGqErEWgYikABOAC4DNwCIRma6qqz3ZHgH+pap/EZGuwCygfaRsMqJERatvBY7bN4xq8Mwzn3HPPXMoLh7F2rV3cP75bybUimHRJpKhodOA9ar6LYCITAUuB7yOQIHG7n4TYEsE7TFqSocOsGFDaHkDRdsMI0ykp4/l0KFioEQkzpxAzYhkaKg1sMmT3uwe8zIaGCoim3FaA3cEu5GI3CIiOSKSs3379kjYaoRCqE7AMCLAHXfMQmSM3wk0b14/aUXiwk2stYaGABNVtQ1wCfB3ESljk6q+oqrZqpp99NFHR93IpGHoUGeYpW8TKb3VhJSUkti9zdw1qkhe3g7Gj1/kT8+dO5QdO+6LoUWJRSQdQT5wnCfdxj3m5SbgXwCq+j8gHWgRQZuMipg5s2Rcfjip4/mZ2cxdowrceOM0v0hc3bp1aN++Maqj6NfvhFibllBEso9gEdBJRDrgOIBfAtcE5MkDzgMmikgmjiOw2E8s8Q61DOzYDSboVlWRN8MIAa9I3MSJK1AdxaFDNhooUkTMEajqEREZDswGUoDXVXWViDwG5KjqdOBu4FURuROn4/gGVRtOEjP27XPG46cG/Cx8D3vfsFBf2ncsXJO7DAPo0+c1Fi7c7E+feuqxMbQmOYjohDJVnYXTCew9NtKzvxroE0kbjCoQqlKnl6wsuCawoWcY1cNE4mKDzSw2yhK4cHt1tf4No4qkp6dy4MARLrusE9On2wtGtDBHkMwMHep0EAcSOELIGxqyMJARRhYuzKNPnzcAn0jcwzG2KDkxR5DM+EYJVaS+6R3qaWEgI4z87GdPs3Xrfn/aROJihzmCZGbPHuczcMhoRaOEDKOGTJ26kiFD3vGn69atYyOCYow5gmTGBmhFlMLCQjZv3szBgwdjbUqt4uijC/jggwsBaNo0nSZN0lmzZk2MrUoc0tPTadOmDWlpaSFfY47AKLtwuxEWNm/eTKNGjWjfvj2S5NpL33+/l/z8vWRntyIzE77+eiedOjWPtVkJh6qyc+dONm/eTIcOHUK+zv7zk4ny1grwrd7lGz5qncNh4eDBg+YEgMWLt/jfNVat2ka3bseYE4gQIkLz5s2pqiZbrLWGjGgSyloBXjkI6xyuMcnsBDZu/ImcnC2eBmcdunU7JrZGJQHV+c1ZiyDZ8K4V4PvB+CQlfC0D6xw2asihQ4Vs317gT3fp0pyMjHoxtMioCGsRJBNr1sCnn5aoi/ro29fZ9u0Lfp0Rt6SkpJCVlUX37t257LLL+MmzZOeqVavo168fnTt3plOnTowdOxavwssHH3xAdnY2Xbt2pWfPntx9992Vlvftt7soLCyiXr00RKBevRSys1tFzAksXbqUm266KSL3DgeHDh3i6quvpmPHjvTu3ZsN5Ui5P/vss3Tr1o3u3bszZMgQ/wCD8ePH07FjR0SEHTt2+PPPnDmTkSNHBr1XdQjZEYiIDfCNd3burFhGIiMDWraMnj1GxKlfvz7Lli0jNzeXZs2aMWHCBAAOHDjAwIEDeeCBB1i3bh3Lly9n4cKFvPjiiwDk5uYyfPhwJk2axOrVq8nJyaFjx47lllNYWEROzhZ+/PEAy5dvBaBXr1acdFL5v6cjvhnsNeCJJ55gxIgRIecPR5lV4bXXXuOoo45i/fr13Hnnndx///1l8uTn5/P888+Tk5NDbm4uRUVFTJ06FYA+ffowZ84c2rVrV+qaAQMGMGPGDAoKCsrcrzpUGhoSkTOAvwIZQFsRORm4VVV/ExYLjMgROHPY5wR8HcDBFpI/1gS+IsLvfhf+tZyzsuC550LOfvrpp7NixQoAJk+eTJ8+fbjwQmcYZ4MGDRg/fjx9+/bl9ttv509/+hMPP/wwXbp0AZyWxbBhw8rcc9++fVx77a9ZuXIZIsKvf30nAwf+HxkZGexzW5hvv/02M2fOZOLEidxwww2kp6ezdOlS+vTpwzvvvMOyZcto6rZQO3XqxKeffkqdOnW47bbbyMvLA+C5556jT5/SsmR79+5lxYoVnHzyyQB8+eWX/Pa3v+XgwYPUr1+fN954g86dOzNx4kTeeecd9u3bR1FREbNmzeKOO+4gNzeXwsJCRo8ezeWXX86GDRu49tpr2b/fmeQ2fvx4zjjjjJC/32C89957jB49GoBBgwYxfPhwVLVMHP/IkSMcOHCAtLQ0CgoKaNWqFQA9e/YMel8RoW/fvsycOZOrrrqqRjZCaH0EzwL9gekAqrpcRM6ucclG5Ak2c7hOBY1A6xxOWIqKipg7d64/jLJq1Sp6BawLccIJJ7Bv3z727NlDbm5uSKGg22+/n/T0hkydOheA9u3r0qJFxUuKbN68mYULF5KSkkJRURHTpk3jxhtv5IsvvqBdu3a0bNmSa665hjvvvJMzzzyTvLw8+vfvX2auQU5ODt27d/enu3TpwoIFC0hNTWXOnDk89NBD/Pvf/wZgyZIlrFixgmbNmvHQQw/Rr18/Xn/9dX766SdOO+00zj//fI455hj++9//kp6eztdff82QIUPIyckpY/9ZZ53F3r17yxx/+umnOf/880sdy8/P57jjnGVZUlNTadKkCTt37iz1HbVu3Zp77rmHtm3bUr9+fS688EK/g66I7OxsFixYEDVHgKpuCvBg1ZCpNGKCd32BwM7gQFE5I3JU4c09nBw4cICsrCzy8/PJzMzkggsuCOv9v/xyAb///Ys0bZpOx47NQrpm8ODBpLjSJVdffTWPPfYYN954I1OnTuXqq68GYM6cOaxeXbK8+Z49e9i3bx8ZGRn+Y99//z3eFQt3797N9ddfz9dff42IUFhY6D93wQUX0KyZY99//vMfpk+fztNPPw04w3zz8vJo1aoVw4cPZ9myZaSkpPDVV18FtX/BggUh1TNUdu3axXvvvcd3331H06ZNGTx4MJMmTWLo0KEVXnfMMcewZUt4lnkPxRFscsNDKiJpwG8BmwYYj+zZ40weS+IhjcmGr4+goKCA/v37M2HCBEaMGEHXrl2ZP39+qbzffvstGRkZNG7cmG7durF48WJ/2MXHnj0H+eqrHwHIzm5FgwZpnHRSyzJOwPviGDizumHDhv79008/nfXr17N9+3beffddHnnkEQCKi4v5/PPPSU9Pr7Bu3ns/+uijnHvuuUybNo0NGzbQ17NuhrdMVeXf//43nTt3LnW/0aNH07JlS5YvX05xcXG5ZVelRdC6dWs2bdpEmzZtOHLkCLt376Z589JzKObMmUOHDh38Tu3KK69k4cKFlToCXwgsHITSWXwbcDvOwvP5QBZg/QPxSDBJCXMKSUGDBg14/vnnGTduHEeOHOFXv/oVn376KXPmzAGclsOIESO47z5nHeB7772XJ554wv9WXFxczMMP/9HvBMAJN11wwQX+Dmhw3m4BWrZsyZo1ayguLmbatGnl2iUiXHHFFdx1111kZmb6H5IXXnghL7zwgj/fsiD9K5mZmaxfv96f3r17N61btwZg4sSJ5ZbZv39/XnjhBf8IqaVLl/qvP/bYY6lTpw5///vfKSpnYMWCBQtYtmxZmS3QCQAMHDiQN998E3D6Svr161emf6Bt27Z8/vnnFBQUoKrMnTuXzMzMcu338dVXX5UKjdWEUBxBZ1X9laq2VNVjVHUoULmVRvQJXHx+925nC1x8vkmTkn6Dxo1jYKgRC3r27EmPHj2YMmUK9evX57333uPxxx+nc+fOnHTSSZx66qkMHz4cgB49evDcc88xZMgQTjyxCx07dmHTpo2A81PKzm5FSkoKjzzyCLt27aJ79+6cfPLJfPzxxwA8+eSTXHrppZxxxhkcW8kAhKuvvppJkyb5w0KAfxRNjx496Nq1Ky+99FKZ67p06cLu3bv9b+f33XcfDz74ID179qxwdNCjjz5KYWEhPXr0oFu3bjz6qCN495vf/IY333yTk08+mbVr15ZqRVSXm266iZ07d9KxY0eeeeYZnnzySQC2bNnCJZdcAkDv3r0ZNGgQp5xyCieddBLFxcXccsst/u+hTZs2bN68mR49enDzzTf77/3xxx8zYMCAGtsIIJWtDCkiS1T1lMqORYvs7GwN1oFjUPLw9z3ky1uI3tt5fOmlMGlSxE1LRtasWRPSm11tJzd3GwcPOg/WNm0a87OfZVRyRfR49tlnadSoUakHZDKwdetWrrnmGubOnRv0fLDfnogsVtXsYPnL7SMQkdOBM4CjReQuz6nGOGsQG7WRihafN4wQ2bJlL1u2OCJx3bsfU2tF4oYNG8Zbb70VazOiTl5eHuPGjQvb/SrqLK6LM3cgFWjkOb4HGBQ2C4zQCZwX4FtsPhCL+xs1IJ5E4tLT07n22mtjbUbUOfXUU8N6v3Idgap+AnwiIhNVdWNYSzWqR+C8gOosNm8Y5bBhwy527DjgT6elmUhcshDK8NECEXkK6Ab4x1Opar+IWWWUjzf041s/wNcxFriimLUMjBA5dKiwlBPIzGxBw4Z1Y2iREU1CcQT/AP4JXIozlPR6oGpi10Z4KG8egG+imK9z2ByAESLffPMjbds28YjEpdK9u7UCko1QHEFzVX1NRH7rCRctirRhRhCq0+nbvn3YzTDin8LCIr843K5dB8nObkWvXq1ibJURK0KZR+Cbp/29iAwQkZ5AaHPJjcjgnQcATqexT0I6JcVxGL7tu+9iY6NRKwgmQ7169TaWL9/KN9+sY9iwwQwefHbYZKijjclQhwlVrXDDCQk1AboDHwOLgcsquy5SW69evTRp8T3emzRxNl86JaVkO+20WFtpuKxevTrWJmjDhg39+9ddd50OG3afLlqUrwsWrNfWrdvprFmzVFV1//79etFFF+n48eNVVXXlypV6/PHH65o1a1RV9ciRI/riiy+G1bbCwsIa32PQoEG6bNmyqJZZFSZMmKC33nqrqqpOmTJFr7rqqjJ5Nm/erO3bt9eCggJVVR08eLC+8cYbqqq6ZMkS/e6777Rdu3a6fft2/zXFxcWalZWl+/fvD1pusN8ekKPlPFcrDQ2pqm+84m7gXAAR6VP+FUbECRSR8yw2YtRSaokM9dy5nwPw6afv06/f2Vx88cVAzWSo77jjDnJychARRo0axS9+8QuToXaJexlqEUkBrsLRGPpQVXNF5FLgIaA+ENxCI/J4O4e9ISLDCEJOzpZSMtTZ2a2YPHlDWGSox44dS5MmTVi5ciVQojVUESZDHV8y1K8BxwFfAs+LyBYgG3hAVd+tcclGzWnSxJGIMGo/MZChXrr0ew4cOMA111zA9u0/0L1717DLUM+ZM8e/mhbAUUcdVek1JkNdmtouQ50N9FDVYhFJB34ATlDVnWEp2ag+FgoyKmD79v1s3OgMJa5XL50pU/5LZmbTsMhQh4rJUDskggz1YVUtBlDVg8C3VXUCInKRiKwTkfUi8kA5ea4SkdUiskpEJlfl/oZhlGXr1v3+fRGhV69WYZGhDqYAajLUiS9D3UVEVrjbSk96pYisqOzGbh/DBOBioCswRES6BuTpBDwI9FHVbsDvqlsRw0hm8vP3kJPjhAm6dz+Go45KJzu7Vam5hdWVoc7MzKR79+58++23Zco1GeqKiXsZahFpV9GFWon+kKteOlpV+7vpB93r/uDJ8yfgK1X9a6gGJ7UMtamJxhXRkqH2isTVr5+aVPpAJkMdYRnqyh70IdAa2ORJbwZ6B+Q50TXwMxxp69Gq+mHgjUTkFuAWcJpRhmHAt9/u4scfk1skzmSow0NIi9dHkFSgE9AXaAPMF5GTVPUnbyZVfQV4BZwWQZRtNIxax6FDhaWcQLKKxJkMdXgIRWKiuuTjDD/10cY95mUzMF1VC1X1O+ArHMdgGEYQvv56J4WFRX6RuPr1U8nObpWUTsAIHyE5AhGpLyKdK89ZikVAJxHpICJ1gV8C0wPyvIvTGkBEWuCEisr2SBlGklNYWEROzhZ27z7kF4vr1atV0oWCjMhQqSMQkcuAZcCHbjpLRAIf6GVQ1SPAcGA2sAb4l6quEpHHRGSgm202sFNEVuPoGN1r8xQMozSrVm3zP/wBGjWyt38jvITSRzAaOA2YB6Cqy0SkQyg3V9VZwKyAYyM9+wrc5W5GIB06QDlqhUZy4BsS6qNnz5b+WbmGES5CkqFW1d0Bx6zDNhqYE0h66tRxhgw3b16f7OxWVXYCwWSofaxatYp+/frRuXNnk6GOEIkkQ/0acA2wAqcj9wXgpcqui9SWVDLUpVcWKNmMuKA6MtQ//XRAFy3K10WL8sNiQ6AM9eOPP66qqgUFBXr88cfr7NmzVdVkqCNFwshQA3cADwOHgMk4cf3Hw+eKjCoRhtmORgwIQYZ6777D1FHwjcrQjLQycgSlqIYM9YoVjijA5MmT6dOnj1/l0mSoTYa6Mrqo6sM4zsCIBTaTOKE5XFjEoYMeXRuBRhnh7RD2ylCDExYyGWqTofYRiiMYJyI/A94G/qmquTUu1QhO796weHGsrTAiQQVv7l/lbuPgQUcbp127Jhx9dPhafQcOHCArK4v8/HwyMzNNhhqToQ5GpZ3Fqnouzspk24GXXdG5R8JSulGaxYuhHMVDI7HYtGl3KZG4Zs0ckbhwOgFwpJqXLVvGxo0bUVW/UmjXrl1ZHPDSEUyGurpUV4b6yiuvBEpkqH3Knvn5+aWcgK9uwWSoc3NzmTFjRqlzwWSofffOy8sjMzOTZ5991i9DnZOTw+HDh4PW7ayzziIrK6vM5lNy9eKToQZCkqFOS0vzy1BXRrRkqP2o6g+q+jxwG86cgjB2Vxt+zAkkPEVFRSxevMUvFb1q1TYAjj++WUTLNRnqEkyGuiyhTCjLFJHRrhT1C8BCHLkIwzCqwLff/sjSpVv9XT5160ZXJM5kqB1Mhros5cpQ+zOI/A/4J87M4PAEpGpAQstQB8pMm+x0XOOVAj50qJCVK7f7z3XrdjT166fFyrSEwWSowyNDHUofwemq+lxtcAJJQ9OmJQvUG3FNoEhcgwaOSJw5gfAwbNgw6tWrF2szok7UZKhF5F+qepUbEvK+kgrOpKYeYbPCKJ80e2DEI3l5O9i48SdatGjC8uVbyc5uRa9erWJtVsJhMtThoaLho791Py8Na4lG5fhkAKxVEJd06zaB1at38MEHzljwxo2T743ViC8qWqHse3f3N6p6v/eciPwRuL/sVUaVGDoUZs4se7xvX+dz3z4IGDJn1G5ExpRKm0icEQ+EMnw02AyUi8NtSFIycybsDtTz85CRAS1bRs8eo8ZkZDihvJtvPpl27ZqaEzDigor6CIYBvwGOF5EVnlONgM8ibVhC8sorMHlySXrfPkhJcTRjAD75xPmcN8/59LUMjFrLtGmruPLKtwFQHcXevQ/5zwVKIhhGbaWiFsFk4DKcVcUu82y9VLXiuc9GcCZPrlR4zIgfGjf+g98JABQUFMTQmuCYDHVsiRcZ6oocgarqBuB2YK9nQ0QiOw0ykcnKct74581zQj8ZGSVpIy545pnPEBnD3r2OBEHDhmmojqJBgwYxtqwsPomJ3NxcmjVr5p8FfODAAQYOHMgDDzzAunXrWL58OQsXLuTFF18EIDc3l+HDhzNp0iRWr15NTk4OHTt2DKttFU36CpUnnniCESNGRLXMqvDaa69x1FFHsX79eu68807uv79s12p+fr5/Al1ubi5FRUV+/aY+ffowZ84c2rVrV+qaAQMGMGPGjLC9fFQ0amgyzoihxTjDR73zohU4PiwWJDKBoaBPP3VkJAKlhQPTvpDQsmUlYSOj1vDGG8v9+xMnDuT664NLBZciBBnqKmMy1CZDHWkZalW91P0MaVlKIwi+UJDvYV5VLaGsLLjmmjAbZVSHO+6Yxfjxi1AdxcqVv+HGG6fxxhtXxNqskDEZapOhrohKZahFpA+wTFX3i8hQ4BTgOVXNq3HpyYAvFARlJSNS3a/f11z1zRuwMFGtoaCggEaNnqK42En37PkSS5feVnUnUIU393BiMtQOJkNdMaEMH/0LUCAiJwN3A98Afw9L6clKaqqzFRU5W9++zuY2pY3aweDB/6RhwxIncPzxTVi69LbYGlVFTIa6bJkmQ12WUBzBEXe9y8uB8ao6AWcIqREOvBISNm+g1pCXt4O3317rT69ZczvffPO72BlUQ0yGugSToS5LKI5gr4g8CFwLvC8idQATwKkJvtFCKSkQONKkEsleI7Kcf/6b5OXtoG3bFtSvn8Kppx6L6ii6dGlR+cW1HJOhdjAZ6rKEIkP9M+AaYJGqLhCRtkBfVf1bWCyoInElQ+0b/RPYR9CkSUmeY46BVh4xsmuuAfdHYESPvLwdtGtX8marOqrG9wwmBWyEF5OhDo8MdaWdxar6g4j8AzhVRC4FvoyVE0gYPJN6jNjTqdOfWb/+J3/6sss6xc4Yo0oMGzaMt956K9ZmRJ2oyVD7EJGrgKeAeThzCV4QkXtV9e0KLzTg++9h61aTiqjFeEXi6tSBvXvvrZUTw4zgmAx1eAilj+Bh4FRVvV5VrwNOAx4NqxWJytatNhKoluKbkdmoUV0AbrvtFIqKaufsYMOINJW2CIA6qrrNk95JiIveG5RISEDZGcRG1Jk6dSVDhrwDOP0Ae/Y8GGOLDCP2hOIIPhSR2cAUN301MCtyJiUQ+/Y58wRSQ/majUjTqNET7NtXMsmooKDAWgCGQWhrFt8LvAz0cLdXAheqMcqhqpISRkR48sn5iIzxO4GMjNorEmcYsaBcRyAinUTkPRHJBQYD41T1LlUtf3ZIspOR4YR/fJtRK/jHP3L9+1OmXFlqzYBEx2SoY0u8yFCjqkE3YAHwa6AzcA/wTnl5K7jHRcA6YD3wQAX5foGjaJpd2T179eqltRZHRajslpLibL59I+Lcdtt0hdGl0tFm9erVUS8zkIYNG/r3r7vuOn388cdVVbWgoECPP/54nT17tqqq7t+/Xy+66CIdP368qqquXLlSjz/+eF2zZo2qqh45ckRffPHFsNpWWFhY43sMGjRIly1bFtUyq8KECRP01ltvVVXVKVOm6FVXXVUmz+bNm7V9+/ZaUFCgqqqDBw/WN954Q1VVlyxZot999522a9dOt2/f7r+muLhYs7KydP/+/UHLDfbbA3K0nOdqRcHrRqr6qru/TkSWVMXBiEgKMAFnqcvNwCIRma6qqwPyNQJ+C3xRlfvXanxvVT4ROVuMPmqUJxL3l79cFlvDTIbaZKjjUYYaSBeRnpSsQ1Dfm1bVyhzDacB6Vf0WQESm4ugVrQ7INxb4I3BvFW2vvQSGhXwOYPfu0rOKjbAyYMAkZs36xp/u3LlZ3InERQqToTYZ6oqoyBF8DzzjSf/gSSvQr5J7twY2edKbgd7eDCJyCnCcqr4vIuU6AhG5BbgFHIGmuMIrKtekCVx6aexsSWDWrt1Rygls3Hg7bdvWIn0gk6H2YzLUpakNMtQVLUxzblhKKAdXvO4Z4IbK8qrqK8Ar4GgNRdKusFCJfpMRPvr2fYO//e0yunRpQf36qfTs+TM++6z2dh5GG58MdUFBAf3792fChAmMGDGCrl27Mn/+/FJ5g8lQ+8IuVaW6MtSPPPIIUCJDnZ6eXmHdgslQT5s2jQ0bNtDXM6M/mAx1586dS91v9OjRfhnq4uLicsuuSovAJ0Pdpk2bkGSoAb8MdWWOINoy1NUlHzjOk27jHvPRCOgOzBORDcDPgekiElQUyTC8rF27A5ExfPJJnl8srqDgYXMC5WAy1CWYDHVZIukIFgGdRKSDiNQFfglM951U1d2q2kJV26tqe+BzYKCqxom0qBErOnR4lszMkofPoEFdYmhN/GAy1A4mQ12WSmWoa3RzkUuA54AU4HVV/b2IPIYzjGl6QN55wD2VOYJaLUMduBSlEXa8InEpKbBnT+0ViTMZ6shjMtThkaGutEUgDkNFZKSbbisip4VirKrOUtUTVfUEVf29e2xkoBNwj/e11oBRHoEiccOHn8qRIzY7ONkZNmwY9erVi7UZUSfqMtTAi0Axziihx4C9wL+B8OqgGkYQ3nxzKTfc4Lw3mEicEYjJUIeHUBxBb1U9RUSWAqjqLjfmbxgRpWHDJygoMJE4w4g0oXQWF7qzhBVARI7GaSEYRkQYO3YeImP8TqBx47omEmcYESQUR/A8MA04RkR+D3wKPBFRq4yk5u23S2aQvvPOIHbvtnCQYUSSUGSo/wHcB/wBZ7bx/6lq8i0SakSUG2+c5h8RtHz5MIYPPxXVUVxxRbcYW2YYiU8oo4baAgXADJx5APvdY4ZRYwoKCqhTZwwTJzpiaL16vQzACy9cEkuzEgaToY4tcS9D7duAlcAK9/Nr4AiwqrLrIrXFhQy1ERL9+/9NYbR/69p1fKxNCismQ10xJkPtUNtlqH2O4iRv2hWK+034XJGRjKxdu4PZs0tmqtY6kbhwYzLUJkMdpzLUQVHVJSLSu/KchlGWPn1eY8qUy+nSpQUNGqRx6qnHMm/ejbE2K+ExGWqToa6ISh2BiNzlSdYBTgHCo30a77zyCkyeHGsr4oK1a3f49YHatZuA6ij270+eJSNNhroEk6EuTW2QoQ5l+Ggjz1YPeB9ngRlj8uTwN/cTkHbtniklEvfLX5r+TrTwyVBv3LgRVfUrhXbt2pXFixeXyhtMhrq6VFeG+sorrwRKZKh9yp75+fmlnICvbsFkqHNzc5kxY0apc8FkqH33zsvLIzMzk2effdYvQ52Tk8Phw4eD1u2ss84iKyurzOZTcvXik6EGQpKhTktL88tQV0bUZKjdiWSNVHWMu/1eVf+hqgcrui4hGDrUWVnMu9WpU3px+k8+cVYd++QTZzPKIDKGvDynGZ2aKqiOYsqUmjdljaphMtQlmAx1Wcp1BCKSqqpFQJ/y8iQ0M2c6D3kvpioaMoEicffffzqFhWEc7mZUGZOhdjAZ6rKUK0MtIkvU0Rj6C86yk28B+33nVfWdsFhQRaImQx248DyUlZlOdbtYfD8634pI8+ZF1rZazKuv5nDLLe8DjkhcMmMy1JHHZKjDI0MdyqihdGAnjvqo4ixer0BMHEHYGDrUeev3cfiws/nwNQsDF6KHEifhy+NzAMuWOUP6kpQGDR7nwIGS5rSJxBmRZtiwYbz1VvIJHURThvoYd8RQLiUOwEf8x0h8oZ8mTZz04cPOg90dzRAyXkeRlQXXXBM2E+OFUaPm8thjn/rTTZvWZdcu0wcyIo/JUIeHihxBCpBBaQfgI/4dAThOwBf6CQzrBIZ9oGy4yJdO4lAQwLvvlgyzmzVrCBdffGIMrTEMo6pU5Ai+V9XHomZJtNmzx4n1B4Z+KktDiQPwtiiSjGuvfYdJk1aiOorly4dxzz0f8vTTF8XaLMMwqkFFjiBYSyBxqO4IoLS0kv0mTeDSS8NjT5xQUFBARsZT/q+vV6+XWbz4VnMChhHHVOQIzouaFbHknHOcz0/dGPeZZ5akMzJKjxpKcvr2fYNPPsnzp7t3P5rFi2+NoUWGYYSDcucRqOqP0TSk1pGRAS1bxtqKWsPatTtKOYHt2+9l5UrTHqztmAx1bEkYGeratoVNhjpQMrpJE2fzcc45zpbknHrqy7pxoyN/m5Hxez3vvIkxtih+MBnqijEZaoe4kKFOeLwdvykpNifAZcmSTfTq9TpQIhK3d28SicSFG5OhNhnqRJKhTlhSUqBu3ZJ0ks4JAGjdehxbtuzzp2+4oUcMrTHCgclQmwx1RZgj8L31+1oAST4nwLduMDgicaYPFCZMhtqPyVCXJl5kqJODJG4BQIlIXOPGTqto5MgzzQkkACZDXbZMNRnqMpgjmDevZHMV/5KJCRM+R2QMDRs+BcDu3Q+iOooxY5Jj9HCyYDLUJZgMdVnMESQx9es/zvDhs/1pX6vASExMhtrBZKjLUq4MdW0lbDLUgZLSScQ993zIuHFf+NPNmqWzc+f9MbQoMTEZ6shjMtThkaG2FkESMnfuBs/+UHMCRtwybNgw6tWrF2szok64Zagj6ghE5CIRWSci60XkgSDn7xKR1SKyQkTmiki7iBnToUPpZSaTjCFD/oXIGAoKCli69DZGjjwT1VH063dCrE0zjGqTzDLUWWGc5xQxR+CudzwBuBjoCgwRka4B2ZYC2araA3gb+FOk7KGcqd2JTkFBAXXqjGHqVGcM9lln/R3AOoMNw/ATyRbBacB6Vf1WVQ8DU4HLvRlU9WNV9fVQfg60iaA9ScfZZ79Ow4YlSqFZWS1NJM4wjDJEckJZa2CTJ70Z6F1B/puAD4KdEJFbgFvAGWoVNhI4RLR27Q4WLCj5+rdvv5cWLWzZSMMwylIrOotFZCiQDTwV7LyqvqKq2aqa7Z1JWC18cnNNmkDjxjW7Vy2kV6+XycvbQZcuLcjISOOSS05AdZQ5AcMwyiWSjiAfOM6TbuMeK4WInA88DAxU1UMRtMehaVNn27074kVFkyVLNiEyhiVLfqBdO2eCz969D/H++xVPUzcSG5Ohji3xIkMdSUewCOgkIh1EpC7wS2C6N4OI9ARexnEC2yJoS1kSaHWxY4992q8UCnDzzSfH0BqjNuGTmMjNzaVZs2b+WcAHDhxg4MCBPPDAA6xbt47ly5ezcOFCXnzxRQByc3MZPnw4kyZNYvXq1eTk5NCxY8ew2lbRpK9QeeKJJxgxYkRUy6wKr732GkcddRTr16/nzjvv5P77yw7Vzs/P90+gy83NpaioyK/f1KdPH+bMmUO7dqUHVA4YMIAZM2aEbRJoxPoIVPWIiAwHZgMpwOuqukpEHsPRxZ6OEwrKAN5yp13nqerASNkEJNyKY16RuLS0Ohw+/GgMrTHKxWSoTYY6WWWoVXUWMCvg2EjPfllxDiMkCgoKaNCgAU2b1uOnnw7x2GPn8OijfWNtllFLMRlqk6GuCJOhjjOeeeYz7r7bEQpTHcWuXWXm6Rm1EZOh9mMy1KWpDTLU5gjiiPT0sRw6VOxP+1oFhlEevj6CgoIC+vfvz4QJExgxYgRdu3Zl/vz5pfIGk6H2hV2qSnVlqB955BGgRIY6PT29wroFk6GeNm0aGzZsoK9vtUGCy1B37ty51P1Gjx7tl6EuLi4ut+yqtAh8MtRt2rQJSYYa8MtQV+YITIY6ybjjjlmIjPE7gaOPro/qKHMCRsiYDHUJJkNdFnMEccDChSUTwz777Ea2bbsvhtYY8YrJUDuYDHVZkkeGOs5kp6+4YirvvruO/fvvpUGDBowdO886g+MMk6GOPCZDbTLUCUlBQQEiY3j33XUA9O07CcCcgGEEwWSow4N1Ftcifv7zV/nii5JRAKeeeixffpl8y2caRqgkswx1ODFHUEtYu3ZHKSdgInGGYUQLCw3FmJNP/gtr1zoicY0a1eWyyzqZSJxhGFHFWgQxYuHCPPr0eQOAzMwJqI5iz54HY2yVYRjJiDmCGNCy5VNs21YiFjV8eHjjfYZhGFXBQkNRRmSM3wnUrVsH1VG88MIlMbbKSFRMhjq2mAy1UQqfXOxRRznT1v/wh3M5dMiUQo3IYjLU4S+zKiS9DLXh8OST83nwQWe2peoofvyx7A/BSAJMhtpkqJNVhjrZqVdvLIcPm0icEXtMhtpkqCvCHEEEGDZsBi+9tMSfbtmyIT/8cE8MLTJijslQ+zEZ6tLUBhlq6yOIAIsXf+/f/+yzG80JGDHD10ewceNGVNXfR9C1a1cWL15cKm8wGerqUl0Z6iuvvBIokaH2KXvm5+eXcgK+ugWToc7NzWXGjBmlzgWTofbdOy8vj8zMTJ599lm/DHVOTg6HDx8OWrezzjqLrKysMptPydWLT4YaCEmGOi0tzS9DXRkmQ10LGTBgEiJjKCgo4Msvb+EPfzgX1VGccUbbWJtmGCZD7cFkqMtijqCG7NjhiMTNmvUNUCIS98ADZ8fSLMMog8lQO5gMdVlMhroG9Or1MkuW/OBPn3FGGz77rPaOaTaii8lQRx6ToTYZ6piydu0OvxMQgf377zUnYBhRxmSow4M5girSrdsEv0hc48Z1GTSoC8XFtmykYcSCZJahzsrKCtv9bPhoiHz00Tecd54T//eJxO3ebSJxhmHEP+YIQqBFiz+xc+cBf/ruu3vH0BrDMIzwYo6gEkTG+Pfr1avDwYOmD2QYRmJhfQTlsGNHaZG4cePONydgGEZCYo4ggLFj5yEyhqOPfgqAH3+8H9VR3HVXn4ovNIxaiMlQxxaToY5D0tLGMnLkJ/50uCReDSNWmAx1+MusCiZDHUf8+tfv8te/LvenW7XKID+/9r39GHGMyVCbDLXJUNduli/f5t9fvPj/ccopx8XQGsMIPyZDbTLUFZG0juCii/7O7Nnfsn//vXz55S1MmPA5t9/+81ibZSQqJkPtx2SoS5PwMtQicpGIrBOR9SLyQJDz9UTkn+75L0SkfSTtgRKRuNmzHQEtn0icOQEjETEZ6rJlmgx1WSLmCEQkBZgAXAx0BYaISNeAbDcBu1S1I/As8MdI2QOwlzT/aCCAc85py5df3hLJIg2jVmAy1CWYDHVZItkiOA1Yr6rfquphYCpweUCey4E33f23gfMk8FsKE8XASloCJSJx8+bdGImiDKNWYjLUDiZDXZaIyVCLyCDgIlW92U1fC/RW1eGePLluns1u+hs3z46Ae90C3ALQtm3bXhs3bqyOQaylOWN++SJTptS8c8UwKsNkqCOPyVAnkQy1qr6iqtmqmu3tHKriTeiiO8wJGEYCYTLU4SGSo4byAe84zDbusWB5NotIKtAE2BlBmwzDSCCSWYY6nESyRbAI6CQiHUSkLvBLYHpAnunA9e7+IOAjjbcl0wyjAuznbESb6vzmIuYIVPUIMByYDawB/qWqq0TkMREZ6GZ7DWguIuuBu4AyQ0wNI15JT09n586d5gyMqKGq7Ny5k/T09CpdlzxrFhtGlCksLGTz5s1lxtEbRiRJT0+nTZs2pKWllTpeUWdx0s4sNoxIk5aWRocOHWJthmFUSlyMGjIMwzAihzkCwzCMJMccgWEYRpITd53FIrIdqMbUYgBaADsqzZVYWJ2TA6tzclCTOrdT1aAzcuPOEdQEEckpr9c8UbE6JwdW5+QgUnW20JBhGEaSY47AMAwjyUk2R/BKrA2IAVbn5MDqnBxEpM5J1UdgGIZhlCXZWgSGYRhGAOYIDMMwkpyEdAQicpGIrBOR9SJSRtFUROqJyD/d81+ISPsYmBlWQqjzXSKyWkRWiMhcEWkXCzvDSWV19uT7hYioiMT9UMNQ6iwiV7l/61UiMjnaNoabEH7bbUXkYxFZ6v6+L4mFneFCRF4XkW3uCo7BzouIPO9+HytE5JQaF6qqCbUBKcA3wPFAXWA50DUgz2+Al9z9XwL/jLXdUajzuUADd39YMtTZzdcImA98DmTH2u4o/J07AUuBo9z0MbG2Owp1fgUY5u53BTbE2u4a1vls4BQgt5zzlwAfAAL8HPiipmUmYovgNGC9qn6rqoeBqcDlAXkuB950998GzhMRiaKN4abSOqvqx6pa4CY/x1kxLp4J5e8MMBb4I5AIWtCh1PnXwARV3QWgqtuibGO4CaXOCjR295sAW6JoX9hR1fnAjxVkuRz4mzp8DjQVkWNrUmYiOoLWwCZPerN7LGgedRbQ2Q00j4p1kSGUOnu5CeeNIp6ptM5uk/k4VX0/moZFkFD+zicCJ4rIZyLyuYhcFDXrIkModR4NDBWRzcAs4I7omBYzqvr/Xim2HkGSISJDgWzgnFjbEklEpA7wDHBDjE2JNqk44aG+OK2++SJykqr+FEujIswQYKKqjhOR04G/i0h3VS2OtWHxQiK2CPKB4zzpNu6xoHlEJBWnObkzKtZFhlDqjIicDzwMDFTVQ1GyLVJUVudGQHdgnohswImlTo/zDuNQ/s6bgemqWqiq3wFf4TiGeCWUOt8E/AtAVf8HpOOIsyUqIf2/V4VEdASLgE4i0kFE6uJ0Bk8PyDMduN7dHwR8pG4vTJxSaZ1FpCfwMo4TiPe4MVRSZ1XdraotVLW9qrbH6RcZqKrxvM5pKL/td3FaA4hIC5xQ0bdRtDHchFLnPOA8ABHJxHEE26NqZXSZDlznjh76ObBbVb+vyQ0TLjSkqkdEZDgwG2fEweuqukpEHgNyVHU68BpO83E9TqfML2Nncc0Jsc5PARnAW26/eJ6qDoyZ0TUkxDonFCHWeTZwoYisBoqAe1U1blu7Idb5buBVEbkTp+P4hnh+sRORKTjOvIXb7zEKSANQ1Zdw+kEuAdYDBcCNNS4zjr8vwzAMIwwkYmjIMAzDqALmCAzDMJIccwSGYRhJjjkCwzCMJMccgWEYRpJjjsColYhIkYgs82ztK8i7LwzlTRSR79yylrgzVKt6j7+KSFd3/6GAcwtraqN7H9/3kisiM0SkaSX5s+JdjdOIPDZ81KiViMg+Vc0Id94K7jERmKmqb4vIhcDTqtqjBversU2V3VdE3gS+UtXfV5D/BhzV1eHhtsVIHKxFYMQFIpLhrqOwRERWikgZpVEROVZE5nvemM9yj18oIv9zr31LRCp7QM8HOrrX3uXeK1dEfuceaygi74vIcvf41e7xeSKSLSJPAvVdO/7hntvnfk4VkQEemyeKyCARSRGRp0Rkkasxf2sIX8v/cMXGROQ0t45LRWShiHR2Z+I+Blzt2nK1a/vrIvKlmzeYYquRbMRae9s224JtOLNil7nbNJxZ8I3dcy1wZlX6WrT73M+7gYfd/RQcvaEWOA/2hu7x+4GRQcqbCAxy9wcDXwC9gJVAQ5xZ2auAnsAvgFc91zZxP+fhrnngs8mTx2fjFcCb7n5dHBXJ+sAtwCPu8XpADtAhiJ37PPV7C7jITTcGUt3984F/u/s3AOM91z8BDHX3m+JoETWM9d/btthuCScxYSQMB1Q1y5cQkTTgCRE5GyjGeRNuCfzguWYR8Lqb911VXSYi5+AsVvKZK61RF+dNOhhPicgjODo1N+Ho10xT1f2uDe8AZwEfAuNE5I844aQFVajXB8CfRaQecBEwX1UPuOGoHiIyyM3XBEcs7ruA6+uLyDK3/muA/3ryvykinXBkFtLKKf9CYKCI3OOm04G27r2MJMUcgREv/Ao4GuilqoXiKIqmezOo6nzXUQwAJorIM8Au4L+qOiSEMu5V1bd9CRE5L1gmVf1KnLUOLgEeF5G5qvpYKJVQ1YMiMg/oD1yNs9AKOKtN3aGqsyu5xQFVzRKRBjj6O7cDz+MswPOxql7hdqzPK+d6AX6hqutCsddIDqyPwIgXmgDbXCdwLlBmzWVx1mHeqqqvAn/FWe7vc6CPiPhi/g1F5MQQy1wA/J+INBCRhjhhnQUi0gooUNVJOGJ+wdaMLXRbJsH4J45QmK91Ac5DfZjvGhE50S0zKOqsNjcCuFtKpNR9UsQ3eLLuxQmR+ZgN3CFu80gcVVojyTFHYMQL/wCyRWQlcB2wNkievsByEVmK87b9Z1XdjvNgnCIiK3DCQl1CKVBVl+D0HXyJ02fwV1VdCpwEfOmGaEYBjwe5/BVgha+zOID/4CwMNEed5RfBcVyrgSXiLFr+MpW02F1bVuAszPIn4A9u3b3XfQx09XUW47Qc0lzbVrlpI8mx4aOGYRhJjrUIDMMwkhxzBIZhGEmOOQLDMIwkxxyBYRhGkmOOwDAMI8kxR2AYhpHkmCMwDMNIcv4/qlB+VYNzTC0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#y_bma_pred = []\n",
    "predictions_bma = []\n",
    "tp_bma = []\n",
    "tn_bma = []\n",
    "fn_bma = []\n",
    "fp_bma = []\n",
    "auc_bma_list = []\n",
    "acc_bma_list = []\n",
    "rec_pos = []\n",
    "rec_neg = []\n",
    "prec_pos = []\n",
    "prec_neg = []\n",
    "f1_pos = []\n",
    "f1_neg = []\n",
    "\n",
    "for j in range(0, 10):\n",
    "    sum_prob0_bma =[]\n",
    "    sum_prob1_bma =[]\n",
    "    n_fold_tags = f\"../data/results2strategy/tags/sintest/probs_sin_test_fold_{j+1}_tags.csv\"\n",
    "    n_fold_text = f\"../data/results2strategy/text/sintest/probs_sin_test_fold_{j+1}_text.csv\"\n",
    "    n_fold_caps = f\"../data/results2strategy/caps/sintest/probs_sin_test_fold_{j+1}_caps.csv\"\n",
    "    #data_probs = pd.read_csv(n_fold, sep=\"\\t\")\n",
    "    probs_tags_test = pd.read_csv(n_fold_tags, sep=\"\\t\")\n",
    "    probs_text_test = pd.read_csv(n_fold_text, sep=\"\\t\")\n",
    "    probs_caps_test = pd.read_csv(n_fold_caps, sep=\"\\t\")\n",
    "    #probs_tags_test.sort_values(by=['file_name'], ascending=True, inplace=True)\n",
    "    #probs_text_test.sort_values(by=['file_name'], ascending=True, inplace=True)\n",
    "    #probs_caps_test.sort_values(by=['file_name'], ascending=True, inplace=True)\n",
    " \n",
    "    file_names_test = probs_tags_test[\"file_name\"]\n",
    "    y_test = probs_caps_test[\"GROUND TRUTH\"]\n",
    "    labels_bma = []\n",
    "    y_prob_auc = []\n",
    "    \n",
    "    for i in range(0,150):\n",
    "      \n",
    "        tags_prob0 = (probs_tags_test[\"SVM PROB 0\"][i]* score_tags_test[\"SCORE 0 SVM\"][j]) + (probs_tags_test[\"KNN PROB 0\"][i]* score_tags_test[\"SCORE 0 KNN\"][j])+ (probs_tags_test[\"NB PROB 0\"][i]* score_tags_test[\"SCORE 0 NB\"][j]) +  (probs_tags_test[\"DT PROB 0\"][i]* score_tags_test[\"SCORE 0 DT\"][j]) +  (probs_tags_test[\"MLP PROB 0\"][i]* score_tags_test[\"SCORE 0 MLP\"][j])\n",
    "        text_prob0 = (probs_text_test[\"SVM PROB 0\"][i]* score_text_test[\"SCORE 0 SVM\"][j]) + (probs_text_test[\"KNN PROB 0\"][i]* score_text_test[\"SCORE 0 KNN\"][j])+ (probs_text_test[\"NB PROB 0\"][i]* score_text_test[\"SCORE 0 NB\"][j]) +  (probs_text_test[\"DT PROB 0\"][i]* score_text_test[\"SCORE 0 DT\"][j]) +  (probs_text_test[\"MLP PROB 0\"][i]* score_text_test[\"SCORE 0 MLP\"][j])\n",
    "        caps_prob0 = (probs_caps_test[\"SVM PROB 0\"][i]* score_caps_test[\"SCORE 0 SVM\"][j]) + (probs_caps_test[\"KNN PROB 0\"][i]* score_caps_test[\"SCORE 0 KNN\"][j])+ (probs_caps_test[\"NB PROB 0\"][i]* score_caps_test[\"SCORE 0 NB\"][j]) +  (probs_caps_test[\"DT PROB 0\"][i]* score_caps_test[\"SCORE 0 DT\"][j]) +  (probs_caps_test[\"MLP PROB 0\"][i]* score_caps_test[\"SCORE 0 MLP\"][j])\n",
    "        tags_prob1 = (probs_tags_test[\"SVM PROB 1\"][i]* score_tags_test[\"SCORE 1 SVM\"][j]) + (probs_tags_test[\"KNN PROB 1\"][i]* score_tags_test[\"SCORE 1 KNN\"][j])+ (probs_tags_test[\"NB PROB 1\"][i]* score_tags_test[\"SCORE 1 NB\"][j]) +  (probs_tags_test[\"DT PROB 1\"][i]* score_tags_test[\"SCORE 1 DT\"][j]) +  (probs_tags_test[\"MLP PROB 1\"][i]* score_tags_test[\"SCORE 1 MLP\"][j])\n",
    "        text_prob1 = (probs_text_test[\"SVM PROB 1\"][i]* score_text_test[\"SCORE 1 SVM\"][j]) + (probs_text_test[\"KNN PROB 1\"][i]* score_text_test[\"SCORE 1 KNN\"][j])+ (probs_text_test[\"NB PROB 1\"][i]* score_text_test[\"SCORE 1 NB\"][j]) +  (probs_text_test[\"DT PROB 1\"][i]* score_text_test[\"SCORE 1 DT\"][j]) +  (probs_text_test[\"MLP PROB 1\"][i]* score_text_test[\"SCORE 1 MLP\"][j])\n",
    "        caps_prob1 = (probs_caps_test[\"SVM PROB 1\"][i]* score_caps_test[\"SCORE 1 SVM\"][j]) + (probs_caps_test[\"KNN PROB 1\"][i]* score_caps_test[\"SCORE 1 KNN\"][j])+ (probs_caps_test[\"NB PROB 1\"][i]* score_caps_test[\"SCORE 1 NB\"][j]) +  (probs_caps_test[\"DT PROB 1\"][i]* score_caps_test[\"SCORE 1 DT\"][j]) +  (probs_caps_test[\"MLP PROB 1\"][i]* score_caps_test[\"SCORE 1 MLP\"][j])\n",
    "        \n",
    "        marginale_1_ = tags_prob1 + text_prob1 + caps_prob1\n",
    "        marginale_0_ = tags_prob0 + text_prob0 + caps_prob0\n",
    "        \n",
    "        label_norm_0, label_norm_1 = evaluation_metrics.normalize(marginale_0_,marginale_1_)\n",
    "        sum_prob0_bma.append(label_norm_0)\n",
    "        sum_prob1_bma.append(label_norm_1)\n",
    "        #y_neg = nb_probs_neg[i] + svm_probs_neg[i] +rf_probs_neg[i]\n",
    "        #y_pos = nb_probs_pos[i] +svm_probs_pos[i] +rf_probs_pos[i]\n",
    "        y_prob_auc.append(marginale_1_)\n",
    "        if label_norm_0 > label_norm_1:\n",
    "        #if probs_sum_0[i] > probs_sum_1[i]:\n",
    "          labels_bma.append(0)\n",
    "        else:\n",
    "          labels_bma.append(1)\n",
    "        #if y_neg > y_pos:\n",
    "        #  y_bma_pred.append(0)\n",
    "        #else:\n",
    "      #  y_bma_pred.append(1)\n",
    "##########################\n",
    " \n",
    "    \n",
    "    #probs_name = f'../data/results2strategy/tags/sintest/probs_sin_test_fold_{j+1}_tags.csv'\n",
    "    #data_probs.to_csv(probs_name, sep=\"\\t\")\n",
    "    tn_b, fp_b, fn_b, tp_b = confusion_matrix(y_test, labels_bma).ravel()\n",
    "    tp_bma.append(tp_b)\n",
    "    tn_bma.append(tn_b)\n",
    "    fn_bma.append(fn_b)\n",
    "    fp_bma.append(fp_b)\n",
    "    rec_pos_bm = tp_b/ (tp_b + fn_b) ###True postive rate recall classe 1\n",
    "    fn_rate_bm = fn_b/ (tp_b+ fn_b)\n",
    "    prec_mis_bm =  tp_b/ (tp_b + fp_b)\n",
    "    prec_notmis_bm = tn_b/ (tn_b + fn_b)\n",
    "    rec_neg_bm = tn_b / (tn_b+ fp_b)\n",
    "    f1_1_bm= (2* (prec_mis_bm * rec_pos_bm)) / (prec_mis_bm+ rec_pos_bm) \n",
    "    f1_0_bm = (2* (prec_notmis_bm * rec_neg_bm)) / (prec_notmis_bm + rec_neg_bm)\n",
    "    false_positive_rate_bma = fp_b / (fp_b+ tn_b)\n",
    "    rec_pos.append(rec_pos_bm) \n",
    "    rec_neg.append(rec_neg_bm) \n",
    "    f1_pos.append(f1_1_bm)   \n",
    "    f1_neg.append(f1_0_bm)\n",
    "    prec_pos.append(prec_mis_bm)\n",
    "    prec_neg.append(prec_notmis_bm)\n",
    "    \n",
    "    fpr_bma, tpr_bma, thresholds_bma = roc_curve(y_test, y_prob_auc)\n",
    "    roc_auc_bma = auc(fpr_bma, tpr_bma)\n",
    "    evaluation_metrics.printResult(labels_bma, y_prob_auc, y_test)\n",
    "    auc_bma_list.append(roc_auc_bma)\n",
    "    acc_bma = accuracy_score(y_test,labels_bma)\n",
    "    print(\"ACC BMA \", acc_bma)\n",
    "    print(\"AUC BMA \", roc_auc_bma)\n",
    "    acc_bma_list.append(acc_bma)\n",
    "    predictions_bma.append(labels_bma)\n",
    "  \n",
    "    probs0_caps_svm = probs_caps_test[\"SVM PROB 0\"]\n",
    "    probs0_caps_knn = probs_caps_test[\"KNN PROB 0\"]\n",
    "    probs0_caps_mlp = probs_caps_test[\"MLP PROB 0\"]\n",
    "    probs0_caps_dtr = probs_caps_test[\"DT PROB 0\"]\n",
    "    probs0_caps_nb  = probs_caps_test[\"NB PROB 0\"]\n",
    "    probs1_caps_svm = probs_caps_test[\"SVM PROB 1\"]\n",
    "    probs1_caps_knn = probs_caps_test[\"KNN PROB 1\"]\n",
    "    probs1_caps_mlp = probs_caps_test[\"MLP PROB 1\"]\n",
    "    probs1_caps_dtr = probs_caps_test[\"DT PROB 1\"]\n",
    "    probs1_caps_nb  = probs_caps_test[\"NB PROB 1\"]\n",
    "    \n",
    "    probs0_text_svm = probs_text_test[\"SVM PROB 0\"]\n",
    "    probs0_text_knn = probs_text_test[\"KNN PROB 0\"]\n",
    "    probs0_text_mlp = probs_text_test[\"MLP PROB 0\"]\n",
    "    probs0_text_dtr = probs_text_test[\"DT PROB 0\"]\n",
    "    probs0_text_nb  = probs_text_test[\"NB PROB 0\"]\n",
    "    \n",
    "    probs1_text_svm = probs_text_test[\"SVM PROB 1\"]\n",
    "    probs1_text_knn = probs_text_test[\"KNN PROB 1\"]\n",
    "    probs1_text_mlp = probs_text_test[\"MLP PROB 1\"]\n",
    "    probs1_text_dtr = probs_text_test[\"DT PROB 1\"]\n",
    "    probs1_text_nb  = probs_text_test[\"NB PROB 1\"]\n",
    "\n",
    "    probs0_tags_svm = probs_tags_test[\"SVM PROB 0\"]\n",
    "    probs0_tags_knn = probs_tags_test[\"KNN PROB 0\"]\n",
    "    probs0_tags_mlp = probs_tags_test[\"MLP PROB 0\"]\n",
    "    probs0_tags_dtr = probs_tags_test[\"DT PROB 0\"]\n",
    "    probs0_tags_nb  = probs_tags_test[\"NB PROB 0\"]\n",
    "    probs1_tags_svm = probs_tags_test[\"SVM PROB 1\"]\n",
    "    probs1_tags_knn = probs_tags_test[\"KNN PROB 1\"]\n",
    "    probs1_tags_mlp = probs_tags_test[\"MLP PROB 1\"]\n",
    "    probs1_tags_dtr = probs_tags_test[\"DT PROB 1\"]\n",
    "    probs1_tags_nb  = probs_tags_test[\"NB PROB 1\"]\n",
    "    \n",
    "    probs_test = {\"file_name\": file_names_test,\n",
    "         \"CAPS SVM PROB 0\": [item for item in probs0_caps_svm], \n",
    "         \"CAPS SVM PROB 1\": [item for item in probs1_caps_svm], \n",
    "         \"CAPS KNN PROB 0\": [item for item in probs0_caps_knn], \n",
    "         \"CAPS KNN PROB 1\": [item for item in probs1_caps_knn],\n",
    "         \"CAPS NB PROB 0\":  [item for item in probs0_caps_nb ],\n",
    "         \"CAPS NB PROB 1\":  [item for item in probs1_caps_nb ], \n",
    "         \"CAPS DT PROB 0\":  [item for item in probs0_caps_dtr],\n",
    "         \"CAPS DT PROB 1\":  [item for item in probs1_caps_dtr], \n",
    "         \"CAPS MLP PROB 0\": [item for item in probs0_caps_mlp],\n",
    "         \"CAPS MLP PROB 1\": [item for item in probs1_caps_mlp], \n",
    "         \"TAGS SVM PROB 0\": [item for item in probs0_tags_svm], \n",
    "         \"TAGS SVM PROB 1\": [item for item in probs1_tags_svm], \n",
    "         \"TAGS KNN PROB 0\": [item for item in probs0_tags_knn], \n",
    "         \"TAGS KNN PROB 1\": [item for item in probs1_tags_knn],\n",
    "         \"TAGS NB PROB 0\": [item for item in  probs0_tags_nb ],\n",
    "         \"TAGS NB PROB 1\": [item for item in  probs1_tags_nb ], \n",
    "         \"TAGS DT PROB 0\": [item for item in  probs0_tags_dtr],\n",
    "         \"TAGS DT PROB 1\": [item for item in  probs1_tags_dtr], \n",
    "         \"TAGS MLP PROB 0\": [item for item in probs0_tags_mlp],\n",
    "         \"TAGS MLP PROB 1\": [item for item in probs1_tags_mlp],\n",
    "         \"TEXT SVM PROB 0\": [item for item in probs0_text_svm], \n",
    "         \"TEXT SVM PROB 1\": [item for item in probs1_text_svm], \n",
    "         \"TEXT KNN PROB 0\": [item for item in probs0_text_knn], \n",
    "         \"TEXT KNN PROB 1\": [item for item in probs1_text_knn],\n",
    "         \"TEXT NB PROB 0\":  [item for item in probs0_text_nb ],\n",
    "         \"TEXT NB PROB 1\":  [item for item in probs1_text_nb ], \n",
    "         \"TEXT DT PROB 0\":  [item for item in probs0_text_dtr],\n",
    "         \"TEXT DT PROB 1\":  [item for item in probs1_text_dtr], \n",
    "         \"TEXT MLP PROB 0\": [item for item in probs0_text_mlp],\n",
    "         \"TEXT MLP PROB 1\": [item for item in probs1_text_mlp],\n",
    "         \"BMA PROB 0\": [item for item in sum_prob0_bma],\n",
    "         \"BMA PROB 1\": [item for item in sum_prob1_bma],\n",
    "         \"LABELS BMA\": [item for item in predictions_bma[0]],\n",
    "         \"GROUND TRUTH\": y_test\n",
    "      }\n",
    "    data_probs_test_clfs = pd.DataFrame(probs_test)\n",
    "    nome_df_test = f\"../data/results2strategy/bma/sintest/CLFS_PROBS_BMATOT_sintest_str2_fold_{j+1}.csv\"\n",
    "    data_probs_test_clfs.to_csv(nome_df_test, sep=\"\\t\")\n",
    "#print(\"PROBS POS PER AUC \", y_prob_auc)\n",
    "#tn, fp, fn, tp = confusion_matrix(y_test, y_bma_pred).ravel()\n",
    "#print(tn,fp,fn,tp)\n",
    "#true_postives_bma.append(tp)\n",
    "#true_negatives_bma.append(tn)\n",
    "#false_negative_bma.append(fn)\n",
    "#false_positives_bma.append(fp)\n",
    "\n",
    "#auc_score_bma = roc_auc_score(y_test, y_prob_auc)\n",
    "\n",
    "#print(\"################  BMA calcolo alternativo #############################\")\n",
    "rec_pos_bma = sum(tp_bma)/ (sum(tp_bma) + sum(fn_bma)) ###True postive rate recall classe 1\n",
    "fn_rate_bma = sum(fn_bma)/ (sum(tp_bma)+ sum(fn_bma))\n",
    "prec_mis_bma = sum(tp_bma)/ (sum(tp_bma) + sum(fp_bma))\n",
    "prec_notmis_bma = sum(tn_bma)/ (sum(tn_bma) + sum(fn_bma))\n",
    "rec_neg_bma = sum(tn_bma) / (sum(tn_bma)+ sum(fp_bma))\n",
    "false_positive_rate_bma = sum(fp_bma) / (sum(fp_bma)+ sum(tn_bma))\n",
    "f1_1_bma= (2* (prec_mis_bma * rec_pos_bma)) / (prec_mis_bma+ rec_pos_bma) \n",
    "f1_0_bma = (2* (prec_notmis_bma * rec_neg_bma)) / (prec_notmis_bma + rec_neg_bma)\n",
    "\n",
    "\n",
    "print(\"################  BMA #############################\")\n",
    "print(\"ACC BMA \", acc_bma_list)\n",
    "print(\"ACC BMA \", sum(acc_bma_list)/10)\n",
    "print(\"AUC BMA \", auc_bma_list)\n",
    "print(\"AUC BMA \", sum(auc_bma_list)/10)\n",
    "\n",
    "print(\"precision class 1 of k fold BMA \", prec_mis_bma)\n",
    "print(\"precision class 0 of kfold BMA \", prec_notmis_bma)\n",
    "print(\"prec \", mean([prec_mis_bma, prec_notmis_bma]))\n",
    "\n",
    "print(\"recall class 1 k fold BMA\", rec_pos_bma)\n",
    "print(\"recall class 0 k fold BMA \", rec_neg_bma)\n",
    "print(\"rec \", mean([rec_pos_bma, rec_neg_bma]))\n",
    "\n",
    "print(\"f1 pos BMA \", f1_1_bma)\n",
    "print(\"f1 neg BMA \", f1_0_bma)\n",
    "print(\"f1 \", mean([f1_0_bma, f1_1_bma]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "prec_bma = mean([prec_notmis_bma,prec_mis_bma])\n",
    "rec_bma = mean([rec_neg_bma, rec_pos_bma])\n",
    "f1_bma = mean([f1_0_bma, f1_1_bma])\n",
    "acc_bma = sum(acc_bma_list)/10\n",
    "auc_bma = sum(auc_bma_list)/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ris_tags_sintest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7698/1595564266.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m res_sintest = {\"Modelli\": [\"TAGS\", \"TEXT\", \"CAPS\", \"BMA\"],\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;34m\"Prec 0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mris_tags_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_text_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_caps_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec_notmis_bma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m        \u001b[0;34m\"Prec 1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mris_tags_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec 1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_text_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec 1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_caps_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec 1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec_mis_bma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m\"Prec\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mris_tags_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_text_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_caps_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Prec\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec_bma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;34m\"Rec 0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mris_tags_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Rec 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_text_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Rec 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mris_caps_sintest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Rec 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_neg_bma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ris_tags_sintest' is not defined"
     ]
    }
   ],
   "source": [
    "res_sintest = {\"Modelli\": [\"TAGS\", \"TEXT\", \"CAPS\", \"BMA\"],\n",
    "        \"Prec 0\": [ris_tags_sintest[\"Prec 0\"][5], ris_text_sintest[\"Prec 0\"][5], ris_caps_sintest[\"Prec 0\"][5], prec_notmis_bma],\n",
    "       \"Prec 1\": [ris_tags_sintest[\"Prec 1\"][5], ris_text_sintest[\"Prec 1\"][5], ris_caps_sintest[\"Prec 1\"][5], prec_mis_bma],\n",
    "       \"Prec\": [ris_tags_sintest[\"Prec\"][5], ris_text_sintest[\"Prec\"][5], ris_caps_sintest[\"Prec\"][5], prec_bma],\n",
    "       \"Rec 0\": [ris_tags_sintest[\"Rec 0\"][5], ris_text_sintest[\"Rec 0\"][5], ris_caps_sintest[\"Rec 0\"][5], rec_neg_bma],\n",
    "       \"Rec 1\": [ris_tags_sintest[\"Rec 1\"][5], ris_text_sintest[\"Rec 1\"][5], ris_caps_sintest[\"Rec 1\"][5], rec_pos_bma],\n",
    "       \"Rec\": [ris_tags_sintest[\"Rec\"][5], ris_text_sintest[\"Rec\"][5], ris_caps_sintest[\"Rec\"][5],rec_bma],\n",
    "       \"F1 0\": [ris_tags_sintest[\"F1 0\"][5], ris_text_sintest[\"F1 0\"][5], ris_caps_sintest[\"F1 0\"][5], f1_0_bma],\n",
    "       \"F1 1\": [ris_tags_sintest[\"F1 1\"][5], ris_text_sintest[\"F1 1\"][5], ris_caps_sintest[\"F1 1\"][5], f1_1_bma], \n",
    "       \"F1\": [ris_tags_sintest[\"F1 \"][5], ris_text_sintest[\"F1 \"][5], ris_caps_sintest[\"F1 \"][5], f1_bma], \n",
    "       \"ACC\": [ris_tags_sintest[\"ACC\"][5], ris_text_sintest[\"ACC\"][5], ris_caps_sintest[\"ACC\"][5], acc_bma],\n",
    "       \"AUC\": [ris_tags_sintest[\"AUC\"][5], ris_text_sintest[\"AUC\"][5], ris_caps_sintest[\"AUC\"][5], roc_auc_bma]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.715268</td>\n",
       "      <td>0.702458</td>\n",
       "      <td>0.708863</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>0.704130</td>\n",
       "      <td>0.713066</td>\n",
       "      <td>0.708598</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>0.734222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.676096</td>\n",
       "      <td>0.656999</td>\n",
       "      <td>0.666547</td>\n",
       "      <td>0.637333</td>\n",
       "      <td>0.694667</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.656143</td>\n",
       "      <td>0.675308</td>\n",
       "      <td>0.665725</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.705422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.667082</td>\n",
       "      <td>0.691977</td>\n",
       "      <td>0.679530</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.678667</td>\n",
       "      <td>0.689433</td>\n",
       "      <td>0.667127</td>\n",
       "      <td>0.678280</td>\n",
       "      <td>0.678667</td>\n",
       "      <td>0.730489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.728834</td>\n",
       "      <td>0.750549</td>\n",
       "      <td>0.705333</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.748667</td>\n",
       "      <td>0.737282</td>\n",
       "      <td>0.759105</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.748667</td>\n",
       "      <td>0.812089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli    Prec 0    Prec 1      Prec     Rec 0     Rec 1       Rec  \\\n",
       "0    TAGS  0.715268  0.702458  0.708863  0.693333  0.724000  0.708667   \n",
       "1    TEXT  0.676096  0.656999  0.666547  0.637333  0.694667  0.666000   \n",
       "2    CAPS  0.667082  0.691977  0.679530  0.713333  0.644000  0.678667   \n",
       "3     BMA  0.772263  0.728834  0.750549  0.705333  0.792000  0.748667   \n",
       "\n",
       "       F1 0      F1 1        F1       ACC       AUC  \n",
       "0  0.704130  0.713066  0.708598  0.708667  0.734222  \n",
       "1  0.656143  0.675308  0.665725  0.666000  0.705422  \n",
       "2  0.689433  0.667127  0.678280  0.678667  0.730489  \n",
       "3  0.737282  0.759105  0.748194  0.748667  0.812089  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_sintest = pd.DataFrame(res_sintest)\n",
    "risultati_sintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.7025</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.7342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.6761</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6753</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.7054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.6671</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.6894</td>\n",
       "      <td>0.6671</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.7305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.7723</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>0.7920</td>\n",
       "      <td>0.7487</td>\n",
       "      <td>0.7373</td>\n",
       "      <td>0.7591</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>0.7487</td>\n",
       "      <td>0.8121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli  Prec 0  Prec 1    Prec   Rec 0   Rec 1     Rec    F1 0    F1 1  \\\n",
       "0    TAGS  0.7153  0.7025  0.7089  0.6933  0.7240  0.7087  0.7041  0.7131   \n",
       "1    TEXT  0.6761  0.6570  0.6665  0.6373  0.6947  0.6660  0.6561  0.6753   \n",
       "2    CAPS  0.6671  0.6920  0.6795  0.7133  0.6440  0.6787  0.6894  0.6671   \n",
       "3     BMA  0.7723  0.7288  0.7505  0.7053  0.7920  0.7487  0.7373  0.7591   \n",
       "\n",
       "       F1     ACC     AUC  \n",
       "0  0.7086  0.7087  0.7342  \n",
       "1  0.6657  0.6660  0.7054  \n",
       "2  0.6783  0.6787  0.7305  \n",
       "3  0.7482  0.7487  0.8121  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_sintest.iloc[:,1:] = risultati_sintest.iloc[:,1:].round(4)\n",
    "risultati_sintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.715268</td>\n",
       "      <td>0.702458</td>\n",
       "      <td>0.708863</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>0.704130</td>\n",
       "      <td>0.713066</td>\n",
       "      <td>0.708598</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>0.734222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.676096</td>\n",
       "      <td>0.656999</td>\n",
       "      <td>0.666547</td>\n",
       "      <td>0.637333</td>\n",
       "      <td>0.694667</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.656143</td>\n",
       "      <td>0.675308</td>\n",
       "      <td>0.665725</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.705422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.667082</td>\n",
       "      <td>0.691977</td>\n",
       "      <td>0.679530</td>\n",
       "      <td>0.713333</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.678667</td>\n",
       "      <td>0.689433</td>\n",
       "      <td>0.667127</td>\n",
       "      <td>0.678280</td>\n",
       "      <td>0.678667</td>\n",
       "      <td>0.730489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMA</td>\n",
       "      <td>0.773775</td>\n",
       "      <td>0.735732</td>\n",
       "      <td>0.754754</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.743767</td>\n",
       "      <td>0.762211</td>\n",
       "      <td>0.752989</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.812444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelli    Prec 0    Prec 1      Prec     Rec 0     Rec 1       Rec  \\\n",
       "0    TAGS  0.715268  0.702458  0.708863  0.693333  0.724000  0.708667   \n",
       "1    TEXT  0.676096  0.656999  0.666547  0.637333  0.694667  0.666000   \n",
       "2    CAPS  0.667082  0.691977  0.679530  0.713333  0.644000  0.678667   \n",
       "3     BMA  0.773775  0.735732  0.754754  0.716000  0.790667  0.753333   \n",
       "\n",
       "       F1 0      F1 1        F1       ACC       AUC  \n",
       "0  0.704130  0.713066  0.708598  0.708667  0.734222  \n",
       "1  0.656143  0.675308  0.665725  0.666000  0.705422  \n",
       "2  0.689433  0.667127  0.678280  0.678667  0.730489  \n",
       "3  0.743767  0.762211  0.752989  0.753333  0.812444  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risultati_sintest = pd.DataFrame(res_sintest)\n",
    "risultati_sintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "risultati_sintest.to_csv(\"../data/results2strategy/bma/sintest/BMA_RESULTS-sintest-22-02.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riis_train = pd.read_csv(\"BMA_RESULTS-train-19-02.csv\", sep=\"\\t\")\n",
    "riis_test = pd.read_csv(\"BMA_RESULTS-test-19-02.csv\", sep=\"\\t\")\n",
    "riis_sintest = pd.read_csv(\"BMA_RESULTS-sintest-19-02.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riis_test.iloc[:,2:] = riis_test.iloc[:,2:].round(4)\n",
    "riis_test.to_csv(\"../data/results/BMA_RESULTS-test-19-02.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riis_sintest.iloc[:,2:] = riis_sintest.iloc[:,2:].round(4)\n",
    "riis_sintest.to_csv(\"../data/results/BMA_RESULTS-sintest-19-02.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Modelli</th>\n",
       "      <th>Prec 0</th>\n",
       "      <th>Prec 1</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec 0</th>\n",
       "      <th>Rec 1</th>\n",
       "      <th>Rec</th>\n",
       "      <th>F1 0</th>\n",
       "      <th>F1 1</th>\n",
       "      <th>F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TAGS</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.6834</td>\n",
       "      <td>0.7584</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.7024</td>\n",
       "      <td>0.6509</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.7940</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CAPS</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.6924</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.7557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BMA</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.8021</td>\n",
       "      <td>0.8626</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.7969</td>\n",
       "      <td>0.8094</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.7969</td>\n",
       "      <td>0.8997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Modelli  Prec 0  Prec 1    Prec   Rec 0   Rec 1     Rec    F1 0  \\\n",
       "0           0    TAGS  0.6541  0.7126  0.6834  0.7584  0.5990  0.6787  0.7024   \n",
       "1           1    TEXT  0.7899  0.7959  0.7929  0.7980  0.7878  0.7929  0.7940   \n",
       "2           2    CAPS  0.6562  0.7695  0.7129  0.8308  0.5648  0.6978  0.7333   \n",
       "3           3     BMA  0.7624  0.8418  0.8021  0.8626  0.7312  0.7969  0.8094   \n",
       "\n",
       "     F1 1      F1     ACC     AUC  \n",
       "0  0.6509  0.6766  0.6787  0.7269  \n",
       "1  0.7918  0.7929  0.7929  0.8753  \n",
       "2  0.6514  0.6924  0.6978  0.7557  \n",
       "3  0.7826  0.7960  0.7969  0.8997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "riis_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riis_train.iloc[:,2:] = riis_train.iloc[:,2:].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM SYNTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFFOMMANCE rec 0.8 prec  0.7142857142857143 f1  0.7547169811320756 acc  0.74\n",
      "1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'not misogynous'), Text(0, 1.5, 'misogynous')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn_bma = []\n",
    "fp_bma = []\n",
    "fn_bma = []\n",
    "tp_bma = []\n",
    "acc = []\n",
    "rec = []\n",
    "prec = []\n",
    "f1 = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    n_fold = f\"../data/results2strategy/bma/sintest/CLFS_PROBS_BMATOT_sintest_str2_fold_{j+1}.csv\"\n",
    "    data_probs = pd.read_csv(n_fold, sep=\"\\t\")\n",
    "    y_test = data_probs[\"GROUND TRUTH\"]\n",
    "    pred =  data_probs[\"LABELS BMA\"]\n",
    "    a = accuracy_score(y_test, pred)\n",
    "    r = recall_score(y_test, pred)\n",
    "    p = precision_score(y_test, pred)\n",
    "    f = f1_score(y_test, pred)\n",
    "    acc.append(a)\n",
    "    rec.append(r)\n",
    "    prec.append(p)\n",
    "    f1.append(f)\n",
    "    tn_b, fp_b, fn_b, tp_b = confusion_matrix(y_test, pred).ravel()\n",
    "    tp_bma.append(tp_b)\n",
    "    tn_bma.append(tn_b)\n",
    "    fn_bma.append(fn_b)\n",
    "    fp_bma.append(fp_b)\n",
    "    \n",
    "print(\"PEFFOMMANCE rec\", mean(rec), \"prec \", mean(prec), \"f1 \", mean(f1), \"acc \", mean(acc))\n",
    "print(sum(tp_bma)+ sum(tn_bma)+ sum(fp_bma)+ sum(fn_bma))\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap([[mean(tn_bma), mean(fp_bma)],[mean(fn_bma), mean(tp_bma)]], annot=True, fmt='g', cmap=\"Blues\", ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['not misogynous', 'misogynous']); ax.yaxis.set_ticklabels(['not misogynous', 'misogynous'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bma_text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cc28eb16bd8d43549a56192430efce750ae0401fff7fe773fc955fcfb63434a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
